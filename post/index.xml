<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Vic&#39;s Blog</title>
		<link>https://cvvz.github.io/post/</link>
		<description>Recent content in Posts on Vic&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>zh-hans</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Wed, 30 Dec 2020 15:42:01 +0800</lastBuildDate>
		<atom:link href="https://cvvz.github.io/post/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>kubernetes网络之service</title>
			<link>https://cvvz.github.io/post/k8s-network-service/</link>
			<pubDate>Wed, 30 Dec 2020 15:42:01 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-service/</guid>
			<description>在kubernetes中，service其实只是一个保存在etcd里的API对象，并不对应任何具体的实体，真正起作用的是watch servi</description>
			<content type="html"><![CDATA[<p>在kubernetes中，service其实只是一个保存在etcd里的API对象，并不对应任何具体的实体，真正起作用的是watch service、endpoint、pod等资源的的DNS、kube-proxy，以及iptables等，他们共同配合，实现service的各项功能。</p>
<h2 id="从集群内部访问clusterip服务">从集群内部访问ClusterIP服务</h2>
<p>在<a href="https://cvvz.github.io/post/k8s-network-dns/">kubernetes网络之DNS
</a>一文中，已经详细说明了从域名到ClusterIP的转换过程。</p>
<p>下面以kubernetes集群中某个Pod访问<code>kubernetes</code>服务（kube-apiserver）为例，分析一下kubernetes是怎么将对ClusterIP的访问转变成对某个后端Pod的访问的。</p>
<blockquote>
<p>注：kube-proxy以iptables模式工作</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k get svc <span class="p">|</span> grep kubernetes
<span class="ln">2</span>kubernetes                      ClusterIP      192.168.0.1       &lt;none&gt;                  443/TCP                                             348d
<span class="ln">3</span>
<span class="ln">4</span>➜  ~ k get ep kubernetes
<span class="ln">5</span>NAME         ENDPOINTS                                                AGE
<span class="ln">6</span>kubernetes   10.20.126.169:6443,10.28.116.8:6443,10.28.126.199:6443   348d
</code></pre></div><ol>
<li>首先数据包从容器中被路由到cni网桥，出现在宿主机网络栈中。</li>
<li>Netfilter在<code>PREROUTING</code>链中处理该数据包，最终会将其转到<code>KUBE-SERVICES</code>链上进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A PREROUTING -m comment --comment <span class="s2">&#34;kubernetes service portals&#34;</span> -j KUBE-SERVICES
</code></pre></div><ol start="3">
<li><code>KUBE-SERVICES</code>链将目的地址为<code>192.168.0.1</code>的数据包跳转到<code>KUBE-SVC-NPX46M4PTMTKRN6Y</code>链进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SERVICES -d 192.168.0.1/32 -p tcp -m comment --comment <span class="s2">&#34;default/kubernetes:https cluster IP&#34;</span> -m tcp --dport <span class="m">443</span> -j KUBE-SVC-NPX46M4PTMTKRN6Y
</code></pre></div><ol start="4">
<li><code>KUBE-SVC-NPX46M4PTMTKRN6Y</code>链以<strong>相等概率</strong>将数据包跳转到<code>KUBE-SEP-A66XJ5Q22M6AZV5X</code>、<code>KUBE-SEP-TYGT5TFZZ2W5DK4V</code>或<code>KUBE-SEP-KQD4HGXQYU3ORDNS</code>链进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-A66XJ5Q22M6AZV5X
<span class="ln">2</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-TYGT5TFZZ2W5DK4V
<span class="ln">3</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -j KUBE-SEP-KQD4HGXQYU3ORDNS
</code></pre></div><ol start="5">
<li>而这三条链，其实代表了三条 DNAT 规则。DNAT 规则的作用，就是将 IP 包的目的地址和端口，改成 <code>--to-destination</code> 所指定的新的目的地址和端口。可以看到，这个目的地址和端口，正是后端 Pod 的 IP 地址和端口。而这一切发生在Netfilter的<code>PREROUTING</code>链上，接下来Netfilter就会根据这个目的地址，对数据包进行路由。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SEP-A66XJ5Q22M6AZV5X -p tcp -m tcp -j DNAT --to-destination 10.20.126.169:6443
<span class="ln">2</span>-A KUBE-SEP-TYGT5TFZZ2W5DK4V -p tcp -m tcp -j DNAT --to-destination 10.28.116.8:6443
<span class="ln">3</span>-A KUBE-SEP-KQD4HGXQYU3ORDNS -p tcp -m tcp -j DNAT --to-destination 10.28.126.199:6443
</code></pre></div><ol start="6">
<li>如果目的Pod的IP地址就在本节点，则数据包会被路由回cni网桥，由cni网桥进行转发；如果目的Pod的IP地址在其他节点，则要进行一次容器跨节点通信，跨节点通信的过程可以参考<a href="https://cvvz.github.io/post/k8s-network-cross-host/">kubernetes网络之CNI与跨节点通信原理</a>这篇文章。</li>
</ol>
<h2 id="从集群外部访问nodeport服务">从集群外部访问NodePort服务</h2>
<p>以下面这个服务(<strong>NodePort为<code>31849</code></strong>)为例：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k get svc webapp
<span class="ln">2</span>NAME     TYPE       CLUSTER-IP       EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>          AGE
<span class="ln">3</span>webapp   NodePort   192.168.15.113   &lt;none&gt;        8081:31849/TCP   319d
</code></pre></div><ol>
<li>kube-proxy会在主机上打开31849端口，并配置一系列iptables规则：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ sudo lsof -i:31849
<span class="ln">2</span>COMMAND      PID USER   FD   TYPE     DEVICE SIZE/OFF NODE NAME
<span class="ln">3</span>kube-prox <span class="m">253942</span> root   12u  IPv6 <span class="m">1852002168</span>      0t0  TCP *:31849 <span class="o">(</span>LISTEN<span class="o">)</span>
</code></pre></div><ol start="2">
<li>入口链<code>KUBE-NODEPORTS</code>是<code>KUBE-SERVICES</code>中的<strong>最后一条规则</strong>：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SERVICES -m comment --comment <span class="s2">&#34;kubernetes service nodeports; NOTE: this must be the last rule in this chain&#34;</span> -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
</code></pre></div><ol start="3">
<li>先跳到<code>KUBE-MARK-MASQ</code>链打上<strong>特殊记号<code>0x4000/0x4000</code></strong>，这个特殊记号<strong>后续在<code>POSTROUTING</code>链中进行SNAT时用到</strong>。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-MARK-MASQ
<span class="ln">2</span>
<span class="ln">3</span>-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
</code></pre></div><ol start="4">
<li>然后跳到<code>KUBE-SVC-BL7FHTIPVYJBLWZN</code>链：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-SVC-BL7FHTIPVYJBLWZN
</code></pre></div><ol start="5">
<li>后续的处理流程和上一节描述的相同，直到找到了目的Pod IP。</li>
<li>如果目的Pod IP地址就在本节点，则路由给cni网桥转发；如果目的Pod IP在其他节点，则需要进行容器跨节点通信。<strong>注意，这种情形下，本节点相当于网关的角色，在将源数据包转发出去之前，需要进行SNAT，将源数据包的源IP地址，转换为网关（本节点）的IP地址，这样，数据包才可能原路返回，即从目的节点经过本节点返回到实际的k8s集群外部的客户端</strong>：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-POSTROUTING -m comment --comment <span class="s2">&#34;kubernetes service traffic requiring SNAT&#34;</span> -m mark --mark 0x4000/0x4000 -j MASQUERADE
</code></pre></div><p>这条规则的意思就是：带有<code>0x4000/0x4000</code>这个特殊标记的数据包在离开节点之前，在<code>POSTROUTING</code>链上进行一次SNAT，即<code>MASQUERADE</code>。而这个特殊标记，如前所述，是在外部客户端数据流入节点时打上去的。</p>
<h2 id="总结">总结</h2>
<p>从上面的分析中，可以看出来，kube-proxy iptables模式中，最重要的是下面这五条链：</p>
<ul>
<li><strong>KUBE-SERVICES</strong>：ClusterIP方式访问的入口链；</li>
<li><strong>KUBE-NODEPORTS</strong>：NodePort方式访问的入口链；</li>
<li><strong>KUBE-SVC-</strong>*：相当于一个负载均衡器，将数据包平均分发给<code>KUBE-SEP-*</code>链；</li>
<li><strong>KUBE-SEP-</strong>*：通过DNAT将Service的目的IP和端口，替换为后端Pod的IP和端口，从而将流量转发到后端Pod。</li>
<li><strong>KUBE-POSTROUTING</strong>：通过对路由到其他节点的数据包进行SNAT，使其能够原路返回。</li>
</ul>
<blockquote>
<p>对于NodePort类型的service，<strong>如果本节点上没有目的Pod，则本节点起到的是网关的作用</strong>，将数据路由到其他节点。在这种情况下，<strong>访问Pod IP的链路会多一跳</strong>。我们可以通过将<code>externalTrafficPolicy</code>字段设置为<code>local</code>，当这样本节点上不存在Pod时，<code>FORWARD</code>链上的<code>filter</code>表规则会直接把包drop掉，而不会从本节点转发出去：</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-XLB-BL7FHTIPVYJBLWZN
<span class="ln">2</span>
<span class="ln">3</span>-A KUBE-XLB-BL7FHTIPVYJBLWZN -m comment --comment <span class="s2">&#34;default/webapp: has no local endpoints&#34;</span> -j KUBE-MARK-DROP
<span class="ln">4</span>
<span class="ln">5</span>-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
<span class="ln">6</span>
<span class="ln">7</span>-A KUBE-FIREWALL -m comment --comment <span class="s2">&#34;kubernetes firewall for dropping marked packets&#34;</span> -m mark --mark 0x8000/0x8000 -j DROP
</code></pre></div><h2 id="kube-proxy的ipvs模式">kube-proxy的IPVS模式</h2>
<p>上述流程描述的是kube-proxy的iptables模式的工作流程，这个模式最大的问题在于：</p>
<ul>
<li>kube-proxy需要为service配置大量的iptables规则，并且刷新这些规则以确保正确性；</li>
<li>iptables的规则是以链表的形式保存的，对iptables的刷新需要遍历链表</li>
</ul>
<p>解决办法就是使用IPVS模式的kube-proxy。IPVS是Linux内核实现的四层负载均衡，因此相比于通过配置iptables规则进行“投机取巧”式的负载均衡，IPVS更加专业。IPVS
和iptables一样底层也是基于netfilter，但使用更高效的数据结构（散列表），允许几乎无限的规模扩张。</p>
<p>创建一个service时，IPVS模式kube-proxy会创建一块虚拟网卡，并且把service的ClusterIP绑在网卡上，然后设置这个网卡的后端real server，对应的是EndPoints，并设置负载均衡规则。这样，数据包就会先发送到kube-proxy的虚拟网卡上，然后转发到后端Pod。</p>
<p>IPVS没有SNAT的能力，所以在一些场景下，依然需要依赖iptables。但是使用IPVS模式的kube-proxy，不存在上述两个问题，性能要优于iptables模式。</p>
]]></content>
		</item>
		
		<item>
			<title>kubernetes网络之CNI与跨节点通信原理</title>
			<link>https://cvvz.github.io/post/k8s-network-cross-host/</link>
			<pubDate>Wed, 30 Dec 2020 09:51:44 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-cross-host/</guid>
			<description>初始化infra容器网络环境 当kubelet通过调用CRI的RunPodSandbox创建好PodSandbox，即infra容器后，就需要</description>
			<content type="html"><![CDATA[<h2 id="初始化infra容器网络环境">初始化infra容器网络环境</h2>
<p>当kubelet通过调用CRI的<a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/cri-api/pkg/apis/services.go#L66">RunPodSandbox</a>创建好<code>PodSandbox</code>，即infra容器后，就需要调用<a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/dockershim/network/plugins.go#L73">SetUpPod</a>方法为Pod（infra容器）创建网络环境，底层是调用CNI的<a href="https://github.com/containernetworking/cni/blob/master/libcni/api.go#L80">AddNetwork</a>为infra容器配置网络环境。</p>
<p>这个配置网络环境的过程，就是kubelet从cni配置文件目录（<code>--cni-conf-dir</code>参数指定）中读取文件，并使用该文件中的CNI配置配置infra网络。kubelet根据配置文件，需要使用CNI插件二进制文件（存放在<code>--cni-bin-dir</code>参数指定的目录下）实际配置infra网络。</p>
<p>这些 CNI 的基础可执行文件，按照功能可以分为三类：</p>
<ol>
<li><strong>Main 插件</strong>，它是用来创建具体网络设备的二进制文件，比如bridge（网桥设备）、loopback（lo 设备）、ptp（Veth Pair 设备）等等</li>
<li><strong>IPAM（IP Address Management）插件</strong>，用来给容器分配IP地址，比如dhcp和host-local。</li>
<li><strong>CNI 社区维护的第三方 CNI 插件</strong>，比如<code>flannel</code>，提供跨主机通信方案</li>
</ol>
<p>初始化一个容器网络环境的过程大致如下：</p>
<ol>
<li>没有网桥就使用<code>bridge</code>创建一个网桥设备</li>
<li>使用<code>ptp</code>创建一个veth pair设备，并且把一端插在容器里，成为容器的eth0网卡，另一端插在网桥上</li>
<li>使用<code>dhcp</code>或<code>host-local</code>为eth0网卡分配IP地址</li>
<li>调用第三方CNI插件，比如<code>flannel</code>，实现容器跨主机通信方案</li>
</ol>
<h2 id="容器跨节点通信">容器跨节点通信</h2>
<p>在<a href="https://cvvz.github.io/post/container-network/">浅谈单机容器网络</a>一文中，已经详细分析了同一主机内部容器之间通过veth + 网桥的方式通信的过程，下面分析一下容器跨主机通信的过程。</p>
<p>容器的跨主机网络方案可以分为两类：<strong>overlay</strong>和<strong>underlay</strong>。</p>
<h3 id="underlay和overlay">underlay和overlay</h3>
<p>所谓underlay，也就是没有在宿主机网络上的虚拟层，容器和宿主机处于同一个网络层面上。</p>
<blockquote>
<p>在这种情形下，Kubernetes 内外网络是互通的，运行在kubernetes中的容器可以很方便的和公司内部已有的非云原生基础设施进行联动，比如DNS、负载均衡、配置中心等，而不需要借助kubernetes内部的DNS、ingress和service做服务发现和负载均衡。</p>
</blockquote>
<p>所谓overlay，其实就是在容器的IP包外面附加额外的数据包头，然后<strong>整体作为宿主机网络报文中的数据进行传输</strong>。容器的IP包加上额外的数据包头就用于跨主机的容器之间通信，<strong>容器网络就相当于覆盖(overlay)在宿主机网络上的一层虚拟网络</strong>。如下图所示：</p>
<figure>
    <img src="/overlay-network.png" width="600px"/> 
</figure>

<h3 id="flannel-udp模式">Flannel UDP模式</h3>
<p>Flannel的UDP模式的工作流程：</p>
<ol>
<li>container-1根据默认路由规则，将IP包发往cni网桥，出现在宿主机的网络栈上；</li>
<li>flanneld预先在宿主机上创建好了路由规则，数据包到达cni网桥后，随即被转发给了flannel0</li>
<li>flannel0的功能就是将数据包传给用户态的flanneld进程</li>
<li>flanneld进程查询etcd，找到目的容器ip地址和目的宿主机ip的对应关系，然后将原ip包封装在一个udp包中发送到目的宿主机上的flanneld进程。</li>
<li>目的宿主机的flanneld收到包后，反向处理一遍就发送到了目的容器中。</li>
</ol>
<p>整个过程如下图所示：</p>
<figure>
    <img src="/flannel-udp.jpg" width="600px"/> 
</figure>

<p>由于这中间数据从flannel0发送到了用户态的flanneld，又从flanneld发送到宿主机的eth0网卡，用户态和内核态发生了两次数据传递，且在用户态还进行了封包操作，所以udp模式性能很差。</p>
<h3 id="flannel-vxlan模式">Flannel VXLAN模式</h3>
<p>Flannel VXLAN模式的原理和UDP模式差不多，区别在于：</p>
<ol>
<li>UDP模式创建的是TUN设备(flannel0)，VXLAN模式创建的是VTEP设备（flannel.1）。</li>
<li>VTEP设备全程工作在内核态，性能比UDP模式更好。</li>
</ol>
<p>VXLAN模式的工作流程：</p>
<ol>
<li>container-1根据默认路由规则，将IP包发往cni网桥，出现在宿主机的网络栈上；</li>
<li>flanneld预先在宿主机上创建好了路由规则，数据包到达cni网桥后，随即被转发给了flannel.1，flannel.1是一个VTEP设备，<strong>它既有 IP 地址，也有 MAC 地址</strong>；</li>
<li><strong>在node2上的目的VTEP设备启动时，node1上的flanneld会将目的VTEP设备的IP地址和MAC地址分别写到node1上的路由表和ARP缓存表中</strong>。</li>
<li>因此，node1上的flannel.1通过查询路由表，知道要发往目的容器，需要经过10.1.16.0这个网关。<strong>其实这个网关，就是目的VTEP设备的ip地址</strong>。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ route -n
<span class="ln">2</span>Kernel IP routing table
<span class="ln">3</span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
<span class="ln">4</span>...
<span class="ln">5</span>10.1.16.0       10.1.16.0       255.255.255.0   UG    <span class="m">0</span>      <span class="m">0</span>        <span class="m">0</span> flannel.1
</code></pre></div><ol start="5">
<li>又由于<strong>这个网关的MAC地址，事先已经被flanneld写到了ARP缓存表中</strong>，所以内核直接把目的VTEP设备的MAC地址封装到链路层的帧头即可：
<figure>
    <img src="/flannel-vxlan-frame.jpg" width="500px"/> 
</figure>
</li>
<li><strong>flanneld还负责维护FDB（转发数据库）中的信息</strong>，查询FDB，就可以通过这个目的VTEP设备的MAC地址找到宿主机Node2的ip地址。</li>
<li>有了目的IP地址，接下来进行一次常规的、宿主机网络上的封包即可。</li>
</ol>
<p>整个过程如下图所示：</p>
<figure>
    <img src="/flannel-vxlan.jpg" width="600px"/> 
</figure>

<p>可以看出，VXLAN模式中，flanneld维护的都是内核态数据：路由表、arp缓存表、FDB，VXLAN模式几乎全程运行在内核态。性能要比UDP模式好不少。</p>
]]></content>
		</item>
		
		<item>
			<title>kubernetes网络之DNS</title>
			<link>https://cvvz.github.io/post/k8s-network-dns/</link>
			<pubDate>Wed, 30 Dec 2020 09:41:51 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-dns/</guid>
			<description>Service和DNS 尽管kubelet在启动容器时，会将同namespace下的Service信息注入到容器的环境变量中： 1➜ ~ kubectl get svc | grep</description>
			<content type="html"><![CDATA[<h2 id="service和dns">Service和DNS</h2>
<p>尽管kubelet在启动容器时，会将同namespace下的Service信息注入到容器的环境变量中：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln"> 1</span>➜  ~ kubectl get svc <span class="p">|</span> grep kubernetes
<span class="ln"> 2</span>kubernetes                      ClusterIP   192.168.0.1       &lt;none&gt;        443/TCP                                             347d
<span class="ln"> 3</span>
<span class="ln"> 4</span>➜  ~ kubectl <span class="nb">exec</span> -it debug-pod -n default -- env <span class="p">|</span> grep KUBERNETES
<span class="ln"> 5</span><span class="nv">KUBERNETES_SERVICE_PORT</span><span class="o">=</span><span class="m">443</span>
<span class="ln"> 6</span><span class="nv">KUBERNETES_PORT</span><span class="o">=</span>tcp://192.168.0.1:443
<span class="ln"> 7</span><span class="nv">KUBERNETES_PORT_443_TCP_ADDR</span><span class="o">=</span>192.168.0.1
<span class="ln"> 8</span><span class="nv">KUBERNETES_PORT_443_TCP_PORT</span><span class="o">=</span><span class="m">443</span>
<span class="ln"> 9</span><span class="nv">KUBERNETES_PORT_443_TCP_PROTO</span><span class="o">=</span>tcp
<span class="ln">10</span><span class="nv">KUBERNETES_PORT_443_TCP</span><span class="o">=</span>tcp://192.168.0.1:443
<span class="ln">11</span><span class="nv">KUBERNETES_SERVICE_PORT_HTTPS</span><span class="o">=</span><span class="m">443</span>
<span class="ln">12</span><span class="nv">KUBERNETES_SERVICE_HOST</span><span class="o">=</span>192.168.0.1
</code></pre></div><p>但是通常情况下我们使用DNS域名解析的方式进行服务注册和发现。</p>
<p>Kubernetes中的DNS应用部署好以后，会对外暴露一个服务，集群内的容器可以通过访问该服务的Cluster IP进行域名解析。DNS服务的Cluster IP由Kubelet的<code>cluster-dns</code>参数指定。并且在创建Pod时，由Kubelet将DNS Server的信息写入容器的<code>/etc/resolv.conf</code>文件中。</p>
<p>查看<code>resolv.conf</code>文件的配置：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- cat /etc/resolv.conf
<span class="ln">2</span>nameserver 192.168.0.2
<span class="ln">3</span>search default.svc.cluster.local svc.cluster.local cluster.local
<span class="ln">4</span>options ndots:5
</code></pre></div><p><code>nameserver 192.168.0.2</code>即表示DNS服务的地址为<code>192.168.0.2</code>。</p>
<p><code>search</code>这一行表示，如果无法直接解析域名，则会尝试加上<code>default.svc.cluster.local</code>, <code>svc.cluster.local</code>, <code>cluster.local</code>后缀进行域名解析。</p>
<blockquote>
<p>其中<code>default</code>是namespace，<code>cluster.local</code>是默认的集群域名后缀，kubelet可以通过<code>--cluster_domain</code>配置。</p>
</blockquote>
<p>也就是说：</p>
<ul>
<li>同namespace下，可以通过<code>nslookup</code> + <code>kubernetes</code>解析域名</li>
<li>不同namespace下，可以通过<code>nslookup</code> + <code>kubernetes.default</code>、<code>kubernetes.default.svc</code>、<code>kubernetes.default.svc.cluster.local</code>解析域名</li>
</ul>
<p>因为dns服务器会帮你补齐全域名：<code>kubernetes.default.svc.cluster.local</code></p>
<blockquote>
<p><code>{svc name}.{svc namespace}.svc.{cluster domain}</code>就是kubernetes的FQDN格式。</p>
</blockquote>
<h2 id="headless-service的域名解析">Headless Service的域名解析</h2>
<p><strong>无论是kube-dns还是CoreDNS，基本原理都是通过watch Service和Pod，生成DNS记录</strong>。常规的ClusterIP类型的Service的域名解析如上所述，DNS服务会返回一个<code>A记录</code>，即域名和ClusterIP的对应关系：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup kubernetes.default
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>Name:	kubernetes.default.svc.cluster.local
<span class="ln">6</span>Address: 192.168.0.1
</code></pre></div><p>Headless Service的域名解析稍微复杂一点。</p>
<blockquote>
<p>ClusterIP可以看作是Service的头，而Headless Service，顾名思义也就是指定他的ClusterIP为None的Service。</p>
</blockquote>
<h3 id="直接解析">直接解析</h3>
<p>当你直接解析它的域名时，返回的是EndPoints中的Pod IP列表：</p>
<blockquote>
<p>这个EndPoints后端的Pod，不仅可以通过在service中指定selector来选择，也可以自己定义，只要名字和service同名即可。</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln"> 1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup headless
<span class="ln"> 2</span>Defaulting container name to debug.
<span class="ln"> 3</span>Use <span class="s1">&#39;kubectl describe pod/debug-pod -n default&#39;</span> to see all of the containers in this pod.
<span class="ln"> 4</span>Server:		192.168.0.2
<span class="ln"> 5</span>Address:	192.168.0.2#53
<span class="ln"> 6</span>
<span class="ln"> 7</span>Name:	headless.default.svc.cluster.local
<span class="ln"> 8</span>Address: 1.1.1.1
<span class="ln"> 9</span>Name:	headless.default.svc.cluster.local
<span class="ln">10</span>Address: 2.2.2.2
<span class="ln">11</span>Name:	headless.default.svc.cluster.local
<span class="ln">12</span>Address: 3.3.3.3
</code></pre></div><h3 id="给pod生成a记录">给Pod生成A记录</h3>
<p>如果<strong>在<code>Pod.spec</code>中指定了<code>hostname</code>和<code>subdomain</code>，并且<code>subdomain</code>和headleass service的名字相同</strong>，那么kubernetes DNS会额外给这个Pod的FQDN生成A记录：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup mywebsite.headless.default.svc.cluster.local
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>Name:	mywebsite.headless.default.svc.cluster.local
<span class="ln">6</span>Address: 10.189.97.217
</code></pre></div><blockquote>
<p>Pod的FQDN是：<code>{hostname}.{subdomain}.{pod namespace}.svc.{cluster domain}</code></p>
</blockquote>
<h3 id="externalname-service">ExternalName Service</h3>
<p>ExternalName 类型的Service，kubernetes DNS会根据<code>ExternalName</code>字段，为其生成<strong>CNAME记录</strong>，在DNS层进行重定向。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="ln">2</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span><span class="ln">3</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">external</span><span class="w">
</span><span class="ln">5</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="ln">6</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="ln">7</span><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">ExternalName</span><span class="w">
</span><span class="ln">8</span><span class="w">  </span><span class="nt">externalName</span><span class="p">:</span><span class="w"> </span><span class="l">my.example.domain.com</span><span class="w">
</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup external
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>external.default.svc.cluster.local	canonical <span class="nv">name</span> <span class="o">=</span> my.example.domain.com.
<span class="ln">6</span>Name:	my.example.domain.com
<span class="ln">7</span>Address: 66.96.162.92
</code></pre></div>]]></content>
		</item>
		
		<item>
			<title>容器相关知识汇总</title>
			<link>https://cvvz.github.io/post/container/</link>
			<pubDate>Thu, 24 Dec 2020 10:33:00 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/container/</guid>
			<description>容器镜像 容器镜像就是容器的rootfs。通过 Dockerfile 制作容器镜像时，就相当于增加 rootfs 层。通过容器镜像运行一个容器时，操作系统内核先将镜像中的每</description>
			<content type="html"><![CDATA[<h2 id="容器镜像">容器镜像</h2>
<p>容器镜像就是容器的rootfs。通过 Dockerfile 制作容器镜像时，就相当于增加 rootfs 层。通过容器镜像运行一个容器时，操作系统内核先将镜像中的每一层<strong>联合挂载</strong>在一个统一的目录下，然后再通过<code>chroot</code>把容器的根目录挂载到这个统一的目录下。</p>
<p>通过 Dockerfile 生成容器镜像时，每个原语执行后，都会生成一个对应的镜像层。需要注意的是，即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，<strong>这个层是空的</strong>。</p>
<p>Docker 中最常用的联合文件系统有三种：<code>AUFS</code>、<code>Devicemapper</code> 和 <code>OverlayFS</code>。</p>
<blockquote>
<p>overlay2 文件系统最多支持 128 个层数叠加，换句话说 Dockerfile 最多只能写 128 行。</p>
</blockquote>
<h2 id="namespace">namespace</h2>
<p>通过查看宿主机上的 <code>/proc/${pid}/ns</code> 目录可以知道容器进程当前的namespace。同一个Pod下的容器，共享哪些namespace呢？看一眼就知道了：</p>
<figure>
    <img src="/namespace.png" width="650px"/> 
</figure>

<p>可以看出：</p>
<ul>
<li>不共享的namespace是：mnt（挂载点）、pid（进程号）和uts（主机名）</li>
<li>共享的namespace是：ipc（进程间通信）、net（网络）和user（用户）。</li>
</ul>
<p>我用 <code> kubectl exec -it ${pod} -c ${container} -n ${ns} -- sh</code> 命令运行的sh进程，它的namespace和我指定的<code>${container}</code>容器一模一样。<code>kubectl exec</code> 本质上是通过<code>setns</code>系统调用加入了指定进程的namespace。</p>
<figure>
    <img src="/exec-namespace.png" width="650px"/> 
</figure>

<h2 id="cgroups">cgroups</h2>
<h3 id="cpu-cgroup">cpu cgroup</h3>
<ul>
<li>
<p>cpu.cfs_period_us：CFS（Completely Fair Scheduler）调度算法的一个调度周期</p>
</li>
<li>
<p>cpu.cfs_quota_us：CFS 调度算法中，在一个调度周期里这个控制组被允许的运行时间</p>
</li>
<li>
<p>cpu.shares：这个值决定了 CPU Cgroup 下控制组可用 CPU 的相对比例。<strong>不过只有当系统上 CPU 完全被占满的时候，这个比例才会在各个控制组间起作用</strong>。</p>
<blockquote>
<p><code>cpu.cfs_quota_us</code> / <code>cpu.cfs_period_us</code> 的值就限制了容器进程的最大cpu使用率。</p>
<p>在操作系统里，<code>cpu.cfs_period_us</code> 的值一般是个固定值，所以在kubernetes中，当你设置了Pod的<code>limits.cpu</code>的值后，kubelet会去修改cgroup中的<code>cpu.cfs_quota_us</code>这个参数来调整容器cpu的使用上限。</p>
<p>在kubernetes中，当设置了 Pod的<code>requests.cpu</code> 的值时，kubelet会去调整 <code>cpu.shares</code> 这个参数，来保证即使节点cpu使用率被打满了，容器仍然能分得一定量的cpu时间。（cpu.shares = 1024 表示 1 个 CPU）</p>
</blockquote>
</li>
</ul>
<h3 id="cpu-cgroup-和-cpu-使用率">cpu cgroup 和 cpu 使用率</h3>
<p>cpu时间的使用类型如下图所示：</p>
<figure>
    <img src="/cpu-usage.jpeg" width="650px"/> 
</figure>

<p>对于进程的 CPU 使用率，只包含两部分:</p>
<ul>
<li>一个是用户态， us 和 ni；</li>
<li>还有一部分是内核态，也就是 sy。</li>
</ul>
<p>至于 wa、hi、si，这些 I/O 或者中断相关的 CPU 使用，CPU Cgroup 不会去做限制。因为本身这些也不属于某个进程的cpu时间。</p>
<p>于是就要提到 cpu 使用率和 cpu 平均负载的区别了：</p>
<ul>
<li>cpu使用率是进程使用cpu的时间，包括用户态和内核态的时间之和。</li>
<li>cpu平均负载≈CPU可运行队列中的进程数+<strong>CPU休眠队列中不可中断状态的进程数</strong>。</li>
</ul>
<p>当节点上处于D状态的进程数量变多的时候，cpu的平均负载会升高，此时大量进程排队竞争disk I/O资源，但cpu可运行队列中的进程数却很少，所以虽然使用率很低，但是仍然会拖慢进程速度。</p>
<p>cpu cgroup能限制cpu的使用率，但是cpu cgroup并没有办法解决平均负载升高的问题。</p>
<p>我们可以做的是，在生产环境中监控容器的宿主机节点里 D 状态的进程数量，然后对 D 状态进程数目异常的节点进行分析，比如磁盘硬件出现问题引起 D 状态进程数目增加，这时就需要更换硬盘。</p>
<h3 id="cpuset-cgroup">cpuset cgroup</h3>
<p>cpuset cgroup用于进程绑核，主要通过设置<code>cpuset.cpus</code>和<code>cpuset.mems</code>两个字段来实现。</p>
<p>在kubernetes中，当 Pod 属于 Guaranteed QoS 类型，并且 requests 值与 limits 被设置为同一个相等的<strong>整数值</strong>就相当于声明Pod中的容器要进行绑核。</p>
<h3 id="memory-cgroup">memory cgroup</h3>
<ul>
<li>memory.limit_in_bytes：一个控制组里所有进程可使用内存的最大值。一旦达到了这个值，可能会触发OOM。
<blockquote>
<p>在kubernetes中，当你指定了 Pod 的 <code>limits.memory=128Mi</code> 之后，相当于将 memory cgroup 中的 <code>memory.limit_in_bytes</code> 字段 设置为 128 * 1024 * 1024</p>
</blockquote>
</li>
<li>memory.usage_in_bytes：当前控制组里所有进程实际使用的内存总和，<strong>包括rss和page cache两部分</strong>。</li>
<li>memory.oom_control：决定了内存使用达到上限时，会不会触发OOM Killer。触发OOM时，会选择控制组里的某个进程杀掉。</li>
<li>memory.stat：显示了各种内存类型的实际开销。<strong>其中&quot;cache&quot;代表page cache；&ldquo;rss&quot;代表进程真正申请到的物理内存大小。RSS 内存和 Page Cache 内存的和，等于<code>memory.usage_in_bytes</code> 的值</strong>。判断容器真实的内存使用量，我们不能用<code>memory.usage_in_bytes</code>，而需要用 <code>memory.stat</code> 里的 rss 值。</li>
<li>memory.swappiness：定义Page Cache 内存和匿名内存释放的比例。</li>
</ul>
<blockquote>
<p>Q：当执行 <code>kubectl exec</code> 时，创建的进程会加入到容器的cgroup控制组吗？</p>
<p>A：会。以cpu cgroup为例，查看<code>/sys/fs/cgroup/cpu/kubepods.slice/kubepods-pod{$uid}.slice/docker-{$containerID}.scope/tasks</code>文件就能发现新创建的进程被加入到容器的cgroup控制组了。</p>
<p>Q：执行 <code>kubectl top</code> 命令获取到的pod指标是从哪里来的？</p>
<p>A：整个执行路径是：<code>kubectl -&gt; apiserver -&gt; aggregated-apiserver -&gt; metric-server -&gt; kubelet(cAdvisor) -&gt; cgroup</code>。最终来源就是cgroup。而Linux <code>top</code>命令的指标数据的来源是<code>/proc</code>文件系统。</p>
</blockquote>
<h2 id="kubeletdockercrioci">kubelet、Docker、CRI、OCI</h2>
<p>docker 架构图如下图所示：</p>
<figure>
    <img src="/docker.png" width="800px"/> 
</figure>

<p>kubelet和docker的集成方案：</p>
<figure>
    <img src="/kubelet-docker.png" width="800px"/> 
</figure>

<p>从这两幅图就能看出来，当前在kubernetes中，创建一个容器的调用链为：</p>
<p><code>kubelet -&gt; dockershim -&gt; docker daemon -&gt; containerd -&gt; containerd-shim -&gt; runc -&gt; container</code></p>
<p>dockershim实现了<a href="https://github.com/kubernetes/kubernetes/blob/8327e433590f9e867b1e31a4dc32316685695729/pkg/kubelet/apis/cri/services.go">CRI</a>定义的gRPC接口，实现方式就是充当docker daemon的客户端，向docker daemon发送命令。实际上dockershim和docker daemon都可以被干掉，<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#deprecation">kubernetes在v1.20也的确这么做了</a>。docker从kubernetes中被移除后，我们可以直接使用<a href="https://github.com/containerd/containerd">containerd</a>或<a href="https://github.com/cri-o/cri-o">CRI-O</a>作为CRI。</p>
<p><a href="https://github.com/opencontainers/runc">runC</a>则是一个<a href="https://github.com/opencontainers/runtime-spec">OCI</a>的参考实现，底层通过Linux系统调用为容器设置 namespaces 和 cgroups, 挂载 rootfs。当然kubernetes其实不关心OCI的底层是怎么实现的，只要能保证遵循OCI文档里的标准，就能自己实现一个OCI。<a href="https://github.com/kata-containers/kata-containers">Kata</a>就是遵循了OCI标准实现的安全容器。它的底层是用虚拟机实现的资源强隔离，而不是namespace。</p>
<p>Kata中的VM可以和Pod做一个类比：</p>
<ul>
<li>kubelet调用CRI的<code>RunPodSandbox</code>接口时，如果是runC实现的OCI，则会去创建<code>infra</code>容器，并执行<code>/pause</code>将容器挂起；如果是Kata，则会去创建一个虚拟机。</li>
<li>接着kubelet调用<code>CreateContainer</code>去创建容器，对于runC，就是创建容器进程并将他们的namespace加入<code>infra</code>容器中去；对于Kata，则是往VM中添加容器。</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>为什么删除Pod时webhook收到三次delete请求</title>
			<link>https://cvvz.github.io/post/k8s-3-deletion-webhook/</link>
			<pubDate>Sun, 13 Dec 2020 19:26:15 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-3-deletion-webhook/</guid>
			<description>最近在玩admission webhook时，发现一个奇怪的现象：我配置了validatingWebhookConfiguration使其监</description>
			<content type="html"><![CDATA[<p>最近在玩admission webhook时，发现一个奇怪的现象：我配置了validatingWebhookConfiguration使其监听pod的删除操作，结果发现每次删除Pod的时候，webhook会收到三次delete请求：</p>
<figure>
    <img src="/3-delete.png" width="1000px"/> 
</figure>

<p>从日志打印上可以分析出，第一次删除请求来自于kubectl客户端，后面两次来自于pod所在的node节点。为什么会收到三次delete请求呢？</p>
<h2 id="删除一个pod的过程">删除一个Pod的过程</h2>
<p>通过阅读kube-apiserver和kubelet源码，我把一个pod的删除过程总结成如下这幅流程图，三个红色加粗的请求即为webhook收到的三次delete请求。
<figure>
    <img src="/delete-pod.drawio.svg" width="800px"/> 
</figure>
</p>
<h3 id="kube-apiserver处理第一次删除请求">kube-apiserver处理第一次删除请求</h3>
<p>首先，由kubectl发来的delete请求，会经过kube-apiserver的admission-controller进行准入校验。我们定义了admission webhook，所以kube-apiserver会将该请求相关的信息封装在<strong>AdmissionReview</strong>结构体中发送给webhook。这是第一次webhook收到delete请求。</p>
<p>kube-apiserver作为一个http服务器，它的handler在<code>staging/src/k8s.io/apiserver/pkg/endpoints/installer.go</code>文件中的<code>registerResourceHandlers</code>函数中定义。其中<code>DELETE</code>请求的handler是<code>restfulDeleteResource</code>：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln">1</span><span class="k">case</span> <span class="s">&#34;DELETE&#34;</span><span class="p">:</span> <span class="c1">// Delete a resource.
</span><span class="ln">2</span><span class="c1"></span>    <span class="c1">// ...
</span><span class="ln">3</span><span class="c1"></span>
<span class="ln">4</span>    <span class="nx">handler</span> <span class="o">:=</span> <span class="nx">metrics</span><span class="p">.</span><span class="nf">InstrumentRouteFunc</span><span class="p">(</span><span class="nx">action</span><span class="p">.</span><span class="nx">Verb</span><span class="p">,</span> <span class="nx">group</span><span class="p">,</span> <span class="nx">version</span><span class="p">,</span> <span class="nx">resource</span><span class="p">,</span> <span class="nx">subresource</span><span class="p">,</span> <span class="nx">requestScope</span><span class="p">,</span> <span class="nx">metrics</span><span class="p">.</span><span class="nx">APIServerComponent</span><span class="p">,</span> <span class="nx">deprecated</span><span class="p">,</span> <span class="nx">removedRelease</span><span class="p">,</span> <span class="nf">restfulDeleteResource</span><span class="p">(</span><span class="nx">gracefulDeleter</span><span class="p">,</span> <span class="nx">isGracefulDeleter</span><span class="p">,</span> <span class="nx">reqScope</span><span class="p">,</span> <span class="nx">admit</span><span class="p">))</span>
<span class="ln">5</span>
<span class="ln">6</span>    <span class="o">...</span>
</code></pre></div><p><code>restfulDeleteResource</code>调用<code>DeleteResource</code>，后者则调用<code>staging/src/k8s.io/apiserver/pkg/registry/generic/registry/store.go</code>文件中的<code>Delete</code>方法对对象进行删除</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln">1</span><span class="kd">func</span> <span class="nf">restfulDeleteResource</span><span class="p">(</span><span class="nx">r</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">GracefulDeleter</span><span class="p">,</span> <span class="nx">allowsOptions</span> <span class="kt">bool</span><span class="p">,</span> <span class="nx">scope</span> <span class="nx">handlers</span><span class="p">.</span><span class="nx">RequestScope</span><span class="p">,</span> <span class="nx">admit</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Interface</span><span class="p">)</span> <span class="nx">restful</span><span class="p">.</span><span class="nx">RouteFunction</span> <span class="p">{</span>
<span class="ln">2</span>	<span class="k">return</span> <span class="kd">func</span><span class="p">(</span><span class="nx">req</span> <span class="o">*</span><span class="nx">restful</span><span class="p">.</span><span class="nx">Request</span><span class="p">,</span> <span class="nx">res</span> <span class="o">*</span><span class="nx">restful</span><span class="p">.</span><span class="nx">Response</span><span class="p">)</span> <span class="p">{</span>
<span class="ln">3</span>		<span class="nx">handlers</span><span class="p">.</span><span class="nf">DeleteResource</span><span class="p">(</span><span class="nx">r</span><span class="p">,</span> <span class="nx">allowsOptions</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">scope</span><span class="p">,</span> <span class="nx">admit</span><span class="p">)(</span><span class="nx">res</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">req</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span>
<span class="ln">4</span>	<span class="p">}</span>
<span class="ln">5</span><span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="nf">DeleteResource</span><span class="p">(</span><span class="nx">r</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">GracefulDeleter</span><span class="p">,</span> <span class="nx">allowsOptions</span> <span class="kt">bool</span><span class="p">,</span> <span class="nx">scope</span> <span class="o">*</span><span class="nx">RequestScope</span><span class="p">,</span> <span class="nx">admit</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Interface</span><span class="p">)</span> <span class="nx">http</span><span class="p">.</span><span class="nx">HandlerFunc</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="c1">//...
</span><span class="ln"> 3</span><span class="c1"></span>
<span class="ln"> 4</span>    <span class="nx">trace</span><span class="p">.</span><span class="nf">Step</span><span class="p">(</span><span class="s">&#34;About to delete object from database&#34;</span><span class="p">)</span>
<span class="ln"> 5</span>		<span class="nx">wasDeleted</span> <span class="o">:=</span> <span class="kc">true</span>
<span class="ln"> 6</span>		<span class="nx">userInfo</span><span class="p">,</span> <span class="nx">_</span> <span class="o">:=</span> <span class="nx">request</span><span class="p">.</span><span class="nf">UserFrom</span><span class="p">(</span><span class="nx">ctx</span><span class="p">)</span>
<span class="ln"> 7</span>		<span class="nx">staticAdmissionAttrs</span> <span class="o">:=</span> <span class="nx">admission</span><span class="p">.</span><span class="nf">NewAttributesRecord</span><span class="p">(</span><span class="kc">nil</span><span class="p">,</span> <span class="kc">nil</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Kind</span><span class="p">,</span> <span class="nx">namespace</span><span class="p">,</span> <span class="nx">name</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Resource</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Subresource</span><span class="p">,</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Delete</span><span class="p">,</span> <span class="nx">options</span><span class="p">,</span> <span class="nx">dryrun</span><span class="p">.</span><span class="nf">IsDryRun</span><span class="p">(</span><span class="nx">options</span><span class="p">.</span><span class="nx">DryRun</span><span class="p">),</span> <span class="nx">userInfo</span><span class="p">)</span>
<span class="ln"> 8</span>		<span class="nx">result</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nf">finishRequest</span><span class="p">(</span><span class="nx">timeout</span><span class="p">,</span> <span class="kd">func</span><span class="p">()</span> <span class="p">(</span><span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 9</span>			<span class="nx">obj</span><span class="p">,</span> <span class="nx">deleted</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">r</span><span class="p">.</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">name</span><span class="p">,</span> <span class="nx">rest</span><span class="p">.</span><span class="nf">AdmissionToValidateObjectDeleteFunc</span><span class="p">(</span><span class="nx">admit</span><span class="p">,</span> <span class="nx">staticAdmissionAttrs</span><span class="p">,</span> <span class="nx">scope</span><span class="p">),</span> <span class="nx">options</span><span class="p">)</span>
<span class="ln">10</span>			<span class="nx">wasDeleted</span> <span class="p">=</span> <span class="nx">deleted</span>
<span class="ln">11</span>			<span class="k">return</span> <span class="nx">obj</span><span class="p">,</span> <span class="nx">err</span>
<span class="ln">12</span>		<span class="p">})</span>
<span class="ln">13</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">14</span>			<span class="nx">scope</span><span class="p">.</span><span class="nf">err</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">w</span><span class="p">,</span> <span class="nx">req</span><span class="p">)</span>
<span class="ln">15</span>			<span class="k">return</span>
<span class="ln">16</span>		<span class="p">}</span>
<span class="ln">17</span>        <span class="nx">trace</span><span class="p">.</span><span class="nf">Step</span><span class="p">(</span><span class="s">&#34;Object deleted from database&#34;</span><span class="p">)</span>
<span class="ln">18</span>        
<span class="ln">19</span>        <span class="o">...</span>
<span class="ln">20</span><span class="p">}</span>
</code></pre></div><p><code>Delete</code>方法中，在<code>BeforeDelete</code>函数中判断是否需要优雅删除，判断的标准是<code>DeletionGracePeriodSeconds</code>值是否为0，不为零则认为是优雅删除，kube-apiserver不会立即将这个API对象从etcd中删除，否则直接删除。</p>
<p>对于Pod而言，默认<code>DeletionGracePeriodSeconds</code>为30秒，因此这里不会被kube-apiserver立刻删除掉。而是将<code>DeletionTimestamp</code>设置为当前时间，<code>DeletionGracePeriodSeconds</code>设置为默认值30秒。</p>
<h3 id="kubelet杀掉容器">kubelet杀掉容器</h3>
<p>kube-apiserver设置好<code>DeletionTimestamp</code>和<code>DeletionGracePeriodSeconds</code>这两个字段后，kubelet 会watch到Pod的更新。那kubelet list-watch机制又是怎么实现的呢？</p>
<p>Kubelet在<code>makePodSourceConfig</code>函数中，监听了三种类型的Pod：通过<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/static-pod/#configuration-files">文件系统上的配置文件</a>配置的静态Pod，通过<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/static-pod/#pods-created-via-http">web 网络上的配置文件</a>配置的静态Pod，以及kube-apiserver中的pod。我们主要关心第三种。</p>
<p>Kubelet通过reflactor watch到Pod资源发生变化后，是通过channel的方式将Pod及其变化传递给syncLoop主控制循环中进行处理的，<strong>并没有使用informer+workqueque的方式</strong>。</p>
<p>kubelet的主控制循环在<code>pkg/kubelet/kubelet.go</code>文件中的<code>syncLoopIteration</code>函数：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">kl</span> <span class="o">*</span><span class="nx">Kubelet</span><span class="p">)</span> <span class="nf">syncLoopIteration</span><span class="p">(</span><span class="nx">configCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">PodUpdate</span><span class="p">,</span> <span class="nx">handler</span> <span class="nx">SyncHandler</span><span class="p">,</span>
<span class="ln"> 2</span>	<span class="nx">syncCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Time</span><span class="p">,</span> <span class="nx">housekeepingCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Time</span><span class="p">,</span> <span class="nx">plegCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="o">*</span><span class="nx">pleg</span><span class="p">.</span><span class="nx">PodLifecycleEvent</span><span class="p">)</span> <span class="kt">bool</span> <span class="p">{</span>
<span class="ln"> 3</span>	<span class="k">select</span> <span class="p">{</span>
<span class="ln"> 4</span>	<span class="k">case</span> <span class="nx">u</span><span class="p">,</span> <span class="nx">open</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="nx">configCh</span><span class="p">:</span>
<span class="ln"> 5</span>		<span class="c1">// Update from a config source; dispatch it to the right handler
</span><span class="ln"> 6</span><span class="c1"></span>		<span class="c1">// callback.
</span><span class="ln"> 7</span><span class="c1"></span>		<span class="k">if</span> <span class="p">!</span><span class="nx">open</span> <span class="p">{</span>
<span class="ln"> 8</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Update channel is closed. Exiting the sync loop.&#34;</span><span class="p">)</span>
<span class="ln"> 9</span>			<span class="k">return</span> <span class="kc">false</span>
<span class="ln">10</span>		<span class="p">}</span>
<span class="ln">11</span>
<span class="ln">12</span>		<span class="k">switch</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Op</span> <span class="p">{</span>
<span class="ln">13</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">ADD</span><span class="p">:</span>
<span class="ln">14</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (ADD, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">15</span>			<span class="c1">// After restarting, kubelet will get all existing pods through
</span><span class="ln">16</span><span class="c1"></span>			<span class="c1">// ADD as if they are new pods. These pods will then go through the
</span><span class="ln">17</span><span class="c1"></span>			<span class="c1">// admission process and *may* be rejected. This can be resolved
</span><span class="ln">18</span><span class="c1"></span>			<span class="c1">// once we have checkpointing.
</span><span class="ln">19</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodAdditions</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">20</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">UPDATE</span><span class="p">:</span>
<span class="ln">21</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (UPDATE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">PodsWithDeletionTimestamps</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">22</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodUpdates</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">23</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">REMOVE</span><span class="p">:</span>
<span class="ln">24</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (REMOVE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">25</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodRemoves</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">26</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">RECONCILE</span><span class="p">:</span>
<span class="ln">27</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">4</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (RECONCILE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">28</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodReconcile</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">29</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">DELETE</span><span class="p">:</span>
<span class="ln">30</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (DELETE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">31</span>			<span class="c1">// DELETE is treated as a UPDATE because of graceful deletion.
</span><span class="ln">32</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodUpdates</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">33</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">RESTORE</span><span class="p">:</span>
<span class="ln">34</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (RESTORE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">35</span>			<span class="c1">// These are pods restored from the checkpoint. Treat them as new
</span><span class="ln">36</span><span class="c1"></span>			<span class="c1">// pods.
</span><span class="ln">37</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodAdditions</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">38</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">SET</span><span class="p">:</span>
<span class="ln">39</span>			<span class="c1">// TODO: Do we want to support this?
</span><span class="ln">40</span><span class="c1"></span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Kubelet does not support snapshot update&#34;</span><span class="p">)</span>
<span class="ln">41</span>        <span class="p">}</span>
<span class="ln">42</span>
<span class="ln">43</span>        <span class="o">...</span>
</code></pre></div><p>当Pod的<code>DeletionTimestamp</code>被设置时，Kubelet会走入<code>kubetypes.DELETE</code>这个分支，最终会调用到<code>pkg/kubelet/kubelet.go</code>中的<code>syncPod</code>函数，<strong><code>syncPod</code> 这个函数是 kubelet 核心处理函数</strong>。这个函数会调用到容器运行时的<code>KillPod</code>方法，该方法进而又会以goroutine的方式，使用<code>pkg/kubelet/kuberuntime/kuberuntime_container.go</code>中定义的<code>killContainer</code>方法<strong>并行的杀掉</strong>所有容器。<code>killContainer</code>的代码实现如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">kubeGenericRuntimeManager</span><span class="p">)</span> <span class="nf">killContainer</span><span class="p">(</span><span class="nx">pod</span> <span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Pod</span><span class="p">,</span> <span class="nx">containerID</span> <span class="nx">kubecontainer</span><span class="p">.</span><span class="nx">ContainerID</span><span class="p">,</span> <span class="nx">containerName</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">message</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">gracePeriodOverride</span> <span class="o">*</span><span class="kt">int64</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
<span class="ln"> 2</span>	<span class="o">...</span>
<span class="ln"> 3</span>
<span class="ln"> 4</span>	<span class="c1">// From this point, pod and container must be non-nil.
</span><span class="ln"> 5</span><span class="c1"></span>	<span class="nx">gracePeriod</span> <span class="o">:=</span> <span class="nb">int64</span><span class="p">(</span><span class="nx">minimumGracePeriodInSeconds</span><span class="p">)</span>
<span class="ln"> 6</span>	<span class="k">switch</span> <span class="p">{</span>
<span class="ln"> 7</span>	<span class="k">case</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">DeletionGracePeriodSeconds</span> <span class="o">!=</span> <span class="kc">nil</span><span class="p">:</span>
<span class="ln"> 8</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">pod</span><span class="p">.</span><span class="nx">DeletionGracePeriodSeconds</span>
<span class="ln"> 9</span>	<span class="k">case</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">Spec</span><span class="p">.</span><span class="nx">TerminationGracePeriodSeconds</span> <span class="o">!=</span> <span class="kc">nil</span><span class="p">:</span>
<span class="ln">10</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">pod</span><span class="p">.</span><span class="nx">Spec</span><span class="p">.</span><span class="nx">TerminationGracePeriodSeconds</span>
<span class="ln">11</span>	<span class="p">}</span>
<span class="ln">12</span>
<span class="ln">13</span>	<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nx">message</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
<span class="ln">14</span>		<span class="nx">message</span> <span class="p">=</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Sprintf</span><span class="p">(</span><span class="s">&#34;Stopping container %s&#34;</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Name</span><span class="p">)</span>
<span class="ln">15</span>	<span class="p">}</span>
<span class="ln">16</span>	<span class="nx">m</span><span class="p">.</span><span class="nf">recordContainerEvent</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">,</span> <span class="nx">v1</span><span class="p">.</span><span class="nx">EventTypeNormal</span><span class="p">,</span> <span class="nx">events</span><span class="p">.</span><span class="nx">KillingContainer</span><span class="p">,</span> <span class="nx">message</span><span class="p">)</span>
<span class="ln">17</span>
<span class="ln">18</span>	<span class="c1">// Run internal pre-stop lifecycle hook
</span><span class="ln">19</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">internalLifecycle</span><span class="p">.</span><span class="nf">PreStopContainer</span><span class="p">(</span><span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">20</span>		<span class="k">return</span> <span class="nx">err</span>
<span class="ln">21</span>	<span class="p">}</span>
<span class="ln">22</span>
<span class="ln">23</span>	<span class="c1">// Run the pre-stop lifecycle hooks if applicable and if there is enough time to run it
</span><span class="ln">24</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Lifecycle</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Lifecycle</span><span class="p">.</span><span class="nx">PreStop</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="nx">gracePeriod</span> <span class="p">&gt;</span> <span class="mi">0</span> <span class="p">{</span>
<span class="ln">25</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="nx">gracePeriod</span> <span class="o">-</span> <span class="nx">m</span><span class="p">.</span><span class="nf">executePreStopHook</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">26</span>	<span class="p">}</span>
<span class="ln">27</span>	<span class="c1">// always give containers a minimal shutdown window to avoid unnecessary SIGKILLs
</span><span class="ln">28</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">gracePeriod</span> <span class="p">&lt;</span> <span class="nx">minimumGracePeriodInSeconds</span> <span class="p">{</span>
<span class="ln">29</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="nx">minimumGracePeriodInSeconds</span>
<span class="ln">30</span>	<span class="p">}</span>
<span class="ln">31</span>	<span class="k">if</span> <span class="nx">gracePeriodOverride</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">32</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">gracePeriodOverride</span>
<span class="ln">33</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Killing container %q, but using %d second grace period override&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">34</span>	<span class="p">}</span>
<span class="ln">35</span>
<span class="ln">36</span>	<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Killing container %q with %d second grace period&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">(),</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">37</span>
<span class="ln">38</span>	<span class="nx">err</span> <span class="o">:=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">runtimeService</span><span class="p">.</span><span class="nf">StopContainer</span><span class="p">(</span><span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">39</span>	<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">40</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Container %q termination failed with gracePeriod %d: %v&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">(),</span> <span class="nx">gracePeriod</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
<span class="ln">41</span>	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
<span class="ln">42</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Container %q exited normally&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">())</span>
<span class="ln">43</span>	<span class="p">}</span>
<span class="ln">44</span>
<span class="ln">45</span>	<span class="nx">m</span><span class="p">.</span><span class="nx">containerRefManager</span><span class="p">.</span><span class="nf">ClearRef</span><span class="p">(</span><span class="nx">containerID</span><span class="p">)</span>
<span class="ln">46</span>
<span class="ln">47</span>	<span class="k">return</span> <span class="nx">err</span>
<span class="ln">48</span><span class="p">}</span>  
</code></pre></div><p>这个方法就是先调用prestop hook，然后在通过<code>runtimeService.StopContainer</code>方法杀掉容器进程，整个过程总时长不能超过<code>DeletionGracePeriodSeconds</code>。注意，prestop hook是不会进行重试的，失败了kubelet也不管，容器还是照杀不误。</p>
<h3 id="statusmanager发送删除请求">statusManager发送删除请求</h3>
<p>kubelet以goroutine的方式运行着一个<code>statusManager</code>，它的作用就是周期性的监听Pod的状态变化，然后执行<code>func (m *manager) syncPod(uid types.UID, status versionedPodStatus) {</code>。在<code>syncPod</code>中，注意到有如下的逻辑：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">manager</span><span class="p">)</span> <span class="nf">syncPod</span><span class="p">(</span><span class="nx">uid</span> <span class="nx">types</span><span class="p">.</span><span class="nx">UID</span><span class="p">,</span> <span class="nx">status</span> <span class="nx">versionedPodStatus</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>
<span class="ln"> 4</span>    <span class="k">if</span> <span class="nx">m</span><span class="p">.</span><span class="nf">canBeDeleted</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">status</span><span class="p">.</span><span class="nx">status</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 5</span>		<span class="nx">deleteOptions</span> <span class="o">:=</span> <span class="nx">metav1</span><span class="p">.</span><span class="nx">DeleteOptions</span><span class="p">{</span>
<span class="ln"> 6</span>			<span class="nx">GracePeriodSeconds</span><span class="p">:</span> <span class="nb">new</span><span class="p">(</span><span class="kt">int64</span><span class="p">),</span>
<span class="ln"> 7</span>			<span class="c1">// Use the pod UID as the precondition for deletion to prevent deleting a
</span><span class="ln"> 8</span><span class="c1"></span>			<span class="c1">// newly created pod with the same name and namespace.
</span><span class="ln"> 9</span><span class="c1"></span>			<span class="nx">Preconditions</span><span class="p">:</span> <span class="nx">metav1</span><span class="p">.</span><span class="nf">NewUIDPreconditions</span><span class="p">(</span><span class="nb">string</span><span class="p">(</span><span class="nx">pod</span><span class="p">.</span><span class="nx">UID</span><span class="p">)),</span>
<span class="ln">10</span>		<span class="p">}</span>
<span class="ln">11</span>		<span class="nx">err</span> <span class="p">=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">kubeClient</span><span class="p">.</span><span class="nf">CoreV1</span><span class="p">().</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">pod</span><span class="p">.</span><span class="nx">Namespace</span><span class="p">).</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">TODO</span><span class="p">(),</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">Name</span><span class="p">,</span> <span class="nx">deleteOptions</span><span class="p">)</span>
<span class="ln">12</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">13</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Warningf</span><span class="p">(</span><span class="s">&#34;Failed to delete status for pod %q: %v&#34;</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pod</span><span class="p">(</span><span class="nx">pod</span><span class="p">),</span> <span class="nx">err</span><span class="p">)</span>
<span class="ln">14</span>			<span class="k">return</span>
<span class="ln">15</span>		<span class="p">}</span>
<span class="ln">16</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Pod %q fully terminated and removed from etcd&#34;</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pod</span><span class="p">(</span><span class="nx">pod</span><span class="p">))</span>
<span class="ln">17</span>		<span class="nx">m</span><span class="p">.</span><span class="nf">deletePodStatus</span><span class="p">(</span><span class="nx">uid</span><span class="p">)</span>
<span class="ln">18</span>	<span class="p">}</span>
<span class="ln">19</span><span class="p">}</span>
</code></pre></div><p>也就是说，<strong><code>statusManager</code>发现Pod可以被删除的时候，就会去调用clientset的delete接口将Pod资源从kube-apiserver中删掉</strong>。那什么时候Pod可以被删除呢？自然是在上一步中，kubelet将Pod的容器、卷、cgroup sandbox等资源统统删除掉，就可以被删除了。</p>
<p>这里，webhook就会收到第二次删除请求，而且这次请求中，将<code>GracePeriodSeconds</code>设置为了0，这就代表着kube-apiserver收到这个DELETE请求后，可以将Pod从etcd中删除了。</p>
<h3 id="第三次delete请求">第三次delete请求</h3>
<p>webhook为什么会收到第三次delete请求，这个问题着实困扰了我很久。</p>
<p>从日志的serviceAccount的信息来看，很像是节点上的组件又发了一次DELETE请求。是kubelet吗？还是kube-proxy？但是查看相关日志和代码，没有发现任何可疑点。</p>
<p>其实，第三次DELETE请求是kube-apiserver自己发的。</p>
<p>在第一部分中，我提到kube-apiserver收到DELETE请求后最终会调用<code>staging/src/k8s.io/apiserver/pkg/registry/generic/registry/store.go</code>文件中的<code>Delete</code>方法，然后由于走的是优雅删除，它更新完Pod的<code>DeletionTimestamp</code>和<code>DeletionGracePeriodSeconds</code>两个字段后，就返回了。</p>
<p>现在，第二次DELETE请求将<code>GracePeriodSeconds</code>设置为了0，于是现在可以开始执行实际的删除操作了。</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">e</span> <span class="o">*</span><span class="nx">Store</span><span class="p">)</span> <span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span> <span class="nx">context</span><span class="p">.</span><span class="nx">Context</span><span class="p">,</span> <span class="nx">name</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">deleteValidation</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">ValidateObjectFunc</span><span class="p">,</span> <span class="nx">options</span> <span class="o">*</span><span class="nx">metav1</span><span class="p">.</span><span class="nx">DeleteOptions</span><span class="p">)</span> <span class="p">(</span><span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="kt">bool</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>    <span class="c1">// delete immediately, or no graceful deletion supported
</span><span class="ln"> 4</span><span class="c1"></span>    <span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">6</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;going to delete %s from registry: &#34;</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span>
<span class="ln"> 5</span>    <span class="nx">out</span> <span class="p">=</span> <span class="nx">e</span><span class="p">.</span><span class="nf">NewFunc</span><span class="p">()</span>
<span class="ln"> 6</span>    <span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">Storage</span><span class="p">.</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">key</span><span class="p">,</span> <span class="nx">out</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">preconditions</span><span class="p">,</span> <span class="nx">storage</span><span class="p">.</span><span class="nf">ValidateObjectFunc</span><span class="p">(</span><span class="nx">deleteValidation</span><span class="p">),</span> <span class="nx">dryrun</span><span class="p">.</span><span class="nf">IsDryRun</span><span class="p">(</span><span class="nx">options</span><span class="p">.</span><span class="nx">DryRun</span><span class="p">));</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 7</span>        <span class="c1">// Please refer to the place where we set ignoreNotFound for the reason
</span><span class="ln"> 8</span><span class="c1"></span>        <span class="c1">// why we ignore the NotFound error .
</span><span class="ln"> 9</span><span class="c1"></span>        <span class="k">if</span> <span class="nx">storage</span><span class="p">.</span><span class="nf">IsNotFound</span><span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="nx">ignoreNotFound</span> <span class="o">&amp;&amp;</span> <span class="nx">lastExisting</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">10</span>            <span class="c1">// The lastExisting object may not be the last state of the object
</span><span class="ln">11</span><span class="c1"></span>            <span class="c1">// before its deletion, but it&#39;s the best approximation.
</span><span class="ln">12</span><span class="c1"></span>            <span class="nx">out</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">e</span><span class="p">.</span><span class="nf">finalizeDelete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">lastExisting</span><span class="p">,</span> <span class="kc">true</span><span class="p">)</span>
<span class="ln">13</span>            <span class="k">return</span> <span class="nx">out</span><span class="p">,</span> <span class="kc">true</span><span class="p">,</span> <span class="nx">err</span>
<span class="ln">14</span>        <span class="p">}</span>
<span class="ln">15</span>        <span class="k">return</span> <span class="kc">nil</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="nx">storeerr</span><span class="p">.</span><span class="nf">InterpretDeleteError</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">qualifiedResource</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span>
<span class="ln">16</span>    <span class="p">}</span>
<span class="ln">17</span>    <span class="o">...</span>
<span class="ln">18</span><span class="p">}</span>
</code></pre></div><p>在<code>e.Storage.Delete</code>方法中，定义了<code>storage.ValidateObjectFunc(deleteValidation)</code>参数，仔细阅读这个方法的实现细节，原来，kube-apiserver在进行删除前，还会再对这个删除操作执行一次准入控制校验，即Validating和Mutating。代码逻辑见<code>staging/src/k8s.io/apiserver/pkg/storage/etcd3/store.go</code>中的<code>conditionalDelete</code>函数：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">s</span> <span class="o">*</span><span class="nx">store</span><span class="p">)</span> <span class="nf">conditionalDelete</span><span class="p">(</span><span class="nx">ctx</span> <span class="nx">context</span><span class="p">.</span><span class="nx">Context</span><span class="p">,</span> <span class="nx">key</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">out</span> <span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="nx">v</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">Value</span><span class="p">,</span> <span class="nx">preconditions</span> <span class="o">*</span><span class="nx">storage</span><span class="p">.</span><span class="nx">Preconditions</span><span class="p">,</span> <span class="nx">validateDeletion</span> <span class="nx">storage</span><span class="p">.</span><span class="nx">ValidateObjectFunc</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>    <span class="k">for</span> <span class="p">{</span>
<span class="ln"> 4</span>		<span class="nx">origState</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">s</span><span class="p">.</span><span class="nf">getState</span><span class="p">(</span><span class="nx">getResp</span><span class="p">,</span> <span class="nx">key</span><span class="p">,</span> <span class="nx">v</span><span class="p">,</span> <span class="kc">false</span><span class="p">)</span>
<span class="ln"> 5</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 6</span>			<span class="k">return</span> <span class="nx">err</span>
<span class="ln"> 7</span>		<span class="p">}</span>
<span class="ln"> 8</span>		<span class="k">if</span> <span class="nx">preconditions</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 9</span>			<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">preconditions</span><span class="p">.</span><span class="nf">Check</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">obj</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">10</span>				<span class="k">return</span> <span class="nx">err</span>
<span class="ln">11</span>			<span class="p">}</span>
<span class="ln">12</span>		<span class="p">}</span>
<span class="ln">13</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nf">validateDeletion</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">obj</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">14</span>			<span class="k">return</span> <span class="nx">err</span>
<span class="ln">15</span>		<span class="p">}</span>
<span class="ln">16</span>		<span class="nx">startTime</span> <span class="o">:=</span> <span class="nx">time</span><span class="p">.</span><span class="nf">Now</span><span class="p">()</span>
<span class="ln">17</span>		<span class="nx">txnResp</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">s</span><span class="p">.</span><span class="nx">client</span><span class="p">.</span><span class="nx">KV</span><span class="p">.</span><span class="nf">Txn</span><span class="p">(</span><span class="nx">ctx</span><span class="p">).</span><span class="nf">If</span><span class="p">(</span>
<span class="ln">18</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">Compare</span><span class="p">(</span><span class="nx">clientv3</span><span class="p">.</span><span class="nf">ModRevision</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span> <span class="s">&#34;=&#34;</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">rev</span><span class="p">),</span>
<span class="ln">19</span>		<span class="p">).</span><span class="nf">Then</span><span class="p">(</span>
<span class="ln">20</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">OpDelete</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span>
<span class="ln">21</span>		<span class="p">).</span><span class="nf">Else</span><span class="p">(</span>
<span class="ln">22</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">OpGet</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span>
<span class="ln">23</span>        <span class="p">).</span><span class="nf">Commit</span><span class="p">()</span>
<span class="ln">24</span>    <span class="o">...</span>
<span class="ln">25</span>
<span class="ln">26</span><span class="p">}</span>
</code></pre></div><p>validateDeletion 即为进行DELETE准入控制校验的地方，这个过程中必定会调用到Validating webhook，也就有了第三次delete请求。至于为什么要再做一次准入控制，我也不太明白。</p>
]]></content>
		</item>
		
		<item>
			<title>Kubernetes Volume实现原理</title>
			<link>https://cvvz.github.io/post/k8s-volume/</link>
			<pubDate>Sat, 12 Dec 2020 12:32:33 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-volume/</guid>
			<description>容器运行时挂载卷的过程 如果CRI是通过dockershim实现的话，kubelet通过CRI接口去拉起一个容器，就好比是通过docker-d</description>
			<content type="html"><![CDATA[<h2 id="容器运行时挂载卷的过程">容器运行时挂载卷的过程</h2>
<p>如果CRI是通过dockershim实现的话，kubelet通过CRI接口去拉起一个容器，就好比是通过docker-daemon执行<code>docker run</code>命令。</p>
<p>而如果想要在容器中挂载宿主机目录的话，就要带上<code>-v</code>参数，以下面这条命令为例：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>docker run -v /home:/test ...
</code></pre></div><p>它的具体的实现过程如下：</p>
<ol>
<li>
<p>创建容器进程并开启Mount namespace</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="ln">1</span><span class="kt">int</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">main_function</span><span class="p">,</span> <span class="n">stack_size</span><span class="p">,</span> <span class="n">CLONE_NEWNS</span> <span class="o">|</span> <span class="n">SIGCHLD</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span> 
</code></pre></div></li>
<li>
<p>将宿主机目录挂载到容器进程的目录中来</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="ln">1</span><span class="n">mount</span><span class="p">(</span><span class="s">&#34;/home&#34;</span><span class="p">,</span> <span class="s">&#34;/test&#34;</span><span class="p">,</span> <span class="s">&#34;&#34;</span><span class="p">,</span> <span class="n">MS_BIND</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span>
</code></pre></div><blockquote>
<p>此时虽然开启了mount namespace，只代表主机和容器之间mount点隔离开了，容器仍然可以看到主机的文件系统目录。</p>
</blockquote>
</li>
<li>
<p>调用 <code>pivot_root</code> 或 <code>chroot</code>，改变容器进程的根目录。至此，容器再也看不到宿主机的文件系统目录了。</p>
</li>
</ol>
<h2 id="kubelet挂载卷的过程">kubelet挂载卷的过程</h2>
<p>当一个Pod被调度到一个节点上之后，kubelet首先为这个Pod在宿主机上创建一个Volume目录：</p>
<p><strong>/var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt;</strong>。</p>
<p>在kubernetes中，卷<code>volumes</code>是Pod的一个属性，而不是容器的。kubelet先以Pod为单位，在宿主机这个Volume目录中准备好Pod需要的卷。接着启动容器，容器启动时，根据<code>volumeMounts</code>的定义将主机的这个目录下的部分卷资源挂载进来。挂载的过程如前所述，相当于为每个容器执行了命令：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>docker run -v /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt;:/&lt;容器内的目标目录&gt; 我的镜像 ...
</code></pre></div><p>而kubelet是怎么把卷挂载到主机的volumes目录下的呢？这取决于Volume的类型。</p>
<h3 id="远程块存储">远程块存储</h3>
<ol>
<li>
<p>Attach：将远程磁盘挂载到本地，成为一个主机上的一个块设备，通过<code>lsblk</code>命令可以查看到。</p>
<blockquote>
<p>Attach 这一步，由<code>kube-controller-manager</code>中的<code>Volume Controller</code>负责</p>
</blockquote>
</li>
<li>
<p>Mount：本地有了新的块设备后，先将其格式化为某种文件系统格式后，就可以进行mount操作了。</p>
<blockquote>
<p>Mount 这一步，由kubelet中的<code>VolumeManagerReconciler</code>这个控制循环负责，它是一个独立于kubelet主循环的goroutine。</p>
</blockquote>
</li>
</ol>
<h3 id="nfs">NFS</h3>
<p>NFS本身已经是一个远程的文件系统了，所以可以直接进行mount，相当于执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>mount -t nfs &lt;NFS服务器地址&gt;:/ /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt; 
</code></pre></div><h3 id="hostpath">hostPath</h3>
<p>hostPath类型的挂载方式，和宿主机上的Volume目录没啥关系，就是容器直接挂载指定的宿主机目录。</p>
<h3 id="emptydirdownwardapiconfigmapsecret">emptyDir、downwardAPI、configMap、secret</h3>
<p>这几种挂载方式，数据都会随着Pod的消亡而被删除。原因是kubelet在创建Pod的Volume资源时，其实是在主机的Volume目录下创建了一些子目录供容器进行挂载。Pod被删除时，kubelet也会把这个Volume目录删掉，从而这个Volume目录中的子目录也都被删除，这几种类型的数据就被删掉了。</p>
<blockquote>
<p>远程块存储、NFS存储等持久化的存储，和hostPath、emptyDir、downwardAPI、configMap、secret不一样，<strong>不是在Pod或任何一种workload中的volume字段中直接定义的</strong>，而是在PV中定义的。</p>
</blockquote>
<h2 id="pvcpv和storageclass">PVC、PV和StorageClass</h2>
<p>在Pod中，如果想使用持久化的存储，如上面提到的远程块存储、NFS存储，或是本地块存储（非hostPath），则在volumes字段中，定义<code>persistentVolumeClaim</code>，即PVC。</p>
<p>PVC和PV进行绑定的过程，由<code>Volume Controller</code>中的<code>PersistentVolumeController</code>这个控制循环负责。所谓“绑定”，也就是填写PVC中的<code>spec.volumeName</code>字段而已。<code>PersistentVolumeController</code>只会将StorageClass相同的PVC和PV绑定起来。</p>
<p>StorageClass主要用来动态分配存储(Dynamic Provisioning)。StorageClass中的<code>provisioner</code>字段用于指定使用哪种<a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner">存储插件</a>进行动态分配，当然，前提是你要在kubernetes中装好对应的存储插件。<code>parameters</code>字段就是生成出来的PV的参数。</p>
<blockquote>
<p><code>PersistentVolumeController</code>只是在找不到对应的PV资源和PVC进行绑定时，借助StorageClass生成了一个PV这个API对象。具体这个PV是怎么成为主机volume目录下的一个子目录的，则是靠前面所述的Attach + Mount两阶段处理后的结果。当然如果是NFS或本地持久化卷，就不需要<code>Volume Controller</code>进行Attach操作了。</p>
</blockquote>
<h2 id="本地持久化卷">本地持久化卷</h2>
<p>对于本地持久化卷，通过在PV模版中</p>
<ul>
<li>定义<code>spec.nodeAffinity</code>来指定持久化卷位于哪个宿主机上</li>
<li>定义<code>spec.local.path</code>来指定宿主机的持久化卷的路径。</li>
</ul>
<p>此外，由于<code>PersistentVolumeController</code>只会将StorageClass相同的PVC和PV绑定起来，所以还需要创建一个StorageClass，并且使PVC和PV中的<code>StorageClassName</code>相同。</p>
<p>在 StorageClass 里，进行了如下定义：<code>volumeBindingMode: WaitForFirstConsumer</code>，这个字段的作用是<strong>延迟绑定PV和PVC</strong>。定义了这个字段，PVC和PV的绑定就不会在<code>PersistentVolumeController</code>中进行，而是由<strong>调度器</strong>在调度Pod的时候，根据Pod中声明的PVC，来决定和哪个PV进行绑定。</p>
<p>本地持久化卷是没办法进行 Dynamic Provisioning的，所以StorageClass字段中的<code>provisioner</code>定义的是<code>kubernetes.io/no-provisioner</code>。但是它的Static Provisioning也并不需要纯手工操作。运维人员可以使用<a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">local-static-provisioner</a>对PV进行自动管理。它的原理是通过DaemonSet检测节点的<code>/mnt/disks</code>目录，这个目录下如果存在挂载点，则根据这个路径自动生成对应的PV。所以，运维人员只需要在node节点上，在<code>/mnt/disks</code>目录下准备好挂载点即可。</p>
<blockquote>
<p>Q：hostPath可以是挂载在宿主机上的一块磁盘，而不是宿主机的主目录，这种情况使用hostPath作为持久化存储不会导致宿主机宕机。那是不是可以使用hostPath代替PVC/PV作为本地持久化卷？</p>
<p>A：不可以。这种玩法失去了<code>PersistentVolumeController</code>对PVC和PV进行自动绑定、解绑的灵活性。也失去了通过<code>local-static-provisioner</code>对PV进行自动管理的灵活性。最关键的是失去了<strong>延迟绑定</strong>的特性，调度器进行调度的时候，无法参考节点存储的使用情况。</p>
<p>Q：删除一个被Pod使用中的PVC/PV时，kubectl会卡住，为什么？</p>
<p>A：PVC和PV中定义了<code>kubernetes.io/pvc-protection</code>、<code>kubernetes.io/pv-protection</code>这个finalizer字段，删除时，资源不会被apiserver立即删除，要等到<code>volume controller</code>进行<strong>pre-delete</strong>操作后，将finalizer字段删掉，才会被实际删除。而<code>volume controller</code>的<strong>pre-delete</strong>操作实际上就是检查PVC/PV有没有被Pod使用。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>浅谈单机容器网络</title>
			<link>https://cvvz.github.io/post/container-network/</link>
			<pubDate>Thu, 03 Dec 2020 00:16:18 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/container-network/</guid>
			<description>容器网络环境隔离怎么理解？ 容器的网络环境是隔离的，这个隔离就体现在不共用内核网络协议栈，即不共用网络协议栈要用到的数据和设备了： 传输层：端口</description>
			<content type="html"><![CDATA[<h2 id="容器网络环境隔离怎么理解">容器网络环境隔离怎么理解？</h2>
<p>容器的网络环境是隔离的，这个隔离就体现在不共用内核网络协议栈，即<strong>不共用网络协议栈要用到的数据和设备</strong>了：</p>
<ul>
<li>传输层：端口号</li>
<li>网络层：路由表、iptables规则</li>
<li>数据链路层：网卡设备、arp缓存表</li>
</ul>
<p>如果在容器中执行<code>iptables</code>、<code>ifconfig</code>、<code>arp</code>和<code>route</code>命令看到的肯定是不同的iptables规则、网络设备、arp缓存表和路由表。</p>
<h2 id="网桥和veth-pair">网桥和veth pair</h2>
<p>同一个宿主机的容器之间通信是通过二层网络进行通信的。物理机如果想通过二层网络通信，那么必须要有两样东西，一个是网线，一个是交换机。</p>
<p>在Linux系统中，扮演虚拟交换机角色的，叫做网桥；扮演网线角色的，叫做veth pair。</p>
<p>以Docker为例，在bridge模式下：</p>
<ul>
<li>Docker Daemon第一次启动时会创建<code>docker0</code>网桥；</li>
<li>在创建容器时，会创建一个veth pair，即veth设备对。</li>
</ul>
<p>veth pair有两个端点：</p>
<ul>
<li>一端在宿主机中，可以看成是宿主机的一块虚拟网卡，但被关联到docker0网桥上；</li>
<li>另一端，则借助net namespace技术，变成了容器中的eth0网卡。</li>
</ul>
<blockquote>
<p>veth pair之所以可以被看成“网线”，是因为它的特殊之处在于，只要有一端收到了数据包，同样的数据包也会在另一端出现。不受namespace的约束。</p>
</blockquote>
<p>网桥：Linux的网桥提供了在同一个机器上各种网络设备之间互相转发数据的设备。<strong>普通的交换机对于接收到的报文，要么转发，要么丢弃，网桥除了具备普通交换机的功能以外，它还可以调用内核协议栈，处理发送给本机的报文</strong>。</p>
<h2 id="同宿主机中的容器通信过程">同宿主机中的容器通信过程</h2>
<p>同一台宿主机中的两个容器（容器A -&gt; 容器B）建立通信的过程如下（<strong>容器B的ip地址为172.17.0.3</strong>）：</p>
<ol>
<li>
<p>容器A中的内核网络协议栈对网络层进行处理时，去查路由表：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ route
<span class="ln">2</span>Kernel IP routing table
<span class="ln">3</span>Destination     Gateway        Genmask       Flags  Metric Ref Use Iface
<span class="ln">4</span>default         172.17.0.1     0.0.0.0        UG     <span class="m">0</span>     <span class="m">0</span>   <span class="m">0</span>   eth0
<span class="ln">5</span>172.17.0.0      0.0.0.0        255.255.0.0    U      <span class="m">0</span>     <span class="m">0</span>   <span class="m">0</span>   eth0
</code></pre></div><p>发现路由表中容器B的网络地址和第二条规则匹配。这条路由规则的网关（Gateway）是 <code>0.0.0.0</code>，这就意味着这是一条直连规则，即：凡是匹配到这条规则的 IP 包，应该经过 eth0 网卡，通过二层网络直接发往目的主机。</p>
</li>
<li>
<p>容器A于是查询本地的arp缓存表，如果没有找到目的MAC地址，则发一条arp广播，通过容器的eth0网卡发送出去。</p>
</li>
<li>
<p>veth pair的另一端收到这个arp消息，把它转发给docker0网桥。</p>
<blockquote>
<p>这个另一端是宿主机的一块虚拟网卡，本来是应该可以调用网络协议栈来处理收到的数据包的，但是它被和docker0网桥绑定了，所以它的功能被降级为交换机的一个端口，只能无脑把数据包发给网桥去处理。</p>
</blockquote>
</li>
<li>
<p>docker0网桥扮演二层交换机的角色，把arp请求广播出去，收到容器B返回的MAC地址后，再通过原链路把MAC地址返回给容器A。</p>
</li>
<li>
<p>容器A使用目的MAC地址和源MAC地址封装链路层头部，将消息通过eth0网卡发送出去。</p>
</li>
<li>
<p>docker0网桥收到数据包，直接根据目的MAC地址将其转发给容器B。</p>
</li>
</ol>
<p>整个过程可以用下面这张图概括：</p>
<figure>
    <img src="/container-network.png" width="600px"/> 
</figure>

<h2 id="pod中的容器网络">Pod中的容器网络</h2>
<p>创建一个Pod前，首先要创建infra容器，这个infra容器就通过veth设备连接到网桥，接着创建其他容器，其他容器<strong>加入</strong>infra容器的net namespace，这样，就能做到和infra容器之间以localhost的方式通信，<strong>因为同一个namespace中的进程，共享内核数据和网络设备</strong>。</p>
]]></content>
		</item>
		
		<item>
			<title>以aggregated API server的方式部署admission webhook</title>
			<link>https://cvvz.github.io/post/why-aggregated-api-server-webhook/</link>
			<pubDate>Tue, 01 Dec 2020 07:19:06 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/why-aggregated-api-server-webhook/</guid>
			<description>openshift 的 generic-admission-server库 是用来编写admission webhook的lib库，它声称使用该库可以避免为每一个w</description>
			<content type="html"><![CDATA[<blockquote>
<p>openshift 的 <a href="https://github.com/openshift/generic-admission-server#generic-admission-server">generic-admission-server库</a> 是用来编写admission webhook的lib库，它声称<strong>使用该库可以避免为每一个webhook创建和维护客户端证书和密钥所带来的复杂性，开发者只需要维护服务端密钥和证书即可</strong>。我们来看下它是如何实现的。</p>
</blockquote>
<p>首先需要知道的是，由于webhook可以从api server接收API对象并对其进行修改，功能十分强大，因此在生产环境中，webhook和api server之间需要进行双向安全认证。即，客户端（api server）和服务端（webhook）双方都需要提供证书，对方则使用CA证书对证书进行校验。</p>
<blockquote>
<p>在一次加密通信中，证书、私钥、CA证书是怎么工作的可以参考我之前写的<a href="https://cvvz.github.io/post/about-computer-security/">这篇文章</a>。</p>
<p>以下讨论的关注点在于如何简化<strong>客户端证书</strong>的部署，<strong>即api server向webhook提供的证书这一部分</strong>。webhook向api server提供的服务端证书仍然是需要手工部署的。</p>
</blockquote>
<h2 id="admission-webhook认证api-server的过程">admission webhook认证api server的过程</h2>
<p>在启动 api server时，通过<code>--admission-control-config-file</code> 这个参数指定了客户端证书、私钥的配置文件，这个文件的格式如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln"> 1</span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apiserver.config.k8s.io/v1</span><span class="w">
</span><span class="ln"> 2</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">AdmissionConfiguration</span><span class="w">
</span><span class="ln"> 3</span><span class="w"></span><span class="nt">plugins</span><span class="p">:</span><span class="w">
</span><span class="ln"> 4</span><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">ValidatingAdmissionWebhook</span><span class="w">
</span><span class="ln"> 5</span><span class="w">  </span><span class="nt">configuration</span><span class="p">:</span><span class="w">
</span><span class="ln"> 6</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apiserver.config.k8s.io/v1</span><span class="w">
</span><span class="ln"> 7</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">WebhookAdmissionConfiguration</span><span class="w">
</span><span class="ln"> 8</span><span class="w">    </span><span class="nt">kubeConfigFile</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&lt;path-to-kubeconfig-file&gt;&#34;</span><span class="w">
</span><span class="ln"> 9</span><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MutatingAdmissionWebhook</span><span class="w">
</span><span class="ln">10</span><span class="w">  </span><span class="nt">configuration</span><span class="p">:</span><span class="w">
</span><span class="ln">11</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apiserver.config.k8s.io/v1</span><span class="w">
</span><span class="ln">12</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">WebhookAdmissionConfiguration</span><span class="w">
</span><span class="ln">13</span><span class="w">    </span><span class="nt">kubeConfigFile</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&lt;path-to-kubeconfig-file&gt;&#34;</span><span class="w">
</span></code></pre></div><p>其中，<code>kubeConfigFile</code> 参数指定了 <code>kubeconfig</code> 文件的存放位置。<code>kubeconfig</code> 文件和用 kubectl 连接 api server 时用到的那个 <code>kubeconfig</code> 格式一样。只不过这里，客户端是api server，而不是kubectl。</p>
<p>可以看到，通过这种方式部署的webhook，需要手工管理客户端凭证（kubeConfig文件），且每个webhook都需要生成一个客户端凭证。而在webhook中，还需要使用生成证书所用的CA证书来校验api server。非常麻烦。</p>
<h2 id="aggregated-api-server认证api-server的过程">aggregated API server认证api server的过程</h2>
<p>aggregated API server 作为api server的另一种服务端，它所实现的校验客户端（api server）的机制相比 admission webhook就更加成熟和容易维护了。</p>
<p>在启动 api server 时，我们只需要指定如下几个参数：</p>
<ul>
<li><code>--proxy-client-key-file</code>：客户端私钥</li>
<li><code>--proxy-client-cert-file</code>：客户端证书</li>
<li><code>--requestheader-client-ca-file</code>：CA证书</li>
</ul>
<p>aggregated API server 认证 api server 的过程就是自动进行的：</p>
<ol>
<li>
<p>首先，api server会提前为我们在 kube-system 命名空间中创建一个名为 <code>extension-apiserver-authentication</code>的 configmap。这个configmap中存储的正是CA证书。</p>
</li>
<li>
<p>api server 和 aggregated API server 通信时，会发送前面指定的客户端证书，并用私钥进行解密。<strong>而 aggregated API server 用来校验证书的CA证书，就是从第一步生成的configmap中获取的。</strong></p>
</li>
</ol>
<p>可以看到，这种维护客户端凭证的方式，不需要我们手工维护配置文件和CA证书，我们只需要在启动API server时配置一次，后续API server和aggregated API server会自动获取各自需要的文件。</p>
<h2 id="以aggregated-api-server的方式部署admission-webhook">以aggregated API server的方式部署admission webhook</h2>
<p>理解了上述两种认证过程，就不难理解为什么以aggregated API server的方式部署webhook可以简化客户端证书的使用了。</p>
<p>部署admission webhook的步骤是：</p>
<ol>
<li>
<p>在(Validating/Mutating)WebhookConfiguration中，配置admission webhook为kubernetes服务：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">webhooks</span><span class="p">:</span><span class="w">
</span><span class="ln">2</span><span class="w"></span>- <span class="nt">clientConfig</span><span class="p">:</span><span class="w">
</span><span class="ln">3</span><span class="w">    </span><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes</span><span class="w">
</span><span class="ln">5</span><span class="w">      </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="ln">6</span><span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/apis/{group}/{version}/{resource}</span><span class="w">
</span><span class="ln">7</span><span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span></code></pre></div></li>
<li>
<p>在ApiService中，配置group、version，以及admission webhook的service：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="ln">2</span><span class="w">  </span><span class="nt">group</span><span class="p">:</span><span class="w"> </span>{<span class="l">group}</span><span class="w">
</span><span class="ln">3</span><span class="w">  </span><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span>{<span class="l">webhook-service}</span><span class="w">
</span><span class="ln">5</span><span class="w">    </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span>{<span class="l">namespace}</span><span class="w">
</span><span class="ln">6</span><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span><span class="ln">7</span><span class="w">  </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span>{<span class="l">version}</span><span class="w">
</span></code></pre></div></li>
</ol>
<p>这种方式部署的admission webhook的整个工作流程如下图所示：
<figure>
    <img src="/webhook.drawio.svg" width="400px"/> 
</figure>
</p>
<ol>
<li>
<p>API Server过滤指定的请求，并将其发给自己</p>
</li>
<li>
<p>由aggregator转发到aggregated API server</p>
</li>
</ol>
<p>这样就省去了为api server配置和维护kubeconfig文件的步骤。<strong>但是服务端（admission webhook）的证书仍然需要自己生成和维护，并且设置API Service中的 <code>spec.caBundle</code> 字段，来指定 api server 使用的 CA 证书</strong>。设置 <code>spec.insecureSkipTLSVerify</code> 为 true 则不使用TLS加密通信。</p>
<blockquote>
<p>生产环境中，可以使用 <a href="https://github.com/jetstack/cert-manager">cert-manager</a> 来自动生成和管理 TLS 证书，而不是直接存在 secret 资源对象中。</p>
</blockquote>
<p>以aggregated API Server的方式部署webhook带来的另一个好处是，aggregated API Server是使用<a href="https://github.com/kubernetes/apiserver">kubernetes apiserver</a>这个lib库构建的，因此复用了kube-apiserver的认证和鉴权机制。</p>
]]></content>
		</item>
		
		<item>
			<title>kubectl patch</title>
			<link>https://cvvz.github.io/post/k8s-kubectl-patch/</link>
			<pubDate>Sun, 22 Nov 2020 23:16:44 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-kubectl-patch/</guid>
			<description>kubectl patch 用来修改 Kubernetes API 对象的字段。可以通过 --type 参数指定三种不同类型的 patch 方式： strategic：strategic merge patch merge： json merge patch json： json</description>
			<content type="html"><![CDATA[<p><code>kubectl patch</code> 用来修改 Kubernetes API 对象的字段。可以通过 <code>--type</code> 参数指定三种不同类型的 patch 方式：</p>
<ul>
<li><code>strategic</code>：strategic merge patch</li>
<li><code>merge</code>： json merge patch</li>
<li><code>json</code>： json patch</li>
</ul>
<p>实际使用情况：</p>
<ul>
<li>strategic merge patch 用的比较少；大多使用 json merge patch 和 json patch</li>
<li>json merge patch 和 json patch 的具体区别可以查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a></li>
<li>json patch 相比于 json merge patch 使用起来复杂一点，但使用方法更灵活，功能更强大，副作用更少。因此更推荐使用。</li>
</ul>
<h2 id="strategic-merge-patch">strategic merge patch</h2>
<p>这是默认的patch类型，strategic merge patch 在进行 patch 操作时，到底是进行<strong>替换</strong>还是进行<strong>合并</strong>，由 Kubernetes 源代码中字段标记中的 <code>patchStrategy</code> 键的值指定。</p>
<p>具体来说：</p>
<ul>
<li>如果你对deployment的 <code>.spec.template.spec.containers</code> 字段进行 strategic merge patch，那么新的 containers 中的字段值会合并到原来的字段中去，因为 <code>PodSpec</code> 结构体的 <code>Containers</code> 字段的 <code>patchStrategy</code> 为 <code>merge</code>。</li>
<li>如果你对deployment的 <code>.spec.template.spec.tolerations</code> 字段进行 strategic merge patch，那么会用新的 tolerations 字段值将老的字段值直接替换。</li>
</ul>
<h2 id="json-merge-patch">json merge patch</h2>
<p><strong>有相同的字段就替换，没有相同的字段就合并</strong>。这在语义上非常容易理解，但是有以下弊端：</p>
<ul>
<li>键值无法被设置为 <code>null</code>，设置为 <code>null</code> 的字段会直接被 json merge patch 删除掉</li>
<li>操作数组非常吃力。如果你想添加或修改数组中的元素，必须在copy原来的数组，并在其基础上进行改动。因为<strong>新的数组会覆盖原来的数组</strong>。</li>
</ul>
<p>特别是第二点，这导致只要是和数组相关的patch操作，最好使用json patch。</p>
<h2 id="json-patch">json patch</h2>
<p>json patch 的格式如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="ln">1</span><span class="p">[</span>
<span class="ln">2</span>    <span class="p">{</span>
<span class="ln">3</span>        <span class="nt">&#34;op&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
<span class="ln">4</span>        <span class="nt">&#34;path&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span> <span class="p">,</span>
<span class="ln">5</span>        <span class="nt">&#34;value&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span>
<span class="ln">6</span>    <span class="p">}</span>
<span class="ln">7</span><span class="p">]</span>
</code></pre></div><p>即由操作、字段路径、新值组成。具体例子查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a>。可以看到这种操作方式非常灵活。</p>
<h2 id="json-patch-转义字符">json patch 转义字符</h2>
<ul>
<li>&ldquo;~&quot;（波浪线）对应的是：&quot;~0&rdquo;</li>
<li>&ldquo;/&quot;（斜杠）对应的是：&quot;~1&rdquo;</li>
</ul>
<p>具体可以查看这个<a href="https://github.com/json-patch/json-patch-tests/issues/42">issue</a>中的讨论。</p>
]]></content>
		</item>
		
		<item>
			<title>浅谈kubernetes监控体系</title>
			<link>https://cvvz.github.io/post/k8s-monitor/</link>
			<pubDate>Fri, 20 Nov 2020 00:24:35 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-monitor/</guid>
			<description>监控和指标 理解监控 我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。 存储使用时序数据库TSDB、前端展示使用grafana、告警</description>
			<content type="html"><![CDATA[<h2 id="监控和指标">监控和指标</h2>
<h3 id="理解监控">理解监控</h3>
<p>我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。</p>
<p>存储使用时序数据库TSDB、前端展示使用grafana、告警系统也有多种开源实现。我重点介绍一下和指标采集相关的内容。</p>
<h3 id="理解指标">理解指标</h3>
<blockquote>
<p><strong>我们所采集的指标 (metrics)，追根溯源，要么来自于操作系统，要么来自于应用进程自身</strong>。</p>
</blockquote>
<p>在kubernetes中，有三种指标需要被关注，分别来自于：</p>
<ul>
<li>kubernetes基础组件。也就是组成kubernetes的应用进程，如api-server、controller-manager、scheduler、kubelet等。</li>
<li>node节点。也就是组成kubernetes的机器。</li>
<li>Pod/容器。也就是业务进程的<strong>运行环境</strong>。</li>
</ul>
<p>基础设施和kubernetes运维人员主要关注前两项指标，保证kubernetes集群的稳定运行。</p>
<p>而业务方开发/运维主要关注<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics">Pod/容器指标</a>，这和以往关注<a href="https://book.open-falcon.org/zh_0_2/faq/linux-metrics.html">操作系统性能指标</a>大不一样。<strong>在云原生时代，业务进程的运行环境从物理机/虚拟机转变为了Pod/容器。可见，Pod/容器就是云原生时代的<code>不可变基础设施</code></strong>。</p>
<h3 id="采集容器指标的过程">采集容器指标的过程</h3>
<ol>
<li>kubelet内置的cAdvisor负责采集容器指标</li>
<li>kubelet对外暴露出API</li>
<li>Promeheus、Metrics-Server（取代了Heapster）通过这些API采集容器指标</li>
</ol>
<h2 id="prometheus">Prometheus</h2>
<p>Prometheus是Kubernetes监控体系的核心。它的<a href="https://prometheus.io/docs/introduction/overview/#architecture">架构</a>如官网的这幅示意图所示：</p>
<figure>
    <img src="/prometheus.png" width="700px"/> 
</figure>

<p>从左到右就分别是采集指标、存储、展示和告警这四大模块。我还是只介绍采集指标相关的内容。</p>
<h3 id="prometheus是如何采集指标的">Prometheus是如何采集指标的</h3>
<ol>
<li>直接采集。Prometheus提供了各语言的<a href="https://prometheus.io/docs/instrumenting/clientlibs/#client-libraries">lib库</a>，使应用能够对外暴露HTTP端口供prometheus拉取指标值。</li>
<li>间接采集。对于无法通过直接引入lib库或改代码的方式接入Prometheus的应用程序和操作系统，则需要借助<a href="https://prometheus.io/docs/instrumenting/exporters/#third-party-exporters">exporter</a>，代替被监控对象来对 Prometheus 暴露出可以被抓取的 Metrics 信息。</li>
</ol>
<h3 id="prometheus是如何采集kubernetes的指标的">Prometheus是如何采集Kubernetes的指标的</h3>
<ul>
<li>kubernetes基础组件：Prometheus是Kubernetes监控体系的核心，所以这些基础组件当然直接使用lib库采集自己的指标并暴露出API。</li>
<li>node节点：操作系统的性能指标肯定只能借助<a href="https://github.com/prometheus/node_exporter#node-exporter">node exporter</a>来采集了。
<blockquote>
<p><strong>如果node exporter运行在容器里，那么为了让容器里的进程获取到主机上的网络、PID、IPC指标，就需要设置<code>hostNetwork: true</code>、<code>hostPID: true</code>、<code>hostIPC: true</code>，来与主机共用网络、PID、IPC这三个namespace</strong>。</p>
</blockquote>
</li>
<li>Pod/容器。如前所述，Prometheus可以通过kubelet(cAdvisor)暴露出来的API采集指标。</li>
</ul>
<h2 id="kubernetes-hpa">kubernetes HPA</h2>
<p>采集到了性能指标之后，发送发送告警，让运维介入，这只是最初级的运维方式。更高级的方式是让系统自身具备根据指标进行水平弹性伸缩 (HPA) 的能力。</p>
<h3 id="metrics-server">Metrics-Server</h3>
<p>Metrics-server（heapster的替代品）<strong>从kubelet中</strong>获取Pod的监控指标，并通过<a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">apiserver聚合层</a>的方式暴露API，API路径为：<code>/apis/metrics.k8s.io/</code>，也就是说，当你访问这个api路径时，apiserver会帮你转发到Metrics-server里去处理，而不是自己处理。<strong>这样，Kubernetes中的HPA组件就可以通过访问这个API获得指标来进行垂直扩缩容决策了</strong>。</p>
<blockquote>
<p><code>kubectl top</code>命令也是通过这个API获得监控指标的。</p>
</blockquote>
<h3 id="custom-metrics">Custom Metrics</h3>
<p><strong>但是应用程序往往更依赖进程本身的监控指标（如http请求数、消息队列的大小）而不是运行环境的监控指标做决策</strong>。所以只有Metrics-Server暴露出来的API肯定是不够的，因此，Kubernetes提供了另一个API供应用程序暴露自定义监控指标，路径为<code>/apis/custom.metrics.k8s.io/</code>。</p>
<p>Custom Metrics的玩法应该是这样的：</p>
<p><figure>
    <img src="/hpa.drawio.svg" width="600px"/> 
</figure>

如上图所示</p>
<ol>
<li>应用Pod，或者它的exporter暴露出API供Prometheus采集</li>
<li>编写Custom Metrics Server，从Prometheus中获取监控数据</li>
<li>HPA组件通过访问<code>/apis/custom.metrics.k8s.io/</code>进行扩缩容决策。</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>Celery Worker僵尸进程问题定位记录</title>
			<link>https://cvvz.github.io/post/celery-worker-zombie/</link>
			<pubDate>Mon, 30 Mar 2020 10:36:36 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/celery-worker-zombie/</guid>
			<description>组内有一个基于Flask + rabbitMQ + Celery搭建的web平台，最近在上面开发需求时碰到了一个比较有趣的问题，在这里记录下来。 问题背景 web平台</description>
			<content type="html"><![CDATA[<blockquote>
<p>组内有一个基于Flask + rabbitMQ + Celery搭建的web平台，最近在上面开发需求时碰到了一个比较有趣的问题，在这里记录下来。</p>
</blockquote>
<h2 id="问题背景">问题背景</h2>
<p>web平台整体架构图如下所示：</p>
<figure>
    <img src="/platform.drawio.svg" width="700px"/> 
</figure>

<p>Flask向rabbitMQ发送任务消息，后者再将任务分发给不同的Celery worker进行处理。由于每一个任务的处理时间较长，为了不阻塞worker处理下一个任务，在worker中，通过两次fork的方式，生成孤儿进程在后台进行任务处理。</p>
<h2 id="问题现象">问题现象</h2>
<ol>
<li>
<p>worker 生成的孤儿进程在抛出异常后，没有自动退出，仍然处于运行状态。</p>
</li>
<li>
<p>kill worker的父进程（SIGTERM），父进程不退出，很多worker变成僵尸进程。（<strong>所有的celery worker都是由同一个父进程fork出来的</strong>）</p>
</li>
</ol>
<h2 id="排查过程">排查过程</h2>
<p>这个问题基本上是通过走读代码定位出来的，下面给出简化后的worker代码便于后面分析。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="ln"> 1</span><span class="k">def</span> <span class="nf">worker</span><span class="p">():</span>
<span class="ln"> 2</span>    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
<span class="ln"> 3</span>        <span class="c1"># 等待任务...</span>
<span class="ln"> 4</span>        <span class="n">wait_task</span><span class="p">()</span>
<span class="ln"> 5</span>
<span class="ln"> 6</span>        <span class="k">try</span><span class="p">:</span>
<span class="ln"> 7</span>            <span class="c1"># 处理任务</span>
<span class="ln"> 8</span>            <span class="n">execute</span><span class="p">()</span>
<span class="ln"> 9</span>        <span class="k">except</span><span class="p">:</span>
<span class="ln">10</span>            <span class="n">on_failure</span><span class="p">()</span>
<span class="ln">11</span>        
<span class="ln">12</span>        <span class="o">...</span>
<span class="ln">13</span>
<span class="ln">14</span>
<span class="ln">15</span><span class="k">def</span> <span class="nf">execute</span><span class="p">():</span>
<span class="ln">16</span>    <span class="k">try</span><span class="p">:</span>
<span class="ln">17</span>        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">18</span>        <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">19</span>            <span class="k">raise</span> <span class="ne">Exception</span>
<span class="ln">20</span>        <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">21</span>            <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">22</span>            <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">23</span>                <span class="k">raise</span> <span class="ne">Exception</span>
<span class="ln">24</span>            <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">25</span>                <span class="c1"># 实际执行任务处理，遇到异常直接raise</span>
<span class="ln">26</span>                <span class="n">do_execute</span><span class="p">()</span>
<span class="ln">27</span>                <span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="ln">28</span>            <span class="k">else</span><span class="p">:</span>
<span class="ln">29</span>                <span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="ln">30</span>        <span class="k">else</span><span class="p">:</span>
<span class="ln">31</span>            <span class="k">return</span>
<span class="ln">32</span>    <span class="k">except</span><span class="p">:</span>
<span class="ln">33</span>        <span class="k">raise</span>
</code></pre></div><h2 id="问题原因">问题原因</h2>
<p>在分析问题原因前，先来运行这样一段代码：</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="ln">1</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="ln">2</span>    <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">3</span>    <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">4</span>        <span class="k">print</span> <span class="s2">&#34;fork failed&#34;</span>
<span class="ln">5</span>    <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">6</span>        <span class="k">print</span> <span class="s2">&#34;child pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="ln">7</span>    <span class="k">else</span><span class="p">:</span>
<span class="ln">8</span>        <span class="k">print</span> <span class="s2">&#34;parent pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="ln">9</span>    <span class="k">print</span> <span class="s2">&#34;pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
</code></pre></div><p>运行结果是：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>parent pid  <span class="m">78216</span>
<span class="ln">2</span>pid  <span class="m">78216</span>
<span class="ln">3</span>child pid  <span class="m">78217</span>
<span class="ln">4</span>pid  <span class="m">78217</span>
</code></pre></div><p>从这个结果我们可以看出，<strong>fork出来的子进程虽然和父进程不共享堆栈（子进程获得父进程堆栈的副本），但是他们共享正文段</strong>，所以他们都执行了程序的最后一行，各自输出了自己的pid。</p>
<p>接着来分析上述worker的代码，在<code>execute()</code>中，通过两次fork，最终使得<code>do_execute()</code>运行在一个孤儿进程中，如果正常运行，最终会执行<code>os._exit(0)</code>正常退出。然而，如果运行过程中抛出异常又会发生什么呢？根据父子进程共享正文段这一结论，我们可以知道这个孤儿进程抛出的异常会被第32行的<code>except</code>捕获到，并继续向上抛出异常，然后会被第9行<code>worker()</code>中的<code>except</code>捕获，并执行<code>on_failure()</code>。<strong>也就是说，这个孤儿进程最终执行到了worker的代码里去了，而worker本身是一个死循环，因此这个孤儿进程就不会退出了。理论上来说，最终它会运行到第4行，成为一个“worker副本”，等待接收任务</strong>。</p>
<p>至于为什么kill worker的父进程会导致worker变僵尸进程，需要深入研究一下celery源码中的信号处理方法。猜测是父进程在退出前，会先保证所有worker子进程已经退出，而它误以为这个“worker副本”也是自己的子进程，但是却没办法通过向子进程发送信号的方式使其退出，于是就阻塞住了自己的退出流程。而其他已经正常退出的worker就会一直处于僵尸状态。</p>
]]></content>
		</item>
		
		<item>
			<title>用树莓派分析函数调用栈</title>
			<link>https://cvvz.github.io/post/call-stack/</link>
			<pubDate>Tue, 03 Sep 2019 18:44:12 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/call-stack/</guid>
			<description>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。 寄存器 分析函数调用栈涉及到的几个特</description>
			<content type="html"><![CDATA[<blockquote>
<p>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。</p>
</blockquote>
<h2 id="寄存器">寄存器</h2>
<p>分析函数调用栈涉及到的几个特殊用途的寄存器如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">ARM</th>
<th style="text-align:center">X86</th>
<th style="text-align:center">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">r11（fp）</td>
<td style="text-align:center">rbp（ebp）</td>
<td style="text-align:center">栈帧指针</td>
</tr>
<tr>
<td style="text-align:center">r13（sp）</td>
<td style="text-align:center">rsp（esp）</td>
<td style="text-align:center">栈顶指针</td>
</tr>
<tr>
<td style="text-align:center">r14（lr）</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center">返回地址</td>
</tr>
<tr>
<td style="text-align:center">r15（pc）</td>
<td style="text-align:center">rip</td>
<td style="text-align:center">指令指针（程序计数器）</td>
</tr>
</tbody>
</table>
<h2 id="函数调用栈">函数调用栈</h2>
<p>如下图（《程序员的自我修养》图10-4）所示：</p>
<figure>
    <img src="/%e6%a0%88.jpg" width="500px"/> 
</figure>

<p>图中，栈帧指针（ebp）指向的内存空间中保存的是上一个栈的栈帧指针（old ebp）。这是X86的情形，在树莓派中分析函数调用栈时发现，ARM的栈帧指针（fp）指向的是函数返回地址。</p>
<p>这只是不同架构CPU的底层实现的不同，并没有优劣之分。</p>
<h3 id="入栈过程">入栈过程</h3>
<p>一个函数的调用过程可以分为如下几步：</p>
<ul>
<li>首先压栈的是参数，且<strong>从右向左</strong>依次压栈；</li>
<li>接着压入返回地址；</li>
<li>接着被调函数执行“标准开头”（x86）：</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>push rbp
<span class="ln">2</span>mov rbp rsp
</code></pre></div><p>“标准开头”执行过程如下：</p>
<ul>
<li>首先rbp入栈；</li>
<li>rbp入栈后，rsp自动加8（64位），rsp此时指向存放rbp的栈帧地址；</li>
<li>接着令<code>%rbp=%rsp</code>，这就使得rbp指向存放着上一个栈的rbp的内存地址。</li>
</ul>
<p>而ARM（32位）的“标准开头”长这样：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>push {fp, lr}
<span class="ln">2</span>add fp, sp, #4
</code></pre></div><ul>
<li>返回地址(lr)入栈</li>
<li>栈帧指针(fp)入栈</li>
<li>接着令<code>%fp=%sp+4</code>，也就是<strong>使fp（栈帧指针）指向存放返回地址的内存</strong>。</li>
</ul>
<p>不论栈帧指针指向的是上一个栈帧指针，还是返回地址，都能<strong>通过函数的栈帧指针偏移找到调用函数的地址，因此根据栈帧指针的链式关系，可以回溯出整个函数的调用关系链</strong>。这对于一些复杂问题的定位是非常有帮助的。</p>
<blockquote>
<p>GCC的编译选项<code>--fomit-frame-pointer</code>可以使程序不使用栈帧指针，而使用栈指针顶定位函数的局部变量、参数、返回地址等。这么做的好处是可以多出一个寄存器（栈帧指针）供使用，程序运行速度更快，但是就没发很方便的使用GDB进行调试了。</p>
</blockquote>
<h3 id="出栈过程">出栈过程</h3>
<p>出栈与入栈动作刚好相反。</p>
<p>x86的“标准结尾”如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>leaveq
<span class="ln">2</span>retq
</code></pre></div><p>实际上<code>leaveq</code>内部分为两条指令：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>movq %rbp, %rsp
<span class="ln">2</span>popq %rbp
</code></pre></div><p>所以，出栈过程可以分解为如下三步：</p>
<ul>
<li>第一步是通过将rbp地址赋给rsp，即此时rsp指向的内存存放的是上一个栈的rbp。</li>
<li>第二步弹出栈顶的数据到rbp中，即rbp指向上一个栈的栈底，出栈动作导致rsp自增，于是rsp此时指向的内存中存放函数返回地址；</li>
<li>第三步通过<code>retq</code>指令将栈顶地址pop到rip，即rip此时指向函数退出后的下一条指令，rsp则指向上一个栈的栈顶。</li>
</ul>
<p>这三步做完后，rsp、rbp、rip就恢复到调用函数以前的现场。</p>
<p>ARM的行为和x86一致，它的“标准结尾”长这样：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>sub sp, fp, #4
<span class="ln">2</span>pop {fp, pc}
</code></pre></div><h2 id="基于树莓派3分析函数调用栈">基于树莓派3分析函数调用栈</h2>
<p>我在树莓派3中运行了如下所示的C语言代码，并用GDB进行了调试：</p>
<blockquote>
<p>树莓派3使用的是<strong>32位、arm架构CPU</strong>，因此下面的调试过程涉及到的寄存器以及地址信息和64位x86 CPU不同</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="ln"> 1</span><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="ln"> 2</span><span class="cp"></span>
<span class="ln"> 3</span><span class="kt">void</span> <span class="nf">test2</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="p">)</span>
<span class="ln"> 4</span><span class="p">{</span>
<span class="ln"> 5</span>    <span class="kt">int</span> <span class="n">ii</span><span class="p">;</span>
<span class="ln"> 6</span>    <span class="n">ii</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
<span class="ln"> 7</span><span class="p">}</span>
<span class="ln"> 8</span>
<span class="ln"> 9</span><span class="kt">char</span> <span class="nf">test</span><span class="p">(</span><span class="kt">char</span> <span class="n">c</span><span class="p">)</span>
<span class="ln">10</span><span class="p">{</span>
<span class="ln">11</span>    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
<span class="ln">12</span>    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;%c&#34;</span><span class="p">,</span><span class="n">c</span><span class="p">);</span>
<span class="ln">13</span>    <span class="n">test2</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="ln">14</span>    <span class="k">return</span> <span class="n">c</span><span class="p">;</span>
<span class="ln">15</span><span class="p">}</span>
<span class="ln">16</span>
<span class="ln">17</span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="ln">18</span><span class="p">{</span>
<span class="ln">19</span>    <span class="kt">char</span> <span class="n">c</span> <span class="o">=</span> <span class="sc">&#39;a&#39;</span><span class="p">;</span>
<span class="ln">20</span>    <span class="kt">char</span> <span class="n">ret</span><span class="p">;</span>
<span class="ln">21</span>    <span class="n">ret</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
<span class="ln">22</span>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="ln">23</span><span class="p">}</span>
</code></pre></div><h3 id="分析函数调用入栈过程">分析函数调用（入栈）过程</h3>
<p>使用GDB进行调试，将断点打在main函数调用test之前，并使用<code>disassemble</code>查看反汇编结果：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) b *0x000104bc
<span class="ln"> 2</span>Breakpoint 2 at 0x104bc: file main.c, line 21.
<span class="ln"> 3</span>(gdb) disassemble /m main
<span class="ln"> 4</span>Dump of assembler code for function main:
<span class="ln"> 5</span>18 {
<span class="ln"> 6</span>   0x000104a0 &lt;+0&gt;: push {r11, lr}
<span class="ln"> 7</span>   0x000104a4 &lt;+4&gt;: add r11, sp, #4
<span class="ln"> 8</span>   0x000104a8 &lt;+8&gt;: sub sp, sp, #8
<span class="ln"> 9</span>
<span class="ln">10</span>19 char c = &#39;a&#39;;
<span class="ln">11</span>   0x000104ac &lt;+12&gt;: mov r3, #97 ; 0x61
<span class="ln">12</span>   0x000104b0 &lt;+16&gt;: strb r3, [r11, #-5]
<span class="ln">13</span>
<span class="ln">14</span>20 char ret;
<span class="ln">15</span>21 ret = test(c);
<span class="ln">16</span>   0x000104b4 &lt;+20&gt;: ldrb r3, [r11, #-5]
<span class="ln">17</span>   0x000104b8 &lt;+24&gt;: mov r0, r3
<span class="ln">18</span>=&gt; 0x000104bc &lt;+28&gt;: bl 0x10468 &lt;test&gt;
<span class="ln">19</span>   0x000104c0 &lt;+32&gt;: mov r3, r0
<span class="ln">20</span>   0x000104c4 &lt;+36&gt;: strb r3, [r11, #-6]
<span class="ln">21</span>
<span class="ln">22</span>22 return 0;
<span class="ln">23</span>   0x000104c8 &lt;+40&gt;: mov r3, #0
<span class="ln">24</span>
<span class="ln">25</span>23 }
<span class="ln">26</span>   0x000104cc &lt;+44&gt;: mov r0, r3
<span class="ln">27</span>   0x000104d0 &lt;+48&gt;: sub sp, r11, #4
<span class="ln">28</span>   0x000104d4 &lt;+52&gt;: pop {r11, pc}
<span class="ln">29</span>
<span class="ln">30</span>End of assembler dump.
</code></pre></div><p>查看此时栈帧指针和栈顶指针的值：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) i r r11 sp
<span class="ln">2</span>r11            0x7efffaec 2130705132
<span class="ln">3</span>sp             0x7efffae0 0x7efffae0
<span class="ln">4</span>(gdb) x /xw 0x7efffaec
<span class="ln">5</span>0x7efffaec: 0x76e8f678
<span class="ln">6</span>(gdb) info symbol 0x76e8f678
<span class="ln">7</span>__libc_start_main + 276 in section .text of /lib/arm-linux-gnueabihf/libc.so.6
</code></pre></div><p>可以看到，栈帧指针指向的返回地址是<code>__libc_start_main + 276</code>，即<strong>main函数是由__libc_start_main调用的</strong>。</p>
<p>由前面分析得知，栈帧指针-4地址处存放的是上一个函数的栈帧指针，于是我们继续向上追溯<code>__libc_start_main</code>的调用者地址，可以发现其值为0：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) x /xw 0x7efffaec-4
<span class="ln">2</span>0x7efffae8: 0x00000000
</code></pre></div><p><strong>因此可以认为<code>__libc_start_main</code>是所有进程真正的起点。</strong></p>
<p>接着执行调用test函数的命令，使用<code>si</code>单步运行，并查看汇编指令：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) si
<span class="ln"> 2</span>test (c=0 &#39;\000&#39;) at main.c:10
<span class="ln"> 3</span>10 {
<span class="ln"> 4</span>(gdb) disassemble
<span class="ln"> 5</span>Dump of assembler code for function test:
<span class="ln"> 6</span>=&gt; 0x00010468 &lt;+0&gt;: push {r11, lr}
<span class="ln"> 7</span>   0x0001046c &lt;+4&gt;: add r11, sp, #4
<span class="ln"> 8</span>   0x00010470 &lt;+8&gt;: sub sp, sp, #16
<span class="ln"> 9</span>   0x00010474 &lt;+12&gt;: mov r3, r0
<span class="ln">10</span>   0x00010478 &lt;+16&gt;: strb r3, [r11, #-13]
<span class="ln">11</span>   0x0001047c &lt;+20&gt;: ldrb r3, [r11, #-13]
<span class="ln">12</span>   0x00010480 &lt;+24&gt;: mov r0, r3
<span class="ln">13</span>   0x00010484 &lt;+28&gt;: bl 0x10300 &lt;putchar@plt&gt;
<span class="ln">14</span>   0x00010488 &lt;+32&gt;: ldr r0, [r11, #-8]
<span class="ln">15</span>   0x0001048c &lt;+36&gt;: bl 0x10440 &lt;test2&gt;
<span class="ln">16</span>   0x00010490 &lt;+40&gt;: ldrb r3, [r11, #-13]
<span class="ln">17</span>   0x00010494 &lt;+44&gt;: mov r0, r3
<span class="ln">18</span>   0x00010498 &lt;+48&gt;: sub sp, r11, #4
<span class="ln">19</span>   0x0001049c &lt;+52&gt;: pop {r11, pc}
<span class="ln">20</span>End of assembler dump.
<span class="ln">21</span>(gdb) i r $lr
<span class="ln">22</span>lr             0x104c0 66752
<span class="ln">23</span>(gdb) info symbol $lr
<span class="ln">24</span>main + 32 in section .text of /root/main
</code></pre></div><p>可以看到此时lr寄存器中保存的指令即调用test后的下一条指令。继续向下执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) ni
<span class="ln">2</span>0x0001046c 10 {
<span class="ln">3</span>(gdb) i r r11 sp
<span class="ln">4</span>r11            0x7efffaec 2130705132
<span class="ln">5</span>sp             0x7efffad8 0x7efffad8
</code></pre></div><p>观察到将r11和lr入栈后，sp减少了8字节，不难猜测，高4字节存放了lr的值（返回地址），低4字节存放了sp的值（上一个栈的栈帧指针）：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) x /xw 0x7efffad8
<span class="ln">2</span>0x7efffad8: 0x7efffaec
<span class="ln">3</span>(gdb) x /xw 0x7efffadc
<span class="ln">4</span>0x7efffadc: 0x000104c0
<span class="ln">5</span>(gdb) i r $lr $r11
<span class="ln">6</span>lr             0x104c0 66752
<span class="ln">7</span>r11            0x7efffaec 2130705132
</code></pre></div><p>继续执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) ni
<span class="ln">2</span>0x00010470 10 {
<span class="ln">3</span>(gdb) i r $r11
<span class="ln">4</span>r11            0x7efffadc 2130705116
</code></pre></div><p>此时r11指向的是函数返回地址，而不是像x86一样指向上一个栈帧指针，和前面所说的一致。</p>
<h2 id="分析函数返回出栈过程">分析函数返回（出栈）过程</h2>
<p>test函数的汇编指令如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) disassemble /m test
<span class="ln"> 2</span>Dump of assembler code for function test:
<span class="ln"> 3</span>10 {
<span class="ln"> 4</span>   0x00010468 &lt;+0&gt;:	push	{r11, lr}
<span class="ln"> 5</span>   0x0001046c &lt;+4&gt;:	add	r11, sp, #4
<span class="ln"> 6</span>   0x00010470 &lt;+8&gt;:	sub	sp, sp, #16
<span class="ln"> 7</span>   0x00010474 &lt;+12&gt;:	mov	r3, r0
<span class="ln"> 8</span>   0x00010478 &lt;+16&gt;:	strb	r3, [r11, #-13]
<span class="ln"> 9</span>
<span class="ln">10</span>11		int i;
<span class="ln">11</span>12		printf(&#34;%c&#34;,c);
<span class="ln">12</span>   0x0001047c &lt;+20&gt;:	ldrb	r3, [r11, #-13]
<span class="ln">13</span>   0x00010480 &lt;+24&gt;:	mov	r0, r3
<span class="ln">14</span>   0x00010484 &lt;+28&gt;:	bl	0x10300 &lt;putchar@plt&gt;
<span class="ln">15</span>
<span class="ln">16</span>13		test2(i);
<span class="ln">17</span>   0x00010488 &lt;+32&gt;:	ldr	r0, [r11, #-8]
<span class="ln">18</span>   0x0001048c &lt;+36&gt;:	bl	0x10440 &lt;test2&gt;
<span class="ln">19</span>
<span class="ln">20</span>14		return c;
<span class="ln">21</span>   0x00010490 &lt;+40&gt;:	ldrb	r3, [r11, #-13]
<span class="ln">22</span>
<span class="ln">23</span>15	}
<span class="ln">24</span>   0x00010494 &lt;+44&gt;:	mov	r0, r3
<span class="ln">25</span>=&gt; 0x00010498 &lt;+48&gt;:	sub	sp, r11, #4
<span class="ln">26</span>   0x0001049c &lt;+52&gt;:	pop	{r11, pc}
<span class="ln">27</span>
<span class="ln">28</span>End of assembler dump.
</code></pre></div><p>函数运行完毕进入出栈流程的执行过程分为如下几步：</p>
<ul>
<li>首先通过 <code>sub sp, r11, #4</code> 将栈顶指针指向上一个栈帧指针</li>
<li>接着通过 <code>pop {r11, pc}</code> 将上一个栈帧指针赋值给r11，并将返回地址赋值给pc</li>
<li>两次pop后，栈顶指针自动往栈底方向退两次</li>
</ul>
<p>最终，栈顶指针（sp）、栈帧指针（r11）和指令指针（pc）都还原成了main函数调用test前的样子，用GDB查看寄存器内容证实了这一点：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) disassemble 
<span class="ln"> 2</span>Dump of assembler code for function main:
<span class="ln"> 3</span>   0x000104a0 &lt;+0&gt;:	push	{r11, lr}
<span class="ln"> 4</span>   0x000104a4 &lt;+4&gt;:	add	r11, sp, #4
<span class="ln"> 5</span>   0x000104a8 &lt;+8&gt;:	sub	sp, sp, #8
<span class="ln"> 6</span>   0x000104ac &lt;+12&gt;:	mov	r3, #97	; 0x61
<span class="ln"> 7</span>   0x000104b0 &lt;+16&gt;:	strb	r3, [r11, #-5]
<span class="ln"> 8</span>   0x000104b4 &lt;+20&gt;:	ldrb	r3, [r11, #-5]
<span class="ln"> 9</span>   0x000104b8 &lt;+24&gt;:	mov	r0, r3
<span class="ln">10</span>   0x000104bc &lt;+28&gt;:	bl	0x10468 &lt;test&gt;
<span class="ln">11</span>=&gt; 0x000104c0 &lt;+32&gt;:	mov	r3, r0
<span class="ln">12</span>   0x000104c4 &lt;+36&gt;:	strb	r3, [r11, #-6]
<span class="ln">13</span>   0x000104c8 &lt;+40&gt;:	mov	r3, #0
<span class="ln">14</span>   0x000104cc &lt;+44&gt;:	mov	r0, r3
<span class="ln">15</span>   0x000104d0 &lt;+48&gt;:	sub	sp, r11, #4
<span class="ln">16</span>   0x000104d4 &lt;+52&gt;:	pop	{r11, pc}
<span class="ln">17</span>End of assembler dump.
<span class="ln">18</span>(gdb) i r r11 sp pc
<span class="ln">19</span>r11            0x7efffaec	2130705132
<span class="ln">20</span>sp             0x7efffae0	0x7efffae0
<span class="ln">21</span>pc             0x104c0	0x104c0 &lt;main+32&gt;
</code></pre></div>]]></content>
		</item>
		
		<item>
			<title>安全知识总结</title>
			<link>https://cvvz.github.io/post/about-computer-security/</link>
			<pubDate>Thu, 22 Aug 2019 12:38:04 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/about-computer-security/</guid>
			<description>加解密算法 对称加密： 用同一个秘钥进行加密和解密，代表算法有AES/DES/RC2/RC5等； 非对称加密： 一次产生公钥和私钥两个秘钥，任意一个</description>
			<content type="html"><![CDATA[<h2 id="加解密算法">加解密算法</h2>
<p><strong>对称加密：</strong> 用同一个秘钥进行加密和解密，代表算法有<code>AES/DES/RC2/RC5</code>等；</p>
<p><strong>非对称加密：</strong> 一次产生公钥和私钥两个秘钥，任意一个都能进行加密，解密则需要用另外一个。具体的用法是：公钥用来“加密”（相应的私钥用来解密），私钥用来“签名”（相应的公钥用来校验）。代表算法有<code>RSA/DSA/ECC/DH</code>等。</p>
<p><strong>摘要：</strong> 摘要是对数据计算Hash值，Hash值不可逆，是一种单向加密。<code>shadow</code>文件中保存的用户密码就是密码明文的Hash值。代表算法有<code>MD5/SHA256</code>等。</p>
<h2 id="ssl协议">SSL协议</h2>
<p>SSL协议工作在传输层和应用层之间。在TCP协议的三次握手之后，进行SSL协议的握手。</p>
<p>SSL握手过程：</p>
<ul>
<li>客户端发送随机数x和自己支持的加密算法</li>
<li>服务端发送随机数y、公钥和选择的加密算法</li>
<li>客户端发送通过公钥加密的随机数z的密文</li>
<li>客户端、服务端用xyz算出对称加密的密钥</li>
<li>双方进行对称加密通信。</li>
</ul>
<h2 id="ssh协议">SSH协议</h2>
<h3 id="密码登录">密码登录</h3>
<ul>
<li>主机将自己的公钥（主机密钥HostKey）发到客户端（HostKey路径在sshd的配置文件中配置）</li>
<li>客户端计算公钥指纹（摘要），询问用户是否信任该kostkey，信任则将key值记录在known_hosts中，下次登录相同服务器时若hostkey相同不必再次确认；否则提示hostkey不一致</li>
<li>用户输入密码，客户端使用公钥加密密码明文并发送到服务端，服务端使用私钥解密并进行密码校验。</li>
</ul>
<p>由于存在发送服务器公钥的过程，因此存在中间人攻击的安全隐患。</p>
<h3 id="公钥登录">公钥登录</h3>
<p>SSH公钥登录解决了SSH协议中的中间人攻击的问题。</p>
<ul>
<li>用户事先生成一对公/私钥，将公钥提前导入到服务器，</li>
<li>登录时，服务器首先发送一个随机数到客户端，</li>
<li>客户端使用私钥加密随机数返回服务端，</li>
<li>服务端使用公钥校验通过则允许登录。</li>
</ul>
<h2 id="中间人攻击">中间人攻击</h2>
<p>SSL协议以及SSH密码登录方式，都存在着中间人攻击的威胁，主要安全隐患在于握手过程中服务端发送的公钥可能被中间人截取，客户端不能确定服务端发送的公钥是否可信。</p>
<h2 id="证书">证书</h2>
<p>证书解了服务端公钥不可信的问题。</p>
<p>证书中记录了服务器的公钥信息，服务器不直接发送公钥，而是发送从CA中心申请到的证书。CA中心把公钥及其他证书信息一起进行摘要计算，再对其进行签名，最终的证书中存放的是公钥、证书信息、数字签名。</p>
<p>因为有了CA中心的数字签名，只要用相应的CA中心的公钥对签名进行校验（即比较解密后的摘要值和本地计算的摘要值是否相同）通过，就能安全使用公钥进行加密。</p>
<p>CA中心的公钥一般预置在操作系统中的根CA证书中。既然CA中心的公钥是用来对签名进行校验的，那么相应的，这个根CA证书就是用来对服务器发来的证书进行校验的。</p>
<h2 id="证书链">证书链</h2>
<p>一般我们不会直接拿根CA证书对应的私钥去做证书的签发，因为频繁使用根证书对应的私钥会增加其泄露的可能性。</p>
<p>安全的做法是：CA中心给二级CA中心签发一个证书（即二级CA证书，二级CA中心严格保存其对应的私钥），二级CA中心再给三级CA中心签发证书&hellip;依次类推。</p>
<p>因此，服务提供者去N级CA中心签发证书时，生成的不再是证书，而是<code>证书链</code>，证书链中依次记录着服务器证书、N级CA证书、N-1级CA证书&hellip;二级CA证书。证书校验时，用根CA证书校验二级CA证书、二级CA证书校验三级CA证书&hellip;最后N级校验服务器证书，只有全部校验通过，服务器证书才算被客户端校验通过。</p>
<h2 id="浏览器通过https协议访问网站的过程">浏览器通过HTTPS协议访问网站的过程</h2>
<ol>
<li>通过本地的DNS配置文件找到DNS服务器地址。</li>
<li>DNS服务器将网址解析为ip地址返回。</li>
<li>本机通过链路层的arp协议找到局域网的路由器。（二层）</li>
<li>路由器通过ip地址路由寻址找到ip地址对应的主机。（三层）</li>
<li>主机通过TCP协议找到本机的端口号（进程listen）。（四层）</li>
<li>TCP三次握手。</li>
<li><strong>使用证书</strong>进行SSL握手（主机将自己的证书链发到浏览器，浏览器使用操作系统预置CA证书进行校验，校验不通过会提示链接不安全的风险）。（SSL层）</li>
<li>服务器进程和浏览器进程在应用层使用HTTP协议交换数据。（七层）</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>进程和线程</title>
			<link>https://cvvz.github.io/post/process-and-thread/</link>
			<pubDate>Sun, 23 Jun 2019 20:34:56 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/process-and-thread/</guid>
			<description>从“程序”开始 对于UNIX操作系统，程序是存放在磁盘上的ELF文件（可以通过file命令查看文件类型） 对于windows操作系统，程序是存放</description>
			<content type="html"><![CDATA[<h2 id="从程序开始">从“程序”开始</h2>
<ul>
<li>对于UNIX操作系统，程序是存放在磁盘上的<strong>ELF文件</strong>（可以通过<code>file</code>命令查看文件类型）</li>
<li>对于windows操作系统，程序是存放在磁盘上的<strong>PE文件</strong>，其中最常见的是<code>.exe</code>文件。</li>
</ul>
<p>编译器将高级语言编写成的程序编译成机器码，操作系统将ELF文件读入内存后，ELF文件中的<strong>代码段</strong>也就是CPU可以执行的机器码（可以通过<code>readelf</code>命令查看ELF文件的代码段内容），CPU从内存中读取机器码并执行。</p>
<h2 id="为进程分配资源">为进程分配资源</h2>
<p>进程产生的标志是：内核为每一个进程都分配了一个<code>task_struct</code>结构体，在<code>task_struct</code>中记录了这个进程所拥有的资源，如全局变量、虚拟内存等，所以说<strong>进程是资源分配的最小单位</strong>。</p>
<h2 id="调度线程">调度线程</h2>
<p><strong>线程是CPU调度的最小单位</strong>，也就是说<strong>内核进行调度的对象实际上是线程，而进程是负责为线程提供共享资源的</strong>。</p>
<p>一个进程中的多个线程共享这个进程的资源，但是<strong>它们虽然共享同一片虚拟内存，自身却拥有这片虚拟内存中的不同的栈空间</strong>；</p>
<h2 id="通信方式">通信方式</h2>
<p>由于同一进程中的线程共享资源，所以通信非常方便，直接读写同一块用户态内存即可，但是这必然就涉及到互斥和原子性问题。</p>
<p>而进程要实现通信则需要借助内核和文件，所有的IPC，都是把内核和文件充当交换信息的桥梁。</p>
<h2 id="上下文切换">上下文切换</h2>
<blockquote>
<p>同一进程中的线程上下文切换，简称<strong>线程上下文切换</strong>。</p>
<p>不同进程中的线程上下文切换，简称<strong>进程上下文切换</strong>。</p>
</blockquote>
<p>不管是线程上下文切换，还是进程上下文切换，都会涉及CPU寄存器和程序计数器的保存和更新。<strong>因此都涉及CPU上下文切换</strong>。</p>
<p>由于线程共享进程中的虚拟内存空间，所以线程上下文切换时，<strong>不需要更新虚拟内存到物理内存的内存映射表</strong>。而进程上下文切换时，则要更新虚拟内存到物理内存的内存映射表。</p>
<p>当内核找不到虚拟内存到物理内存的映射关系时，便会产生<code>缺页中断</code>。所以<strong>进程上下文切换后，程序执行更容易产生缺页中断</strong>。</p>
<h2 id="怎么理解linux中的线程是以进程的方式实现的">怎么理解Linux中的线程是以进程的方式实现的</h2>
<ul>
<li>对于支持线程的操作系统而言，如果一个进程中有N个线程，则存在一个进程描述符，依次轮流指向N个线程。这个进程描述符指明共享资源，包括内存空间和打开的文件。而每一个线程描述它们自己独享的资源。也就是说<strong>内核中描述线程的结构体和描述进程的结构体不同</strong>。</li>
<li>而在Linux中，则有N个<code>task_struct</code>数据结构，只是这些数据结构的某些资源项是共享的，某些是独占的。</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>抓包解读smtp和tls协议</title>
			<link>https://cvvz.github.io/post/smtp-with-tls/</link>
			<pubDate>Sat, 22 Jun 2019 23:21:54 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/smtp-with-tls/</guid>
			<description>背景：某进程调用 libcurl 提供的 curl_easy_perform 接口与邮箱服务器进行smtp通信时，服务端返回56(CURLE_RECV_ERROR)错误。由于服务端日志信息不足</description>
			<content type="html"><![CDATA[<blockquote>
<p>背景：某进程调用 <code>libcurl</code> 提供的 <code>curl_easy_perform</code> 接口与邮箱服务器进行smtp通信时，服务端返回56(<code>CURLE_RECV_ERROR</code>)错误。由于服务端日志信息不足，于是想到可以通过抓包查看建立smtp连接时的错误信息。</p>
</blockquote>
<h3 id="第一次抓包">第一次抓包</h3>
<figure>
    <img src="/smtp-with-tls.png" width="1050px"/> 
</figure>

<p>从图中可以清晰看出整个SMTP连接从建立到断开的全过程：</p>
<ol>
<li>通过三次握手建立TCP连接</li>
<li>客户端向服务端发送 <code>STARTTLS</code>，服务端回复 <code>220 Ready to start TLS</code>后，SMTP协议准备建立安全信道</li>
<li><a href="https://cvvz.github.io/post/about-computer-security/#ssl%E5%8D%8F%E8%AE%AE">TLS协议握手</a>建立连接</li>
<li>TLS协议建立连接后，<strong>应用层协议的内容就被加密了，抓包只能看到图中的<code>Application Data</code>字样</strong>。</li>
<li>通过TCP四次挥手断开连接</li>
</ol>
<blockquote>
<p>由于smtp协议内容被加密了，因此需要先去掉TLS连接，再抓包分析。</p>
</blockquote>
<h3 id="第二次抓包">第二次抓包</h3>
<figure>
    <img src="/smtp-without-tls.png" width="1050px"/> 
</figure>

<p>从第二次抓包得到的信息，可以看出连接断开的根因是smtp服务器返回了<code>502 VRFY disallowed</code>。</p>
<p>接下来网上搜索<code>smtp VRFY disallowed</code>相关内容就能找到答案了：原来<code>libcurl</code>从7.34.0版本开始，要求SMTP客户端显式的设置 <code>CURLOPT_UPLOAD</code> 选项，否则libcurl将发送<code>VRFY</code>命令。而一般服务器出于安全性的考虑，会禁止执行VRFY命令。（参考<a href="https://issues.dlang.org/show_bug.cgi?id=13042">https://issues.dlang.org/show_bug.cgi?id=13042</a> ）</p>
<blockquote>
<p>通过抓包还证实了，不进行加密通信的应用层数据是明文传输的，smtp协议中的用户名密码被一览无余。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>gdb中的多线程和信号处理</title>
			<link>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</link>
			<pubDate>Mon, 10 Jun 2019 11:44:52 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</guid>
			<description>多线程调试 使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。 All-Stop 任何一个线程在断点处hang住时，所有其他线</description>
			<content type="html"><![CDATA[<h2 id="多线程调试">多线程调试</h2>
<p>使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。</p>
<h3 id="all-stop">All-Stop</h3>
<blockquote>
<p>任何一个线程在断点处hang住时，所有其他线程也会hang住。默认为all-stop模式。</p>
</blockquote>
<ol>
<li>
<p>在all-stop模式中，当一个线程到达断点或产生信号，GDB将自动选择该线程作为当前线程并停住（提示<code>Switching to Thread n</code>），并且其他线程也都会停止运行；</p>
</li>
<li>
<p>当执行<code>continue</code>、<code>until</code>、<code>finish</code>、<code>next</code>、<code>step</code>等使线程继续运行，所有线程会同时继续运行，直到某一个线程再次被stop，然后该线程成为当前线程。</p>
</li>
<li>
<p>这里还存在这样一种情况：当你单步跟踪某个线程时，这个线程一定是执行了某条完整语句后在下一条语句前停住，<strong>但是这段时间里其他线程可能执行了半条、一条或多条语句</strong>。</p>
</li>
<li>
<p>在all-stop模式下，可以通过设定<code>scheduler-locking</code>（调度器锁定）来控制CPU调度器的行为从而控制多线程的并发运行行为。</p>
<ul>
<li><code>set scheduler-locking off</code>：默认调度器锁定为关，也就是CPU也可以进行自由调度，那么所有线程是“同进同止”的，一起stop，一起继续运行，竞争CPU资源；</li>
<li><code>set scheduler-locking on</code>：开启调度器锁定，不允许CPU自由调度，CPU只能执行当前线程中的指令，其他线程一直处于stop状态；</li>
</ul>
</li>
</ol>
<h3 id="non-stop">Non-Stop</h3>
<blockquote>
<p>任何一个线程被stop甚至单步调试时，其他线程可以自由运行。</p>
</blockquote>
<ol>
<li>通过<code>set non-stop on</code>手动开启non-stop模式。一般non-stop模式搭配异步执行命令使用。</li>
<li>GDB的可执行命令分为两种：同步执行和异步执行。
<ul>
<li>同步执行：即执行一条命令后，要等待有线程被stop了才会在弹出命令提示符。这是默认执行模式。</li>
<li>异步执行：立刻返回弹出命令提示符。打开命令异步执行模式开关的命令是<code>set target-async on</code>。</li>
</ul>
<blockquote>
<p>在命令后跟<code>&amp;</code>表示该命令以异步的方式执行，如<code>attach&amp;</code>、<code>continue&amp;</code>等。</p>
</blockquote>
</li>
<li>non-stop模式下可使用<code>interrupt</code>停止当前运行中的线程，<code>interrupt -a</code>停下所有线程。</li>
</ol>
<h2 id="信号处理">信号处理</h2>
<p>GDB能够检测到程序中产生的信号，并进行针对性的处理。通过<code>info handle</code>查看对所有信号的处理方式：</p>
<ul>
<li>Stop：检测到信号是否停住程序的运行；</li>
<li>Print：是否打印收到该信号的信息；</li>
<li>Pass to program：是否把该信号传给进程处理（或者说是否屏蔽该信号，无法屏蔽<code>SIGKILL</code>和<code>SIGSTOP</code>信号）</li>
</ul>
<p>通过<code>handle SIG</code>来指定某个信号的处理方式。</p>
]]></content>
		</item>
		
		<item>
			<title>解剖进程虚拟内存空间</title>
			<link>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</link>
			<pubDate>Fri, 07 Jun 2019 23:14:03 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</guid>
			<description>对于32位 x86 Linux操作系统，典型的进程地址空间如下图所示： 每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFF</description>
			<content type="html"><![CDATA[<p>对于<strong>32位 x86 Linux操作系统</strong>，典型的进程地址空间如下图所示：</p>
<figure>
    <img src="/linuxFlexibleAddressSpaceLayout.png" width="750px"/> 
</figure>

<p>每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFFFFFF，共4GB。</p>
<p>进程地址空间从低到高依次是：</p>
<ul>
<li><strong>Text Segment：</strong> 机器指令，只读，一个程序的多个进程共享一个正文段。</li>
</ul>
<blockquote>
<p>如果进程带有调试信息，可以通过<code>addr2line</code> + 正文段地址获得对应的源代码位置。</p>
</blockquote>
<ul>
<li>
<p><strong>Data Segment：</strong> 具有初值的全局/静态变量。</p>
</li>
<li>
<p><strong>BSS Segment：</strong> 未赋初值的全局/静态变量。</p>
</li>
<li>
<p><strong>Heap：</strong> 堆。堆从低地址向高地址生长。堆区内存在分配过程中可能产生内存碎片：</p>
</li>
</ul>
<p><img src="/fragmentedHeap.png" alt="内存碎片" title="内存碎片"></p>
<blockquote>
<p>申请堆内存的接口是阻塞接口，即可能因为暂时分配不到够大的堆空间导致进程让出CPU。</p>
</blockquote>
<ul>
<li>
<p><strong>Memory Mapping Segment：</strong> 内存映射区。动态库、mmap、共享内存使用的都是内存映射区。</p>
</li>
<li>
<p><strong>Stack：</strong> 栈。栈从高地址向低地址生长。进程栈空间的总大小可通过
<code>ulimit -s</code>查看，默认为8MB。栈中不仅存放着局部变量，<strong>每次函数调用时，参数、返回地址、寄存器值等都会进行压栈。</strong></p>
</li>
<li>
<p><strong>Kernel space：</strong> 进程地址空间的最高1GB是内核空间。<strong>内核空间被所有进程共享</strong>，但是用户态进程只有通过系统调用陷入内核态才能执行内核态代码。</p>
</li>
</ul>
<blockquote>
<p>参考文章：<a href="https://manybutfinite.com/post/anatomy-of-a-program-in-memory/">https://manybutfinite.com/post/anatomy-of-a-program-in-memory/</a></p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>Git笔记</title>
			<link>https://cvvz.github.io/post/usage-of-git/</link>
			<pubDate>Sun, 02 Jun 2019 23:41:24 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/usage-of-git/</guid>
			<description>整理一下最近学习的git知识，以及平时常用的git功能。 .git 使用git init或clone一个远端仓，会在本地建立一个.git目录。这个目录是</description>
			<content type="html"><![CDATA[<blockquote>
<p>整理一下最近学习的git知识，以及平时常用的git功能。</p>
</blockquote>
<h2 id="git">.git</h2>
<p>使用git init或clone一个远端仓，会在本地建立一个.git目录。<strong>这个目录是git仓的全部，把.git拷贝到其他目录下，就能在该目录下建立一个一模一样的git仓</strong>。</p>
<h2 id="缓存区staged">缓存区（staged）</h2>
<ul>
<li>对working derictoy中的文件做的改动，他们的状态是unstaged</li>
<li>使用 <code>git add</code>/<code>git rm</code>/<code>git mv</code> 将其送入缓存区（staged）</li>
<li>使用 <code>git commit</code> 提交缓存区中记录的改动。</li>
<li><code>git diff {filename}</code> 可以查看unstaged和staged中文件的不同</li>
<li><code>git diff --staged {filename}</code> 可以查看staged中的文件和原文件的不同</li>
<li>注意staged和<code>stash</code>的区别</li>
</ul>
<h2 id="上游分支">上游分支</h2>
<p><code>git clone</code>可以通过参数 <code>-b</code> 来指定clone远端仓库到本地后拉取哪条分支，不指定则默认拉取<code>master</code>；远端仓库中必须存在同名分支，作为本地分支的上游分支。</p>
<p>通过<code>git branch -vv</code> 或 <code>git status</code> 命令可以查看本地分支相比上游分支领先/落后多少个commit。</p>
<p><code>git checkout -b {local_branch} {remote_branch}</code>用来创建并切换分支，并指定该分支的上游分支。</p>
<h2 id="revert和reset">revert和reset</h2>
<p><code>git reset</code>把HEAD指针指向到某一个commit id，这次commit之后的所有commit都会被删除。</p>
<p><code>git revert</code>用来撤销某一次commit带来的变化，不会影响其他commit。revert本身也需要commit。</p>
<p>非fast-forward形式合并两条分支时，git会自动生成一个合并提交。如果想回退某条分支的merge操作，可以revert这次合并提交的commit，git会让你选择留下这次合并提交的哪一个父分支，另一个父分支所作的改动会被回退。</p>
<h2 id="如何修改一次历史commit">如何修改一次历史commit</h2>
<p>执行<code>git rebase -i {commitid}^</code>（commitid是想要修改的那次提交），git会以commitid的前一次提交作为base，采用交互式的方式，重新提交后面的每一次commit，将想要修改的那一次的提交命令设置为edit即可。</p>
]]></content>
		</item>
		
		<item>
			<title>进程间通信</title>
			<link>https://cvvz.github.io/post/ipc/</link>
			<pubDate>Fri, 02 Nov 2018 22:34:20 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/ipc/</guid>
			<description>进程间通信的六种方式： 管道 共享内存 消息队列 信号量 信号 socket 管道 管道机制和UNIX系统的文件系统密切关联，使用管道和使用文件系统非常类似。实际上使</description>
			<content type="html"><![CDATA[<p>进程间通信的六种方式：</p>
<ul>
<li>管道</li>
<li>共享内存</li>
<li>消息队列</li>
<li>信号量</li>
<li>信号</li>
<li>socket</li>
</ul>
<h1 id="管道">管道</h1>
<p>管道机制和UNIX系统的文件系统密切关联，使用管道和使用文件系统非常类似。实际上使用<strong>管道可以看成是创建了一个不会残留的临时文件，一个进程写文件，另一个进程读文件，从而实现了进程间通信</strong>。</p>
<p>管道分为 <strong>匿名管道</strong> 和 <strong>FIFO</strong>。</p>
<h2 id="匿名管道">匿名管道</h2>
<p>使用 <code>pipe</code> 函数创建匿名管道。它返回两个文件描述符，<code>fd[0]</code>是管道的读端，<code>fd[1]</code>是写端。</p>
<p>如果进程只调用<code>pipe</code>，那么只能自写自读，基本没什么用。</p>
<p>因此，<strong>使用<code>pipe</code>创建管道后，必然要使用 <code>fork</code> 创建子进程，这样就可以做到父子进程使用不同的fd进行读写通信</strong>。</p>
<h3 id="popen">popen</h3>
<p>库函数 <code>popen</code> 就是使用匿名管道实现的。函数原型：</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="ln">1</span><span class="n">FILE</span> <span class="o">*</span> <span class="n">popen</span><span class="err">（</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">cmdstring</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">type</span><span class="err">）</span><span class="p">;</span>
</code></pre></div><p><code>popen</code>创建了一个管道，然后执行fork，在子进程中使用<code>exec</code>执行cmdstring；返回的文件指针根据参数type指向管道的读或写端。</p>
<p>type可取&quot;w&quot;和&quot;r&quot;：</p>
<ul>
<li>
<p>取&quot;w&quot;时，返回的文件指针指向管道的写端fd[1]，子进程通过<code>dup2</code>将<code>stdin</code>复制到fd[0]，而cmdstring执行依赖<code>stdin</code>，就等于依赖父进程通过文件指针写入管道了；</p>
</li>
<li>
<p>取&quot;r&quot;时，文件指针指向管道的读端fd[0]，子进程通过<code>dup2</code>将<code>stdout</code>复制到fd[1]，而cmdstring执行默认输出到<code>stdout</code>，那么父进程就可以通过该文件指针读出cmdstring命令的输出。</p>
</li>
</ul>
<p>通过 <code>pclose</code> 函数关闭打开的文件指针，并使用<code>waitpid</code>关闭子进程;因此<code>popen</code>后如果不执行<code>pclose</code>将造成内存泄漏和僵尸进程。</p>
<h2 id="fifo">FIFO</h2>
<p><code>FIFO</code>可以用来在不相关的进程间通信。</p>
<p><code>FIFO</code>是一种文件类型，所以创建<code>FIFO</code>就是创建文件。通过 <code>mkfifo</code> 函数创建 <code>FIFO</code> 时，要指定一个具体的文件路径。</p>
<p>创建了<code>FIFO</code>之后，就可以通过标准文件操作（<code>open</code>、<code>read</code>、<code>write</code>、<code>close</code>）来使用它。毕竟在Linux中，一切皆文件。</p>
<h1 id="xsi-ipc">XSI IPC</h1>
<p><strong>消息队列、信号量、共享内存被统称为<code>XSI IPC</code></strong>，他们之间有很多共通之处：</p>
<ol>
<li>独立于文件系统，有自己的一套操作管理函数和内核数据结构；不能像管理文件一样管理这些资源。</li>
<li>这些资源归属于操作系统，而不属于某个进程，如果进程退出前忘记回收资源，资源不会自己释放掉，可能影响系统内其他进程。</li>
<li>进程通过<code>xxxget</code>函数并指定参数key的方式获得一个id，通过id来使用和管理指定的资源；id是进程内管理资源的标识符，不具有全局性，key值才是全局标识符；两个进程指定同一个key值就能获取同一个资源，从而关联起来。</li>
</ol>
<h2 id="信号量">信号量</h2>
<p>信号量(semaphore)作为IPC的角色是专门用来控制多个进程访问共享资源的，实际就是一个计数器。</p>
<p>通过<code>semget</code>、<code>semctl</code>、<code>semop</code>管理信号量。</p>
<h2 id="共享内存和mmap">共享内存和mmap</h2>
<h3 id="mmap">mmap</h3>
<p><code>mmap</code>把磁盘上某个具体文件映射到进程的内存映射区中，以实现对文件更快的读写。</p>
<p>通过将同一文件映射到不同的进程中内存空间，就可以实现进程间共享内存通信。</p>
<h3 id="共享内存">共享内存</h3>
<p>共享内存可以看成是把内核中的一块内存映射到进程的内存映射区。这样，两个进程共享同一块内存就可以实现通信了，由于是直接对内存读写，这种IPC方式也是最快的。</p>
<p>通过<code>shmget</code>、<code>shmctl</code>、<code>shmat</code>、<code>shmdt</code>管理共享内存。</p>
]]></content>
		</item>
		
	</channel>
</rss>
