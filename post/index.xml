<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Vic&#39;s Blog</title>
		<link>https://cvvz.github.io/post/</link>
		<description>Recent content in Posts on Vic&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>zh-hans</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Mon, 23 Nov 2020 22:55:34 +0800</lastBuildDate>
		<atom:link href="https://cvvz.github.io/post/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>[翻译]helm的使用</title>
			<link>https://cvvz.github.io/post/helm-using-translate/</link>
			<pubDate>Mon, 23 Nov 2020 22:55:34 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/helm-using-translate/</guid>
			<description>最近在做一个需求，需要对helm chart进行改造，准备系统性的学习一下helm。正好周末有点时间，索性自己翻译了一下官方文档（版本：v3</description>
			<content type="html"><![CDATA[<blockquote>
<p>最近在做一个需求，需要对helm chart进行改造，准备系统性的学习一下helm。正好周末有点时间，索性自己翻译了一下<a href="https://helm.sh/docs/intro/using_helm/">官方文档</a>（版本：v3.4.1）。提了一个<a href="https://github.com/helm/helm-www/pull/959/files">PR</a>。</p>
</blockquote>
<hr>
<p>本指南介绍了使用 Helm 来管理 Kubernetes 集群上的软件包的基础知识。在这之前，假定您已经<a href="https://helm.sh/zh/docs/intro/install/">安装</a>了 Helm 客户端。</p>
<p>如果您仅对运行一些快速命令感兴趣，则不妨从<a href="https://helm.sh/zh/docs/intro/quickstart/">快速入门指南</a>开始。本章包含了 Helm 命令的详细说明，并解释如何使用 Helm。</p>
<h2 id="三大概念">三大概念</h2>
<p><em>Chart</em> 代表着 Helm 包。它包含在 Kubernetes 集群内部运行应用程序，工具或服务所需的所有资源定义。你可以把它看作是 Homebrew formula，Apt dpkg，或 Yum RPM 在Kubernetes 中的等价物。</p>
<p><em>Repository</em> 是用来存放和共享 charts 的地方。它就像 Perl 的 <a href="https://www.cpan.org">CPAN</a> 或是 Fedora 的<a href="https://fedorahosted.org/pkgdb2/">软件包仓库</a>，只不过它是供 Kubernetes 包所使用的。</p>
<p><em>Release</em> 是运行在 Kubernetes 集群中的 chart 的实例。一个 chart 通常可以在同一个集群中安装多次。每一次安装都会创建一个新的 <em>release</em>。以 MySQL chart为例，如果你想在你的集群中运行两个数据库，你可以安装该chart两次。每一个数据库都会拥有它自己的 <em>release</em> 和 <em>release name</em>。</p>
<p>在了解了上述这些概念以后，我们就可以这样来解释 Helm：</p>
<p>Helm 安装 <em>charts</em> 到 Kubernetes 集群中，每次安装都会创建一个新的 <em>release</em>。你可以在 Helm 的 chart <em>repositories</em> 中寻找新的 chart。</p>
<h2 id="helm-search查找-charts">&lsquo;helm search&rsquo;：查找 Charts</h2>
<p>Helm 自带一个强大的搜索命令，可以用来从两种来源中进行搜索：</p>
<ul>
<li><code>helm search hub</code> 从 <a href="https://artifacthub.io">Artifact Hub</a> 中查找并列出 helm charts。Artifact Hub中存放了大量不同的 repository。</li>
<li><code>helm search repo</code> 从你添加（使用 <code>helm repo add</code>）到本地 helm 客户端中的 repository 中进行查找。该命令基于本地数据进行搜索，无需连接互联网。</li>
</ul>
<p>你可以通过运行 <code>helm search hub</code> 命令找到公开可用的charts：</p>
<pre><code class="language-console" data-lang="console">$ helm search hub wordpress
URL                                                 CHART VERSION APP VERSION DESCRIPTION
https://hub.helm.sh/charts/bitnami/wordpress        7.6.7         5.2.4       Web publishing platform for building blogs and ...
https://hub.helm.sh/charts/presslabs/wordpress-...  v0.6.3        v0.6.3      Presslabs WordPress Operator Helm Chart
https://hub.helm.sh/charts/presslabs/wordpress-...  v0.7.1        v0.7.1      A Helm chart for deploying a WordPress site on ...
</code></pre><p>上述命令从 Artifact Hub 中搜索所有的 <code>wordpress</code> charts。</p>
<p>如果不进行过滤，<code>helm search hub</code> 命令会展示所有可用的 charts。</p>
<p>使用 <code>helm search repo</code> 命令，你可以从你所添加的 repository 中查找chart的名字。</p>
<pre><code class="language-console" data-lang="console">$ helm repo add brigade https://brigadecore.github.io/charts
&quot;brigade&quot; has been added to your repositories
$ helm search repo brigade
NAME                          CHART VERSION APP VERSION DESCRIPTION
brigade/brigade               1.3.2         v1.2.1      Brigade provides event-driven scripting of Kube...
brigade/brigade-github-app    0.4.1         v0.2.1      The Brigade GitHub App, an advanced gateway for...
brigade/brigade-github-oauth  0.2.0         v0.20.0     The legacy OAuth GitHub Gateway for Brigade
brigade/brigade-k8s-gateway   0.1.0                     A Helm chart for Kubernetes
brigade/brigade-project       1.0.0         v1.0.0      Create a Brigade project
brigade/kashti                0.4.0         v0.4.0      A Helm chart for Kubernetes
</code></pre><p>Helm 搜索使用模糊字符串匹配算法，所以你可以只输入名字的一部分：</p>
<pre><code class="language-console" data-lang="console">$ helm search repo kash
NAME            CHART VERSION APP VERSION DESCRIPTION
brigade/kashti  0.4.0         v0.4.0      A Helm chart for Kubernetes
</code></pre><p>搜索是用来发现可用包的一个好办法。一旦你找到你想安装的 helm 包，你便可以通过使用 <code>helm install</code> 命令来安装它。</p>
<h2 id="helm-install安装一个-helm-包">&lsquo;helm install&rsquo;：安装一个 helm 包</h2>
<p>使用 <code>helm install</code> 命令来安装一个新的 helm 包。最简单的使用方法只需要传入两个参数：你命名的release名字和你想安装的chart的名称。</p>
<pre><code class="language-console" data-lang="console">$ helm install happy-panda stable/mariadb
WARNING: This chart is deprecated
NAME: happy-panda
LAST DEPLOYED: Fri May  8 17:46:49 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
This Helm chart is deprecated

...

Services:

  echo Master: happy-panda-mariadb.default.svc.cluster.local:3306
  echo Slave:  happy-panda-mariadb-slave.default.svc.cluster.local:3306

Administrator credentials:

  Username: root
  Password : $(kubectl get secret --namespace default happy-panda-mariadb -o jsonpath=&quot;{.data.mariadb-root-password}&quot; | base64 --decode)

To connect to your database:

  1. Run a pod that you can use as a client:

      kubectl run happy-panda-mariadb-client --rm --tty -i --restart='Never' --image  docker.io/bitnami/mariadb:10.3.22-debian-10-r27 --namespace default --command -- bash

  2. To connect to master service (read/write):

      mysql -h happy-panda-mariadb.default.svc.cluster.local -uroot -p my_database

  3. To connect to slave service (read-only):

      mysql -h happy-panda-mariadb-slave.default.svc.cluster.local -uroot -p my_database

To upgrade this helm chart:

  1. Obtain the password as described on the 'Administrator credentials' section and set the 'rootUser.password' parameter as shown below:

      ROOT_PASSWORD=$(kubectl get secret --namespace default happy-panda-mariadb -o jsonpath=&quot;{.data.mariadb-root-password}&quot; | base64 --decode)
      helm upgrade happy-panda stable/mariadb --set rootUser.password=$ROOT_PASSWORD

</code></pre><p>现在，<code>mariadb</code> chart 已经被安装。请注意，安装 chart 会创建一个新的 <em>release</em> 对象。上述 release 被命名为 <code>happy-panda</code>。（如果你想要 Helm 为你自动生成一个名字，请将 release 名字留空并使用 <code>--generate-name</code>。）</p>
<p>在安装过程中，<code>helm</code> 客户端会打印一些有用的信息，其中包括：哪些资源已经被创建，release当前的状态，以及你是否还需要执行额外的配置步骤。</p>
<p>Helm 客户端不会等到所有资源都运行才退出。许多 charts 需要大小超过 600M 的 Docker 镜像，可能需要很长时间才能安装到群集中。</p>
<p>你可以使用 <code>helm status</code> 来追踪 release 的状态，或是重新读取配置信息：</p>
<pre><code class="language-console" data-lang="console">$ helm status happy-panda                
NAME: happy-panda
LAST DEPLOYED: Fri May  8 17:46:49 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
This Helm chart is deprecated

...

Services:

  echo Master: happy-panda-mariadb.default.svc.cluster.local:3306
  echo Slave:  happy-panda-mariadb-slave.default.svc.cluster.local:3306

Administrator credentials:

  Username: root
  Password : $(kubectl get secret --namespace default happy-panda-mariadb -o jsonpath=&quot;{.data.mariadb-root-password}&quot; | base64 --decode)

To connect to your database:

  1. Run a pod that you can use as a client:

      kubectl run happy-panda-mariadb-client --rm --tty -i --restart='Never' --image  docker.io/bitnami/mariadb:10.3.22-debian-10-r27 --namespace default --command -- bash

  2. To connect to master service (read/write):

      mysql -h happy-panda-mariadb.default.svc.cluster.local -uroot -p my_database

  3. To connect to slave service (read-only):

      mysql -h happy-panda-mariadb-slave.default.svc.cluster.local -uroot -p my_database

To upgrade this helm chart:

  1. Obtain the password as described on the 'Administrator credentials' section and set the 'rootUser.password' parameter as shown below:

      ROOT_PASSWORD=$(kubectl get secret --namespace default happy-panda-mariadb -o jsonpath=&quot;{.data.mariadb-root-password}&quot; | base64 --decode)
      helm upgrade happy-panda stable/mariadb --set rootUser.password=$ROOT_PASSWORD
</code></pre><p>上述信息展示了 release 的当前状态。</p>
<h3 id="安装前自定义-chart">安装前自定义 chart</h3>
<p>上述安装方式只会使用 chart 的默认配置选项。很多时候，我们需要自定义 chart 来指定我们想要的配置。</p>
<p>使用 <code>helm show values</code> 可以查看 chart 中的可配置选项：</p>
<pre><code class="language-console" data-lang="console">$ helm show values stable/mariadb
Fetched stable/mariadb-0.3.0.tgz to /Users/mattbutcher/Code/Go/src/helm.sh/helm/mariadb-0.3.0.tgz
## Bitnami MariaDB image version
## ref: https://hub.docker.com/r/bitnami/mariadb/tags/
##
## Default: none
imageTag: 10.1.14-r3

## Specify a imagePullPolicy
## Default to 'Always' if imageTag is 'latest', else set to 'IfNotPresent'
## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images
##
# imagePullPolicy:

## Specify password for root user
## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#setting-the-root-password-on-first-run
##
# mariadbRootPassword:

## Create a database user
## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-user-on-first-run
##
# mariadbUser:
# mariadbPassword:

## Create a database
## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-on-first-run
##
# mariadbDatabase:
# ...
</code></pre><p>然后，你可以使用 YAML 格式的文件覆盖上述任意配置项，并在安装过程中使用该文件。</p>
<pre><code class="language-console" data-lang="console">$ echo '{mariadbUser: user0, mariadbDatabase: user0db}' &gt; config.yaml
$ helm install -f config.yaml stable/mariadb --generate-name
</code></pre><p>上述命令将为 MariaDB 创建一个名称为 <code>user0</code> 的默认用户，并且授予该用户访问新建的 <code>user0db</code> 数据库的权限。chart 中的其他默认配置保持不变。</p>
<p>安装过程中有两种方式传递配置数据：</p>
<ul>
<li><code>--values</code> (或 <code>-f</code>)：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。</li>
<li><code>--set</code>：通过命令行的方式对指定项进行覆盖。</li>
</ul>
<p>如果同时使用两种方式，则 <code>--set</code> 中的值会被合并到 <code>--values</code> 中，但是 <code>--set</code> 中的值优先级更高。在<code>--set</code> 中覆盖的内容会被被保存在 ConfigMap 中。可以通过 <code>helm get values &lt;release-name&gt;</code> 来查看指定 release 中 <code>--set</code> 设置的值。也可以通过运行 <code>helm upgrade</code> 并指定 <code>--reset-values</code> 字段来清除 <code>--set</code> 中设置的值。</p>
<h4 id="--set-的格式和限制"><code>--set</code> 的格式和限制</h4>
<p><code>--set</code> 选项使用0或多个 name/value 对。最简单的用法类似于：<code>--set name=value</code>，等价于如下 YAML 格式：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">value</span><span class="w">
</span></code></pre></div><p>多个值使用逗号分割，因此 <code>--set a=b,c=d</code> 的 YAML 表示是：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">a</span><span class="p">:</span><span class="w"> </span><span class="l">b</span><span class="w">
</span><span class="w"></span><span class="nt">c</span><span class="p">:</span><span class="w"> </span><span class="l">d</span><span class="w">
</span></code></pre></div><p>支持更复杂的表达式。例如，<code>--set outer.inner=value</code> 被转换成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">outer</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">inner</span><span class="p">:</span><span class="w"> </span><span class="l">value</span><span class="w">
</span></code></pre></div><p>列表使用花括号（<code>{}</code>）来表示。例如，<code>--set name={a, b, c}</code> 被转换成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">name</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">a</span><span class="w">
</span><span class="w">  </span>- <span class="l">b</span><span class="w">
</span><span class="w">  </span>- <span class="l">c</span><span class="w">
</span></code></pre></div><p>从 2.5.0 版本开始，可以使用数组下标的语法来访问列表中的元素。例如 <code>--set servers[0].port=80</code> 就变成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">servers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></code></pre></div><p>多个值也可以通过这种方式来设置。<code>--set servers[0].port=80,servers[0].host=example</code> 变成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">servers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span><span class="w">    </span><span class="nt">host</span><span class="p">:</span><span class="w"> </span><span class="l">example</span><span class="w">
</span></code></pre></div><p>如果需要在 <code>--set</code> 中使用特殊字符，你可以使用反斜线来进行转义；<code>--set name=value1\,value2</code> 就变成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;value1,value2&#34;</span><span class="w">
</span></code></pre></div><p>类似的，你也可以转义点序列。这可能会在 chart 使用 <code>toYaml</code> 函数来解析 annotations，labels，和 node selectors 时派上用场。<code>--set nodeSelector.&quot;kubernetes\.io/role&quot;=master</code> 语法就变成了：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">nodeSelector</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">kubernetes.io/role</span><span class="p">:</span><span class="w"> </span><span class="l">master</span><span class="w">
</span></code></pre></div><p>深层嵌套的数据结构可能会很难用 <code>--set</code> 表达。我们希望 Chart 的设计者们在设计 <code>values.yaml</code> 文件的格式时，考虑到 <code>--set</code> 的使用。（更多内容请查看 <a href="../chart_template_guide/values_files/">Values Files</a>）</p>
<h3 id="更多安装方法">更多安装方法</h3>
<p><code>helm install</code> 命令可以从多个来源进行安装：</p>
<ul>
<li>chart 的 repository（如上所述）</li>
<li>本地 chart 压缩包（<code>helm install foo foo-0.1.1.tgz</code>）</li>
<li>解压后的 chart 目录（<code>helm install foo path/to/foo</code>）</li>
<li>完整的 URL（<code>helm install foo https://example.com/charts/foo-1.2.3.tgz</code>）</li>
</ul>
<h2 id="helm-upgrade-和-helm-rollback升级-release-和失败时恢复">&lsquo;helm upgrade&rsquo; 和 &lsquo;helm rollback&rsquo;：升级 release 和失败时恢复</h2>
<p>当你想升级到 chart 的新版本，或是修改 release 的配置，你可以使用 <code>helm upgrade</code> 命令。</p>
<p>一次升级操作会使用已有的 release 并根据你提供的信息对其进行升级。由于 Kubernetes 的 chart 可能会很大而且很复杂，Helm 会尝试执行最小侵入式升级。即它只会更新自上次发布以来发生了更改的内容。</p>
<pre><code class="language-console" data-lang="console">$ helm upgrade -f panda.yaml happy-panda stable/mariadb
Fetched stable/mariadb-0.3.0.tgz to /Users/mattbutcher/Code/Go/src/helm.sh/helm/mariadb-0.3.0.tgz
happy-panda has been upgraded. Happy Helming!
Last Deployed: Wed Sep 28 12:47:54 2016
Namespace: default
Status: DEPLOYED
...
</code></pre><p>在上面的例子中，<code>happy-panda</code> 这个 release 使用相同的 chart 进行升级，但是使用了一个新的 YAML 文件：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">mariadbUser</span><span class="p">:</span><span class="w"> </span><span class="l">user1</span><span class="w">
</span></code></pre></div><p>我们可以使用 <code>helm get values</code> 命令来看看配置值是否真的生效了：</p>
<pre><code class="language-console" data-lang="console">$ helm get values happy-panda
mariadbUser: user1
</code></pre><p><code>helm get</code> 是一个查看集群中 release 的有用工具。正如我们上面所看到的，<code>panda.yaml</code> 中的新值已经被部署到集群中了。</p>
<p>现在，假如在一次发布过程中，发生了不符合预期的事情，也很容易通过 <code>helm rollback [RELEASE] [REVISION]</code> 命令回滚到之前的发布版本。</p>
<pre><code class="language-console" data-lang="console">$ helm rollback happy-panda 1
</code></pre><p>上面这条命令将我们的 <code>happy-panda</code> 回滚到了它最初的版本。release 版本其实是一个增量修订（revision）。每当发生了一次安装、升级或回滚操作，revision 的值就会加1。第一次 revision 的值永远是1。我们可以使用 <code>helm history [RELEASE]</code> 命令来查看一个特定 release 的修订版本号。</p>
<h2 id="安装升级回滚时的有用选项">安装、升级、回滚时的有用选项</h2>
<p>你还可以指定一些其他有用的选项来自定义 Helm 在安装、升级、回滚期间的行为。请注意这并不是 cli 参数的完整列表。要查看所有参数的说明，请执行 <code>helm &lt;command&gt; --help</code> 命令。</p>
<ul>
<li><code>--timeout</code>：一个 <a href="https://golang.org/pkg/time/#ParseDuration">Go duration</a> 类型的值，用来表示等待 Kubernetes 命令完成的超时时间，默认值为 <code>5m0s</code>。</li>
<li><code>--wait</code>：表示必须要等到所有的 Pods 都处于 ready 状态，PVC 都被绑定，Deployments 都至少拥有最小 ready 状态 Pods 个数（<code>Desired</code>减去 <code>maxUnavailable</code>），并且 Services 都具有 IP 地址（如果是<code>LoadBalancer</code>，则为 Ingress），才会标记该 release 为成功。最长等待时间由 <code>--timeout</code> 值指定。如果达到超时时间，release 将被标记为 <code>FAILED</code>。注意：当 Deployment 的 <code>replicas</code> 被设置为1，但其滚动升级策略中的 <code>maxUnavailable</code> 没有被设置为0时，<code>--wait</code> 将返回就绪，因为已经满足了最小 ready Pod 数。</li>
<li><code>--no-hooks</code>：不运行当前命令的钩子。</li>
<li><code>--recreate-pods</code>（仅适用于 <code>upgrade</code> 和 <code>rollback</code>）：这个参数会导致重建所有的 Pod（deployment 中的 Pod 除外）。（在 Helm 3 中已被废弃）</li>
</ul>
<h2 id="helm-uninstall卸载-release">&lsquo;helm uninstall&rsquo;：卸载 release</h2>
<p>使用 <code>helm uninstall</code> 命令从集群中卸载一个 release：</p>
<pre><code class="language-console" data-lang="console">$ helm uninstall happy-panda
</code></pre><p>该命令将从集群中移除指定 release。你可以通过 <code>helm list</code> 命令看到当前部署的所有 release：</p>
<pre><code class="language-console" data-lang="console">$ helm list
NAME            VERSION UPDATED                         STATUS          CHART
inky-cat        1       Wed Sep 28 12:59:46 2016        DEPLOYED        alpine-0.1.0
</code></pre><p>从上面的输出中，我们可以看到，<code>happy-panda</code> 这个 release 已经被卸载。</p>
<p>在上一个 Helm 版本中，当一个 release 被删除，会保留一条删除记录。而在 Helm 3 中，删除也会移除 release 的记录。如果你想保留删除记录，使用 <code>helm uninstall --keep-history</code>。使用 <code>helm list --uninstalled</code> 只会展示使用了 <code>--keep-history</code> 删除的 release。</p>
<p><code>helm list --all</code> 会展示 Helm 保留的所有 release 记录，包括失败或删除的条目（指定了 <code>--keep-history</code>）：</p>
<pre><code class="language-console" data-lang="console">$  helm list --all
NAME            VERSION UPDATED                         STATUS          CHART
happy-panda     2       Wed Sep 28 12:47:54 2016        UNINSTALLED     mariadb-0.3.0
inky-cat        1       Wed Sep 28 12:59:46 2016        DEPLOYED        alpine-0.1.0
kindred-angelf  2       Tue Sep 27 16:16:10 2016        UNINSTALLED     alpine-0.1.0
</code></pre><p>注意，因为现在默认会删除 release，所以你不再能够回滚一个已经被卸载的资源了。</p>
<h2 id="helm-repo使用-repository">&lsquo;helm repo&rsquo;：使用 repository</h2>
<p>Helm 3 不再附带一个默认的 chart repository。<code>helm repo</code> 提供了一组命令用于添加、列出和移除 repository。</p>
<p>使用 <code>helm repo list</code> 来查看配置的 repository：</p>
<pre><code class="language-console" data-lang="console">$ helm repo list
NAME            URL
stable          https://charts.helm.sh/stable
mumoshu         https://mumoshu.github.io/charts
</code></pre><p>使用 <code>helm repo add</code> 来添加新的 repository：</p>
<pre><code class="language-console" data-lang="console">$ helm repo add dev https://example.com/dev-charts
</code></pre><p>因为 chart 仓库经常在变化，在任何时候你都可以通过执行 <code>helm repo update</code> 命令来确保你的 Helm 客户端是最新的。</p>
<p>使用 <code>helm repo remove</code> 命令来移除仓库。</p>
<h2 id="创建你自己的-charts">创建你自己的 charts</h2>
<p><a href="https://helm.sh/zh/docs/topics/charts/">chart 开发指南</a> 介绍了如何开发你自己的chart。 但是你也可以通过使用 <code>helm create</code> 命令来快速开始：</p>
<pre><code class="language-console" data-lang="console">$ helm create deis-workflow
Creating deis-workflow
</code></pre><p>现在，<code>./deis-workflow</code> 目录下已经有一个 chart 了。你可以编辑它并创建你自己的模版。</p>
<p>在编辑 chart 时，可以通过 <code>helm lint</code> 验证格式是否正确。</p>
<p>当准备将 chart 打包分发时，你可以运行 <code>helm package</code> 命令：</p>
<pre><code class="language-console" data-lang="console">$ helm package deis-workflow
deis-workflow-0.1.0.tgz
</code></pre><p>然后这个 chart 就可以很轻松的通过 <code>helm install</code> 命令安装：</p>
<pre><code class="language-console" data-lang="console">$ helm install deis-workflow ./deis-workflow-0.1.0.tgz
...
</code></pre><p>打包好的 chart 可以上传到 chart 仓库中。查看 chart 仓库服务器中的文档来了解如何上传。</p>
<p>注意：<code>stable</code> 的仓库在 <a href="https://github.com/helm/charts">Kubernetes Charts GitHub
repository</a> 上进行管理。这个项目接受 chart 源码并（在审计后）为你打包。</p>
<h2 id="总结">总结</h2>
<p>这一章介绍了 <code>helm</code> 客户端的基本使用方式，包括搜索，安装，升级，和卸载。也涵盖了一些有用的工具类命令，如<code>helm status</code>，<code>helm get</code>，和 <code>helm repo</code>。</p>
<p>有关这些命令的更多信息，请查看 Helm 的内置帮助命令：<code>helm help</code>。</p>
<p>在下一章中，我们来看一下如何开发 charts。</p>
]]></content>
		</item>
		
		<item>
			<title>kubectl patch</title>
			<link>https://cvvz.github.io/post/k8s-kubectl-patch/</link>
			<pubDate>Sun, 22 Nov 2020 23:16:44 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-kubectl-patch/</guid>
			<description>kubectl patch 用来修改 Kubernetes API 对象的字段。可以通过 --type 参数指定三种不同类型的 patch 方式： strategic：strategic merge patch merge： json merge patch json： json</description>
			<content type="html"><![CDATA[<p><code>kubectl patch</code> 用来修改 Kubernetes API 对象的字段。可以通过 <code>--type</code> 参数指定三种不同类型的 patch 方式：</p>
<ul>
<li><code>strategic</code>：strategic merge patch</li>
<li><code>merge</code>： json merge patch</li>
<li><code>json</code>： json patch</li>
</ul>
<p>实际使用情况：</p>
<ul>
<li>strategic merge patch 用的比较少；大多使用 json merge patch 和 json patch</li>
<li>json merge patch 和 json patch 的具体区别可以查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a></li>
<li>json patch 相比于 json merge patch 使用起来复杂一点，但使用方法更灵活，功能更强大，副作用更少。因此更推荐使用。</li>
</ul>
<h2 id="strategic-merge-patch">strategic merge patch</h2>
<p>这是默认的patch类型，strategic merge patch 在进行 patch 操作时，到底是进行<strong>替换</strong>还是进行<strong>合并</strong>，由 Kubernetes 源代码中字段标记中的 <code>patchStrategy</code> 键的值指定。</p>
<p>具体来说：</p>
<ul>
<li>如果你对deployment的 <code>.spec.template.spec.containers</code> 字段进行 strategic merge patch，那么新的 containers 中的字段值会合并到原来的字段中去，因为 <code>PodSpec</code> 结构体的 <code>Containers</code> 字段的 <code>patchStrategy</code> 为 <code>merge</code>。</li>
<li>如果你对deployment的 <code>.spec.template.spec.tolerations</code> 字段进行 strategic merge patch，那么会用新的 tolerations 字段值将老的字段值直接替换。</li>
</ul>
<h2 id="json-merge-patch">json merge patch</h2>
<p><strong>有相同的字段就替换，没有相同的字段就合并</strong>。这在语义上非常容易理解，但是有以下弊端：</p>
<ul>
<li>键值无法被设置为 <code>null</code>，设置为 <code>null</code> 的字段会直接被 json merge patch 删除掉</li>
<li>操作数组非常吃力。如果你想添加或修改数组中的元素，必须在copy原来的数组，并在其基础上进行改动。因为<strong>新的数组会覆盖原来的数组</strong>。</li>
</ul>
<p>特别是第二点，这导致只要是和数组相关的patch操作，最好使用json patch。</p>
<h2 id="json-patch">json patch</h2>
<p>json patch 的格式如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
    <span class="p">{</span>
        <span class="nt">&#34;op&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;path&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span> <span class="p">,</span>
        <span class="nt">&#34;value&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span>
    <span class="p">}</span>
<span class="p">]</span>
</code></pre></div><p>即由操作、字段路径、新值组成。具体例子查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a>。可以看到这种操作方式非常灵活。</p>
<h2 id="json-patch-转义字符">json patch 转义字符</h2>
<ul>
<li>&ldquo;~&quot;（波浪线）对应的是：&quot;~0&rdquo;</li>
<li>&ldquo;/&quot;（斜杠）对应的是：&quot;~1&rdquo;</li>
</ul>
<p>具体可以查看这个<a href="https://github.com/json-patch/json-patch-tests/issues/42">issue</a>中的讨论。</p>
]]></content>
		</item>
		
		<item>
			<title>浅谈kubernetes监控体系</title>
			<link>https://cvvz.github.io/post/k8s-monitor/</link>
			<pubDate>Fri, 20 Nov 2020 00:24:35 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-monitor/</guid>
			<description>监控和指标 理解监控 我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。 存储使用时序数据库TSDB、前端展示使用grafana、告警</description>
			<content type="html"><![CDATA[<h2 id="监控和指标">监控和指标</h2>
<h3 id="理解监控">理解监控</h3>
<p>我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。</p>
<p>存储使用时序数据库TSDB、前端展示使用grafana、告警系统也有多种开源实现。我重点介绍一下和指标采集相关的内容。</p>
<h3 id="理解指标">理解指标</h3>
<blockquote>
<p><strong>我们所采集的指标 (metrics)，追根溯源，要么来自于操作系统，要么来自于应用进程自身</strong>。</p>
</blockquote>
<p>在kubernetes中，有三种指标需要被关注，分别来自于：</p>
<ul>
<li>kubernetes基础组件。也就是组成kubernetes的应用进程，如api-server、controller-manager、scheduler、kubelet等。</li>
<li>node节点。也就是组成kubernetes的机器。</li>
<li>Pod/容器。也就是业务进程的<strong>运行环境</strong>。</li>
</ul>
<p>基础设施和kubernetes运维人员主要关注前两项指标，保证kubernetes集群的稳定运行。</p>
<p>而业务方开发/运维主要关注<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics">Pod/容器指标</a>，这和以往关注<a href="https://book.open-falcon.org/zh_0_2/faq/linux-metrics.html">操作系统性能指标</a>大不一样。<strong>在云原生时代，业务进程的运行环境从物理机/虚拟机转变为了Pod/容器。可见，Pod/容器就是云原生时代的<code>不可变基础设施</code></strong>。</p>
<h3 id="采集容器指标的过程">采集容器指标的过程</h3>
<ol>
<li>kubelet内置的cAdvisor负责采集容器指标</li>
<li>kubelet对外暴露出API</li>
<li>Promeheus、Metrics-Server（取代了Heapster）通过这些API采集容器指标</li>
</ol>
<h2 id="prometheus">Prometheus</h2>
<p>Prometheus是Kubernetes监控体系的核心。它的<a href="https://prometheus.io/docs/introduction/overview/#architecture">架构</a>如官网的这幅示意图所示：</p>
<figure>
    <img src="/prometheus.png" width="700px"/> 
</figure>

<p>从左到右就分别是采集指标、存储、展示和告警这四大模块。我还是只介绍采集指标相关的内容。</p>
<h3 id="prometheus是如何采集指标的">Prometheus是如何采集指标的</h3>
<ol>
<li>直接采集。Prometheus提供了各语言的<a href="https://prometheus.io/docs/instrumenting/clientlibs/#client-libraries">lib库</a>，使应用能够对外暴露HTTP端口供prometheus拉取指标值。</li>
<li>间接采集。对于无法通过直接引入lib库或改代码的方式接入Prometheus的应用程序和操作系统，则需要借助<a href="https://prometheus.io/docs/instrumenting/exporters/#third-party-exporters">exporter</a>，代替被监控对象来对 Prometheus 暴露出可以被抓取的 Metrics 信息。</li>
</ol>
<h3 id="prometheus是如何采集kubernetes的指标的">Prometheus是如何采集Kubernetes的指标的</h3>
<ul>
<li>kubernetes基础组件：Prometheus是Kubernetes监控体系的核心，所以这些基础组件当然直接使用lib库采集自己的指标并暴露出API。</li>
<li>node节点：操作系统的性能指标肯定只能借助<a href="https://github.com/prometheus/node_exporter#node-exporter">node exporter</a>来采集了。
<blockquote>
<p><strong>如果node exporter运行在容器里，那么为了让容器里的进程获取到主机上的网络、PID、IPC指标，就需要设置<code>hostNetwork: true</code>、<code>hostPID: true</code>、<code>hostIPC: true</code>，来与主机共用网络、PID、IPC这三个namespace</strong>。</p>
</blockquote>
</li>
<li>Pod/容器。如前所述，Prometheus可以通过kubelet(cAdvisor)暴露出来的API采集指标。</li>
</ul>
<h2 id="kubernetes-hpa">kubernetes HPA</h2>
<p>为了automate everything，采集到了性能指标之后，肯定不能只是发送告警，让运维介入，系统应该具备根据指标自动弹性伸缩的能力。<strong>Kubernetes自身具备了水平弹性伸缩的能力，下面介绍和Kubernetes的垂直弹性伸缩(HPA)能力相关的两个内容</strong>。</p>
<h3 id="metrics-server">Metrics-Server</h3>
<p>Metrics-server（heapster的替代品）<strong>从kubelet中</strong>获取Pod的监控指标，并通过<a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">apiserver聚合层</a>的方式暴露API，API路径为：<code>/apis/metrics.k8s.io/</code>，也就是说，当你访问这个api路径时，apiserver会帮你转发到Metrics-server里去处理，而不是自己处理。<strong>这样，Kubernetes中的HPA组件就可以通过访问这个API获得指标来进行垂直扩缩容决策了</strong>。</p>
<blockquote>
<p><code>kubectl top</code>命令也是通过这个API获得监控指标的。</p>
</blockquote>
<h3 id="custom-metrics">Custom Metrics</h3>
<p><strong>但是应用程序往往更依赖进程本身的监控指标（如http请求数、消息队列的大小）而不是运行环境的监控指标做决策</strong>。所以只有Metrics-Server暴露出来的API肯定是不够的，因此，Kubernetes提供了另一个API供应用程序暴露自定义监控指标，路径为<code>/apis/custom.metrics.k8s.io/</code>。</p>
<p>Custom Metrics的玩法应该是这样的：</p>
<ol>
<li>应用程序，或者它的exporter暴露出API供Prometheus采集</li>
<li>造一个自定义Metrics-Server，从Prometheus中获取监控数据</li>
<li>HPA组件通过访问<code>/apis/custom.metrics.k8s.io/</code>进行决策。</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>用树莓派分析函数调用栈</title>
			<link>https://cvvz.github.io/post/call-stack/</link>
			<pubDate>Tue, 03 Sep 2019 18:44:12 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/call-stack/</guid>
			<description>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。 寄存器 分析函数调用栈涉及到的几个特</description>
			<content type="html"><![CDATA[<blockquote>
<p>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。</p>
</blockquote>
<h2 id="寄存器">寄存器</h2>
<p>分析函数调用栈涉及到的几个特殊用途的寄存器如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">ARM</th>
<th style="text-align:center">X86</th>
<th style="text-align:center">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">r11（fp）</td>
<td style="text-align:center">rbp（ebp）</td>
<td style="text-align:center">栈帧指针</td>
</tr>
<tr>
<td style="text-align:center">r13（sp）</td>
<td style="text-align:center">rsp（esp）</td>
<td style="text-align:center">栈顶指针</td>
</tr>
<tr>
<td style="text-align:center">r14（lr）</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center">返回地址</td>
</tr>
<tr>
<td style="text-align:center">r15（pc）</td>
<td style="text-align:center">rip</td>
<td style="text-align:center">指令指针（程序计数器）</td>
</tr>
</tbody>
</table>
<h2 id="函数调用栈">函数调用栈</h2>
<p>如下图（《程序员的自我修养》图10-4）所示：</p>
<figure>
    <img src="/%e6%a0%88.jpg" width="500px"/> 
</figure>

<p>图中，栈帧指针（ebp）指向的内存空间中保存的是上一个栈的栈帧指针（old ebp）。这是X86的情形，在树莓派中分析函数调用栈时发现，ARM的栈帧指针（fp）指向的是函数返回地址。</p>
<p>这只是不同架构CPU的底层实现的不同，并没有优劣之分。</p>
<h3 id="入栈过程">入栈过程</h3>
<p>一个函数的调用过程可以分为如下几步：</p>
<ul>
<li>首先压栈的是参数，且<strong>从右向左</strong>依次压栈；</li>
<li>接着压入返回地址；</li>
<li>接着被调函数执行“标准开头”（x86）：</li>
</ul>
<pre><code class="language-x86asm" data-lang="x86asm">push rbp
mov rbp rsp
</code></pre><p>“标准开头”执行过程如下：</p>
<ul>
<li>首先rbp入栈；</li>
<li>rbp入栈后，rsp自动加8（64位），rsp此时指向存放rbp的栈帧地址；</li>
<li>接着令<code>%rbp=%rsp</code>，这就使得rbp指向存放着上一个栈的rbp的内存地址。</li>
</ul>
<p>而ARM（32位）的“标准开头”长这样：</p>
<pre><code class="language-armasm" data-lang="armasm">push {fp, lr}
add fp, sp, #4
</code></pre><ul>
<li>返回地址(lr)入栈</li>
<li>栈帧指针(fp)入栈</li>
<li>接着令<code>%fp=%sp+4</code>，也就是<strong>使fp（栈帧指针）指向存放返回地址的内存</strong>。</li>
</ul>
<p>不论栈帧指针指向的是上一个栈帧指针，还是返回地址，都能<strong>通过函数的栈帧指针偏移找到调用函数的地址，因此根据栈帧指针的链式关系，可以回溯出整个函数的调用关系链</strong>。这对于一些复杂问题的定位是非常有帮助的。</p>
<blockquote>
<p>GCC的编译选项<code>--fomit-frame-pointer</code>可以使程序不使用栈帧指针，而使用栈指针顶定位函数的局部变量、参数、返回地址等。这么做的好处是可以多出一个寄存器（栈帧指针）供使用，程序运行速度更快，但是就没发很方便的使用GDB进行调试了。</p>
</blockquote>
<h3 id="出栈过程">出栈过程</h3>
<p>出栈与入栈动作刚好相反。</p>
<p>x86的“标准结尾”如下：</p>
<pre><code class="language-x86asm" data-lang="x86asm">leaveq
retq
</code></pre><p>实际上<code>leaveq</code>内部分为两条指令：</p>
<pre><code class="language-x86asm" data-lang="x86asm">movq %rbp, %rsp
popq %rbp
</code></pre><p>所以，出栈过程可以分解为如下三步：</p>
<ul>
<li>第一步是通过将rbp地址赋给rsp，即此时rsp指向的内存存放的是上一个栈的rbp。</li>
<li>第二步弹出栈顶的数据到rbp中，即rbp指向上一个栈的栈底，出栈动作导致rsp自增，于是rsp此时指向的内存中存放函数返回地址；</li>
<li>第三步通过<code>retq</code>指令将栈顶地址pop到rip，即rip此时指向函数退出后的下一条指令，rsp则指向上一个栈的栈顶。</li>
</ul>
<p>这三步做完后，rsp、rbp、rip就恢复到调用函数以前的现场。</p>
<p>ARM的行为和x86一致，它的“标准结尾”长这样：</p>
<pre><code class="language-armasm" data-lang="armasm">sub sp, fp, #4
pop {fp, pc}
</code></pre><h2 id="基于树莓派3分析函数调用栈">基于树莓派3分析函数调用栈</h2>
<p>我在树莓派3中运行了如下所示的C语言代码，并用GDB进行了调试：</p>
<blockquote>
<p>树莓派3使用的是<strong>32位、arm架构CPU</strong>，因此下面的调试过程涉及到的寄存器以及地址信息和64位x86 CPU不同</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="kt">void</span> <span class="nf">test2</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">ii</span><span class="p">;</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">char</span> <span class="nf">test</span><span class="p">(</span><span class="kt">char</span> <span class="n">c</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;%c&#34;</span><span class="p">,</span><span class="n">c</span><span class="p">);</span>
    <span class="n">test2</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">c</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">c</span> <span class="o">=</span> <span class="sc">&#39;a&#39;</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">ret</span><span class="p">;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><h3 id="分析函数调用入栈过程">分析函数调用（入栈）过程</h3>
<p>使用GDB进行调试，将断点打在main函数调用test之前，并使用<code>disassemble</code>查看反汇编结果：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) b *0x000104bc
Breakpoint 2 at 0x104bc: file main.c, line 21.
(gdb) disassemble /m main
Dump of assembler code for function main:
18 {
   0x000104a0 &lt;+0&gt;: push {r11, lr}
   0x000104a4 &lt;+4&gt;: add r11, sp, #4
   0x000104a8 &lt;+8&gt;: sub sp, sp, #8

19 char c = 'a';
   0x000104ac &lt;+12&gt;: mov r3, #97 ; 0x61
   0x000104b0 &lt;+16&gt;: strb r3, [r11, #-5]

20 char ret;
21 ret = test(c);
   0x000104b4 &lt;+20&gt;: ldrb r3, [r11, #-5]
   0x000104b8 &lt;+24&gt;: mov r0, r3
=&gt; 0x000104bc &lt;+28&gt;: bl 0x10468 &lt;test&gt;
   0x000104c0 &lt;+32&gt;: mov r3, r0
   0x000104c4 &lt;+36&gt;: strb r3, [r11, #-6]

22 return 0;
   0x000104c8 &lt;+40&gt;: mov r3, #0

23 }
   0x000104cc &lt;+44&gt;: mov r0, r3
   0x000104d0 &lt;+48&gt;: sub sp, r11, #4
   0x000104d4 &lt;+52&gt;: pop {r11, pc}

End of assembler dump.
</code></pre><p>查看此时栈帧指针和栈顶指针的值：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) i r r11 sp
r11            0x7efffaec 2130705132
sp             0x7efffae0 0x7efffae0
(gdb) x /xw 0x7efffaec
0x7efffaec: 0x76e8f678
(gdb) info symbol 0x76e8f678
__libc_start_main + 276 in section .text of /lib/arm-linux-gnueabihf/libc.so.6
</code></pre><p>可以看到，栈帧指针指向的返回地址是<code>__libc_start_main + 276</code>，即<strong>main函数是由__libc_start_main调用的</strong>。</p>
<p>由前面分析得知，栈帧指针-4地址处存放的是上一个函数的栈帧指针，于是我们继续向上追溯<code>__libc_start_main</code>的调用者地址，可以发现其值为0：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) x /xw 0x7efffaec-4
0x7efffae8: 0x00000000
</code></pre><p><strong>因此可以认为<code>__libc_start_main</code>是所有进程真正的起点。</strong></p>
<p>接着执行调用test函数的命令，使用<code>si</code>单步运行，并查看汇编指令：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) si
test (c=0 '\000') at main.c:10
10 {
(gdb) disassemble
Dump of assembler code for function test:
=&gt; 0x00010468 &lt;+0&gt;: push {r11, lr}
   0x0001046c &lt;+4&gt;: add r11, sp, #4
   0x00010470 &lt;+8&gt;: sub sp, sp, #16
   0x00010474 &lt;+12&gt;: mov r3, r0
   0x00010478 &lt;+16&gt;: strb r3, [r11, #-13]
   0x0001047c &lt;+20&gt;: ldrb r3, [r11, #-13]
   0x00010480 &lt;+24&gt;: mov r0, r3
   0x00010484 &lt;+28&gt;: bl 0x10300 &lt;putchar@plt&gt;
   0x00010488 &lt;+32&gt;: ldr r0, [r11, #-8]
   0x0001048c &lt;+36&gt;: bl 0x10440 &lt;test2&gt;
   0x00010490 &lt;+40&gt;: ldrb r3, [r11, #-13]
   0x00010494 &lt;+44&gt;: mov r0, r3
   0x00010498 &lt;+48&gt;: sub sp, r11, #4
   0x0001049c &lt;+52&gt;: pop {r11, pc}
End of assembler dump.
(gdb) i r $lr
lr             0x104c0 66752
(gdb) info symbol $lr
main + 32 in section .text of /root/main
</code></pre><p>可以看到此时lr寄存器中保存的指令即调用test后的下一条指令。继续向下执行：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) ni
0x0001046c 10 {
(gdb) i r r11 sp
r11            0x7efffaec 2130705132
sp             0x7efffad8 0x7efffad8
</code></pre><p>观察到将r11和lr入栈后，sp减少了8字节，不难猜测，高4字节存放了lr的值（返回地址），低4字节存放了sp的值（上一个栈的栈帧指针）：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) x /xw 0x7efffad8
0x7efffad8: 0x7efffaec
(gdb) x /xw 0x7efffadc
0x7efffadc: 0x000104c0
(gdb) i r $lr $r11
lr             0x104c0 66752
r11            0x7efffaec 2130705132
</code></pre><p>继续执行：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) ni
0x00010470 10 {
(gdb) i r $r11
r11            0x7efffadc 2130705116
</code></pre><p>此时r11指向的是函数返回地址，而不是像x86一样指向上一个栈帧指针，和前面所说的一致。</p>
<h2 id="分析函数返回出栈过程">分析函数返回（出栈）过程</h2>
<p>test函数的汇编指令如下所示：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) disassemble /m test
Dump of assembler code for function test:
10 {
   0x00010468 &lt;+0&gt;:	push	{r11, lr}
   0x0001046c &lt;+4&gt;:	add	r11, sp, #4
   0x00010470 &lt;+8&gt;:	sub	sp, sp, #16
   0x00010474 &lt;+12&gt;:	mov	r3, r0
   0x00010478 &lt;+16&gt;:	strb	r3, [r11, #-13]

11		int i;
12		printf(&quot;%c&quot;,c);
   0x0001047c &lt;+20&gt;:	ldrb	r3, [r11, #-13]
   0x00010480 &lt;+24&gt;:	mov	r0, r3
   0x00010484 &lt;+28&gt;:	bl	0x10300 &lt;putchar@plt&gt;

13		test2(i);
   0x00010488 &lt;+32&gt;:	ldr	r0, [r11, #-8]
   0x0001048c &lt;+36&gt;:	bl	0x10440 &lt;test2&gt;

14		return c;
   0x00010490 &lt;+40&gt;:	ldrb	r3, [r11, #-13]

15	}
   0x00010494 &lt;+44&gt;:	mov	r0, r3
=&gt; 0x00010498 &lt;+48&gt;:	sub	sp, r11, #4
   0x0001049c &lt;+52&gt;:	pop	{r11, pc}

End of assembler dump.
</code></pre><p>函数运行完毕进入出栈流程的执行过程分为如下几步：</p>
<ul>
<li>首先通过 <code>sub sp, r11, #4</code> 将栈顶指针指向上一个栈帧指针</li>
<li>接着通过 <code>pop {r11, pc}</code> 将上一个栈帧指针赋值给r11，并将返回地址赋值给pc</li>
<li>两次pop后，栈顶指针自动往栈底方向退两次</li>
</ul>
<p>最终，栈顶指针（sp）、栈帧指针（r11）和指令指针（pc）都还原成了main函数调用test前的样子，用GDB查看寄存器内容证实了这一点：</p>
<pre><code class="language-armasm" data-lang="armasm">(gdb) disassemble 
Dump of assembler code for function main:
   0x000104a0 &lt;+0&gt;:	push	{r11, lr}
   0x000104a4 &lt;+4&gt;:	add	r11, sp, #4
   0x000104a8 &lt;+8&gt;:	sub	sp, sp, #8
   0x000104ac &lt;+12&gt;:	mov	r3, #97	; 0x61
   0x000104b0 &lt;+16&gt;:	strb	r3, [r11, #-5]
   0x000104b4 &lt;+20&gt;:	ldrb	r3, [r11, #-5]
   0x000104b8 &lt;+24&gt;:	mov	r0, r3
   0x000104bc &lt;+28&gt;:	bl	0x10468 &lt;test&gt;
=&gt; 0x000104c0 &lt;+32&gt;:	mov	r3, r0
   0x000104c4 &lt;+36&gt;:	strb	r3, [r11, #-6]
   0x000104c8 &lt;+40&gt;:	mov	r3, #0
   0x000104cc &lt;+44&gt;:	mov	r0, r3
   0x000104d0 &lt;+48&gt;:	sub	sp, r11, #4
   0x000104d4 &lt;+52&gt;:	pop	{r11, pc}
End of assembler dump.
(gdb) i r r11 sp pc
r11            0x7efffaec	2130705132
sp             0x7efffae0	0x7efffae0
pc             0x104c0	0x104c0 &lt;main+32&gt;
</code></pre>]]></content>
		</item>
		
		<item>
			<title>安全知识总结</title>
			<link>https://cvvz.github.io/post/about-computer-security/</link>
			<pubDate>Thu, 22 Aug 2019 12:38:04 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/about-computer-security/</guid>
			<description>加解密算法 对称加密： 用同一个秘钥进行加密和解密，代表算法有AES/DES/RC2/RC5等； 非对称加密： 一次产生公钥和私钥两个秘钥，任意一个</description>
			<content type="html"><![CDATA[<h2 id="加解密算法">加解密算法</h2>
<p><strong>对称加密：</strong> 用同一个秘钥进行加密和解密，代表算法有<code>AES/DES/RC2/RC5</code>等；</p>
<p><strong>非对称加密：</strong> 一次产生公钥和私钥两个秘钥，任意一个都能进行加密，解密则需要用另外一个。具体的用法是：公钥用来“加密”（相应的私钥用来解密），私钥用来“签名”（相应的公钥用来校验）。代表算法有<code>RSA/DSA/ECC/DH</code>等。</p>
<p><strong>摘要：</strong> 摘要是对数据计算Hash值，Hash值不可逆，是一种单向加密。<code>shadow</code>文件中保存的用户密码就是密码明文的Hash值。代表算法有<code>MD5/SHA256</code>等。</p>
<h2 id="ssl协议">SSL协议</h2>
<p>SSL协议工作在传输层和应用层之间。在TCP协议的三次握手之后，进行SSL协议的握手。</p>
<p>SSL握手过程：</p>
<ul>
<li>客户端发送随机数x和自己支持的加密算法</li>
<li>服务端发送随机数y、公钥和选择的加密算法</li>
<li>客户端发送通过公钥加密的随机数z的密文</li>
<li>客户端、服务端用xyz算出对称加密的密钥</li>
<li>双方进行对称加密通信。</li>
</ul>
<h2 id="ssh协议">SSH协议</h2>
<h3 id="密码登录">密码登录</h3>
<ul>
<li>主机将自己的公钥（主机密钥HostKey）发到客户端（HostKey路径在sshd的配置文件中配置）</li>
<li>客户端计算公钥指纹（摘要），询问用户是否信任该kostkey，信任则将key值记录在known_hosts中，下次登录相同服务器时若hostkey相同不必再次确认；否则提示hostkey不一致</li>
<li>用户输入密码，客户端使用公钥加密密码明文并发送到服务端，服务端使用私钥解密并进行密码校验。</li>
</ul>
<p>由于存在发送服务器公钥的过程，因此存在中间人攻击的安全隐患。</p>
<h3 id="公钥登录">公钥登录</h3>
<p>SSH公钥登录解决了SSH协议中的中间人攻击的问题。</p>
<ul>
<li>用户事先生成一对公/私钥，将公钥提前导入到服务器，</li>
<li>登录时，服务器首先发送一个随机数到客户端，</li>
<li>客户端使用私钥加密随机数返回服务端，</li>
<li>服务端使用公钥校验通过则允许登录。</li>
</ul>
<h2 id="中间人攻击">中间人攻击</h2>
<p>SSL协议以及SSH密码登录方式，都存在着中间人攻击的威胁，主要安全隐患在于握手过程中服务端发送的公钥可能被中间人截取，客户端不能确定服务端发送的公钥是否可信。</p>
<h2 id="证书">证书</h2>
<p>证书解了服务端公钥不可信的问题。</p>
<p>证书中记录了服务器的公钥信息，服务器不直接发送公钥，而是发送从CA中心申请到的证书。CA中心把公钥及其他证书信息一起进行摘要计算，再对其进行签名，最终的证书中存放的是公钥、证书信息、数字签名。</p>
<p>因为有了CA中心的数字签名，只要用相应的CA中心的公钥对签名进行校验（即比较解密后的摘要值和本地计算的摘要值是否相同）通过，就能安全使用公钥进行加密。</p>
<p>CA中心的公钥一般预置在操作系统中的根CA证书中。既然CA中心的公钥是用来对签名进行校验的，那么相应的，这个根CA证书就是用来对服务器发来的证书进行校验的。</p>
<h2 id="证书链">证书链</h2>
<p>一般我们不会直接拿根CA证书对应的私钥去做证书的签发，因为频繁使用根证书对应的私钥会增加其泄露的可能性。</p>
<p>安全的做法是：CA中心给二级CA中心签发一个证书（即二级CA证书，二级CA中心严格保存其对应的私钥），二级CA中心再给三级CA中心签发证书&hellip;依次类推。</p>
<p>因此，服务提供者去N级CA中心签发证书时，生成的不再是证书，而是<code>证书链</code>，证书链中依次记录着服务器证书、N级CA证书、N-1级CA证书&hellip;二级CA证书。证书校验时，用根CA证书校验二级CA证书、二级CA证书校验三级CA证书&hellip;最后N级校验服务器证书，只有全部校验通过，服务器证书才算被客户端校验通过。</p>
<h2 id="浏览器通过https协议访问网站的过程">浏览器通过HTTPS协议访问网站的过程</h2>
<ol>
<li>通过本地的DNS配置文件找到DNS服务器地址。</li>
<li>DNS服务器将网址解析为ip地址返回。</li>
<li>本机通过链路层的arp协议找到局域网的路由器。（二层）</li>
<li>路由器通过ip地址路由寻址找到ip地址对应的主机。（三层）</li>
<li>主机通过TCP协议找到本机的端口号（进程listen）。（四层）</li>
<li>TCP三次握手。</li>
<li><strong>使用证书</strong>进行SSL握手（主机将自己的证书链发到浏览器，浏览器使用操作系统预置CA证书进行校验，校验不通过会提示链接不安全的风险）。（SSL层）</li>
<li>服务器进程和浏览器进程在应用层使用HTTP协议交换数据。（七层）</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>进程和线程</title>
			<link>https://cvvz.github.io/post/process-and-thread/</link>
			<pubDate>Sun, 23 Jun 2019 20:34:56 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/process-and-thread/</guid>
			<description>从“程序”开始 对于UNIX操作系统，程序是存放在磁盘上的ELF文件（可以通过file命令查看文件类型） 对于windows操作系统，程序是存放</description>
			<content type="html"><![CDATA[<h2 id="从程序开始">从“程序”开始</h2>
<ul>
<li>对于UNIX操作系统，程序是存放在磁盘上的<strong>ELF文件</strong>（可以通过<code>file</code>命令查看文件类型）</li>
<li>对于windows操作系统，程序是存放在磁盘上的<strong>PE文件</strong>，其中最常见的是<code>.exe</code>文件。</li>
</ul>
<p>编译器将高级语言编写成的程序编译成机器码，操作系统将ELF文件读入内存后，ELF文件中的<strong>代码段</strong>也就是CPU可以执行的机器码（可以通过<code>readelf</code>命令查看ELF文件的代码段内容），CPU从内存中读取机器码并执行。</p>
<h2 id="为进程分配资源">为进程分配资源</h2>
<p>进程产生的标志是：内核为每一个进程都分配了一个<code>task_struct</code>结构体，在<code>task_struct</code>中记录了这个进程所拥有的资源，如全局变量、虚拟内存等，所以说<strong>进程是资源分配的最小单位</strong>。</p>
<h2 id="调度线程">调度线程</h2>
<p><strong>线程是CPU调度的最小单位</strong>，也就是说<strong>内核进行调度的对象实际上是线程，而进程是负责为线程提供共享资源的</strong>。</p>
<p>一个进程中的多个线程共享这个进程的资源，但是<strong>它们虽然共享同一片虚拟内存，自身却拥有这片虚拟内存中的不同的栈空间</strong>；</p>
<h2 id="通信方式">通信方式</h2>
<p>由于同一进程中的线程共享资源，所以通信非常方便，直接读写同一块用户态内存即可，但是这必然就涉及到互斥和原子性问题。</p>
<p>而进程要实现通信则需要借助内核和文件，所有的IPC，都是把内核和文件充当交换信息的桥梁。</p>
<h2 id="上下文切换">上下文切换</h2>
<blockquote>
<p>同一进程中的线程上下文切换，简称<strong>线程上下文切换</strong>。</p>
<p>不同进程中的线程上下文切换，简称<strong>进程上下文切换</strong>。</p>
</blockquote>
<p>不管是线程上下文切换，还是进程上下文切换，都会涉及CPU寄存器和程序计数器的保存和更新。<strong>因此都涉及CPU上下文切换</strong>。</p>
<p>由于线程共享进程中的虚拟内存空间，所以线程上下文切换时，<strong>不需要更新虚拟内存到物理内存的内存映射表</strong>。而进程上下文切换时，则要更新虚拟内存到物理内存的内存映射表。</p>
<p>当内核找不到虚拟内存到物理内存的映射关系时，便会产生<code>缺页中断</code>。所以<strong>进程上下文切换后，程序执行更容易产生缺页中断</strong>。</p>
<h2 id="怎么理解linux中的线程是以进程的方式实现的">怎么理解Linux中的线程是以进程的方式实现的</h2>
<ul>
<li>对于支持线程的操作系统而言，如果一个进程中有N个线程，则存在一个进程描述符，依次轮流指向N个线程。这个进程描述符指明共享资源，包括内存空间和打开的文件。而每一个线程描述它们自己独享的资源。也就是说<strong>内核中描述线程的结构体和描述进程的结构体不同</strong>。</li>
<li>而在Linux中，则有N个<code>task_struct</code>数据结构，只是这些数据结构的某些资源项是共享的，某些是独占的。</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>抓包解读smtp和tls协议</title>
			<link>https://cvvz.github.io/post/smtp-with-tls/</link>
			<pubDate>Sat, 22 Jun 2019 23:21:54 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/smtp-with-tls/</guid>
			<description>背景：某进程调用 libcurl 提供的 curl_easy_perform 接口与邮箱服务器进行smtp通信时，服务端返回56(CURLE_RECV_ERROR)错误。由于服务端日志信息不足</description>
			<content type="html"><![CDATA[<blockquote>
<p>背景：某进程调用 <code>libcurl</code> 提供的 <code>curl_easy_perform</code> 接口与邮箱服务器进行smtp通信时，服务端返回56(<code>CURLE_RECV_ERROR</code>)错误。由于服务端日志信息不足，于是想到可以通过抓包查看建立smtp连接时的错误信息。</p>
</blockquote>
<h3 id="第一次抓包">第一次抓包</h3>
<figure>
    <img src="/smtp-with-tls.png" width="1050px"/> 
</figure>

<p>从图中可以清晰看出整个SMTP连接从建立到断开的全过程：</p>
<ol>
<li>通过三次握手建立TCP连接</li>
<li>客户端向服务端发送 <code>STARTTLS</code>，服务端回复 <code>220 Ready to start TLS</code>后，SMTP协议准备建立安全信道</li>
<li><a href="https://cvvz.github.io/post/about-computer-security/#ssl%E5%8D%8F%E8%AE%AE">TLS协议握手</a>建立连接</li>
<li>TLS协议建立连接后，<strong>应用层协议的内容就被加密了，抓包只能看到图中的<code>Application Data</code>字样</strong>。</li>
<li>通过TCP四次挥手断开连接</li>
</ol>
<blockquote>
<p>由于smtp协议内容被加密了，因此需要先去掉TLS连接，再抓包分析。</p>
</blockquote>
<h3 id="第二次抓包">第二次抓包</h3>
<figure>
    <img src="/smtp-without-tls.png" width="1050px"/> 
</figure>

<p>从第二次抓包得到的信息，可以看出连接断开的根因是smtp服务器返回了<code>502 VRFY disallowed</code>。</p>
<p>接下来网上搜索<code>smtp VRFY disallowed</code>相关内容就能找到答案了：原来<code>libcurl</code>从7.34.0版本开始，要求SMTP客户端显式的设置 <code>CURLOPT_UPLOAD</code> 选项，否则libcurl将发送<code>VRFY</code>命令。而一般服务器出于安全性的考虑，会禁止执行VRFY命令。（参考<a href="https://issues.dlang.org/show_bug.cgi?id=13042">https://issues.dlang.org/show_bug.cgi?id=13042</a> ）</p>
<blockquote>
<p>通过抓包还证实了，不进行加密通信的应用层数据是明文传输的，smtp协议中的用户名密码被一览无余。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>gdb中的多线程和信号处理</title>
			<link>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</link>
			<pubDate>Mon, 10 Jun 2019 11:44:52 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</guid>
			<description>多线程调试 使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。 All-Stop 任何一个线程在断点处hang住时，所有其他线</description>
			<content type="html"><![CDATA[<h2 id="多线程调试">多线程调试</h2>
<p>使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。</p>
<h3 id="all-stop">All-Stop</h3>
<blockquote>
<p>任何一个线程在断点处hang住时，所有其他线程也会hang住。默认为all-stop模式。</p>
</blockquote>
<ol>
<li>
<p>在all-stop模式中，当一个线程到达断点或产生信号，GDB将自动选择该线程作为当前线程并停住（提示<code>Switching to Thread n</code>），并且其他线程也都会停止运行；</p>
</li>
<li>
<p>当执行<code>continue</code>、<code>until</code>、<code>finish</code>、<code>next</code>、<code>step</code>等使线程继续运行，所有线程会同时继续运行，直到某一个线程再次被stop，然后该线程成为当前线程。</p>
</li>
<li>
<p>这里还存在这样一种情况：当你单步跟踪某个线程时，这个线程一定是执行了某条完整语句后在下一条语句前停住，<strong>但是这段时间里其他线程可能执行了半条、一条或多条语句</strong>。</p>
</li>
<li>
<p>在all-stop模式下，可以通过设定<code>scheduler-locking</code>（调度器锁定）来控制CPU调度器的行为从而控制多线程的并发运行行为。</p>
<ul>
<li><code>set scheduler-locking off</code>：默认调度器锁定为关，也就是CPU也可以进行自由调度，那么所有线程是“同进同止”的，一起stop，一起继续运行，竞争CPU资源；</li>
<li><code>set scheduler-locking on</code>：开启调度器锁定，不允许CPU自由调度，CPU只能执行当前线程中的指令，其他线程一直处于stop状态；</li>
</ul>
</li>
</ol>
<h3 id="non-stop">Non-Stop</h3>
<blockquote>
<p>任何一个线程被stop甚至单步调试时，其他线程可以自由运行。</p>
</blockquote>
<ol>
<li>通过<code>set non-stop on</code>手动开启non-stop模式。一般non-stop模式搭配异步执行命令使用。</li>
<li>GDB的可执行命令分为两种：同步执行和异步执行。
<ul>
<li>同步执行：即执行一条命令后，要等待有线程被stop了才会在弹出命令提示符。这是默认执行模式。</li>
<li>异步执行：立刻返回弹出命令提示符。打开命令异步执行模式开关的命令是<code>set target-async on</code>。</li>
</ul>
<blockquote>
<p>在命令后跟<code>&amp;</code>表示该命令以异步的方式执行，如<code>attach&amp;</code>、<code>continue&amp;</code>等。</p>
</blockquote>
</li>
<li>non-stop模式下可使用<code>interrupt</code>停止当前运行中的线程，<code>interrupt -a</code>停下所有线程。</li>
</ol>
<h2 id="信号处理">信号处理</h2>
<p>GDB能够检测到程序中产生的信号，并进行针对性的处理。通过<code>info handle</code>查看对所有信号的处理方式：</p>
<ul>
<li>Stop：检测到信号是否停住程序的运行；</li>
<li>Print：是否打印收到该信号的信息；</li>
<li>Pass to program：是否把该信号传给进程处理（或者说是否屏蔽该信号，无法屏蔽<code>SIGKILL</code>和<code>SIGSTOP</code>信号）</li>
</ul>
<p>通过<code>handle SIG</code>来指定某个信号的处理方式。</p>
]]></content>
		</item>
		
		<item>
			<title>解剖进程虚拟内存空间</title>
			<link>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</link>
			<pubDate>Fri, 07 Jun 2019 23:14:03 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</guid>
			<description>对于32位 x86 Linux操作系统，典型的进程地址空间如下图所示： 每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFF</description>
			<content type="html"><![CDATA[<p>对于<strong>32位 x86 Linux操作系统</strong>，典型的进程地址空间如下图所示：</p>
<figure>
    <img src="/linuxFlexibleAddressSpaceLayout.png" width="750px"/> 
</figure>

<p>每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFFFFFF，共4GB。</p>
<p>进程地址空间从低到高依次是：</p>
<ul>
<li><strong>Text Segment：</strong> 机器指令，只读，一个程序的多个进程共享一个正文段。</li>
</ul>
<blockquote>
<p>如果进程带有调试信息，可以通过<code>addr2line</code> + 正文段地址获得对应的源代码位置。</p>
</blockquote>
<ul>
<li>
<p><strong>Data Segment：</strong> 具有初值的全局/静态变量。</p>
</li>
<li>
<p><strong>BSS Segment：</strong> 未赋初值的全局/静态变量。</p>
</li>
<li>
<p><strong>Heap：</strong> 堆。堆从低地址向高地址生长。堆区内存在分配过程中可能产生内存碎片：</p>
</li>
</ul>
<p><img src="/fragmentedHeap.png" alt="内存碎片" title="内存碎片"></p>
<blockquote>
<p>申请堆内存的接口是阻塞接口，即可能因为暂时分配不到够大的堆空间导致进程让出CPU。</p>
</blockquote>
<ul>
<li>
<p><strong>Memory Mapping Segment：</strong> 内存映射区。动态库、mmap、共享内存使用的都是内存映射区。</p>
</li>
<li>
<p><strong>Stack：</strong> 栈。栈从高地址向低地址生长。进程栈空间的总大小可通过
<code>ulimit -s</code>查看，默认为8MB。栈中不仅存放着局部变量，<strong>每次函数调用时，参数、返回地址、寄存器值等都会进行压栈。</strong></p>
</li>
<li>
<p><strong>Kernel space：</strong> 进程地址空间的最高1GB是内核空间。<strong>内核空间被所有进程共享</strong>，但是用户态进程只有通过系统调用陷入内核态才能执行内核态代码。</p>
</li>
</ul>
<blockquote>
<p>参考文章：<a href="https://manybutfinite.com/post/anatomy-of-a-program-in-memory/">https://manybutfinite.com/post/anatomy-of-a-program-in-memory/</a></p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>Git笔记</title>
			<link>https://cvvz.github.io/post/usage-of-git/</link>
			<pubDate>Sun, 02 Jun 2019 23:41:24 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/usage-of-git/</guid>
			<description>整理一下最近学习的git知识，以及平时常用的git功能。 .git 使用git init或clone一个远端仓，会在本地建立一个.git目录。这个目录是</description>
			<content type="html"><![CDATA[<blockquote>
<p>整理一下最近学习的git知识，以及平时常用的git功能。</p>
</blockquote>
<h2 id="git">.git</h2>
<p>使用git init或clone一个远端仓，会在本地建立一个.git目录。<strong>这个目录是git仓的全部，把.git拷贝到其他目录下，就能在该目录下建立一个一模一样的git仓</strong>。</p>
<h2 id="缓存区staged">缓存区（staged）</h2>
<ul>
<li>对working derictoy中的文件做的改动，他们的状态是unstaged</li>
<li>使用 <code>git add</code>/<code>git rm</code>/<code>git mv</code> 将其送入缓存区（staged）</li>
<li>使用 <code>git commit</code> 提交缓存区中记录的改动。</li>
<li><code>git diff {filename}</code> 可以查看unstaged和staged中文件的不同</li>
<li><code>git diff --staged {filename}</code> 可以查看staged中的文件和原文件的不同</li>
<li>注意staged和<code>stash</code>的区别</li>
</ul>
<h2 id="上游分支">上游分支</h2>
<p><code>git clone</code>可以通过参数 <code>-b</code> 来指定clone远端仓库到本地后拉取哪条分支，不指定则默认拉取<code>master</code>；远端仓库中必须存在同名分支，作为本地分支的上游分支。</p>
<p>通过<code>git branch -vv</code> 或 <code>git status</code> 命令可以查看本地分支相比上游分支领先/落后多少个commit。</p>
<p><code>git checkout -b {local_branch} {remote_branch}</code>用来创建并切换分支，并指定该分支的上游分支。</p>
<h2 id="revert和reset">revert和reset</h2>
<p><code>git reset</code>把HEAD指针指向到某一个commit id，这次commit之后的所有commit都会被删除。</p>
<p><code>git revert</code>用来撤销某一次commit带来的变化，不会影响其他commit。revert本身也需要commit。</p>
<p>非fast-forward形式合并两条分支时，git会自动生成一个合并提交。如果想回退某条分支的merge操作，可以revert这次合并提交的commit，git会让你选择留下这次合并提交的哪一个父分支，另一个父分支所作的改动会被回退。</p>
<h2 id="如何修改一次历史commit">如何修改一次历史commit</h2>
<p>执行<code>git rebase -i {commitid}^</code>（commitid是想要修改的那次提交），git会以commitid的前一次提交作为base，采用交互式的方式，重新提交后面的每一次commit，将想要修改的那一次的提交命令设置为edit即可。</p>
]]></content>
		</item>
		
		<item>
			<title>进程间通信</title>
			<link>https://cvvz.github.io/post/ipc/</link>
			<pubDate>Fri, 02 Nov 2018 22:34:20 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/ipc/</guid>
			<description>进程间通信的六种方式： 管道 共享内存 消息队列 信号量 信号 socket 管道 管道机制和UNIX系统的文件系统密切关联，使用管道和使用文件系统非常类似。实际上使</description>
			<content type="html"><![CDATA[<p>进程间通信的六种方式：</p>
<ul>
<li>管道</li>
<li>共享内存</li>
<li>消息队列</li>
<li>信号量</li>
<li>信号</li>
<li>socket</li>
</ul>
<h1 id="管道">管道</h1>
<p>管道机制和UNIX系统的文件系统密切关联，使用管道和使用文件系统非常类似。实际上使用<strong>管道可以看成是创建了一个不会残留的临时文件，一个进程写文件，另一个进程读文件，从而实现了进程间通信</strong>。</p>
<p>管道分为 <strong>匿名管道</strong> 和 <strong>FIFO</strong>。</p>
<h2 id="匿名管道">匿名管道</h2>
<p>使用 <code>pipe</code> 函数创建匿名管道。它返回两个文件描述符，<code>fd[0]</code>是管道的读端，<code>fd[1]</code>是写端。</p>
<p>如果进程只调用<code>pipe</code>，那么只能自写自读，基本没什么用。</p>
<p>因此，<strong>使用<code>pipe</code>创建管道后，必然要使用 <code>fork</code> 创建子进程，这样就可以做到父子进程使用不同的fd进行读写通信</strong>。</p>
<h3 id="popen">popen</h3>
<p>库函数 <code>popen</code> 就是使用匿名管道实现的。函数原型：</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="n">FILE</span> <span class="o">*</span> <span class="n">popen</span><span class="err">（</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">cmdstring</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">type</span><span class="err">）</span><span class="p">;</span>
</code></pre></div><p><code>popen</code>创建了一个管道，然后执行fork，在子进程中使用<code>exec</code>执行cmdstring；返回的文件指针根据参数type指向管道的读或写端。</p>
<p>type可取&quot;w&quot;和&quot;r&quot;：</p>
<ul>
<li>
<p>取&quot;w&quot;时，返回的文件指针指向管道的写端fd[1]，子进程通过<code>dup2</code>将<code>stdin</code>复制到fd[0]，而cmdstring执行依赖<code>stdin</code>，就等于依赖父进程通过文件指针写入管道了；</p>
</li>
<li>
<p>取&quot;r&quot;时，文件指针指向管道的读端fd[0]，子进程通过<code>dup2</code>将<code>stdout</code>复制到fd[1]，而cmdstring执行默认输出到<code>stdout</code>，那么父进程就可以通过该文件指针读出cmdstring命令的输出。</p>
</li>
</ul>
<p>通过 <code>pclose</code> 函数关闭打开的文件指针，并使用<code>waitpid</code>关闭子进程;因此<code>popen</code>后如果不执行<code>pclose</code>将造成内存泄漏和僵尸进程。</p>
<h2 id="fifo">FIFO</h2>
<p><code>FIFO</code>可以用来在不相关的进程间通信。</p>
<p><code>FIFO</code>是一种文件类型，所以创建<code>FIFO</code>就是创建文件。通过 <code>mkfifo</code> 函数创建 <code>FIFO</code> 时，要指定一个具体的文件路径。</p>
<p>创建了<code>FIFO</code>之后，就可以通过标准文件操作（<code>open</code>、<code>read</code>、<code>write</code>、<code>close</code>）来使用它。毕竟在Linux中，一切皆文件。</p>
<h1 id="xsi-ipc">XSI IPC</h1>
<p><strong>消息队列、信号量、共享内存被统称为<code>XSI IPC</code></strong>，他们之间有很多共通之处：</p>
<ol>
<li>独立于文件系统，有自己的一套操作管理函数和内核数据结构；不能像管理文件一样管理这些资源。</li>
<li>这些资源归属于操作系统，而不属于某个进程，如果进程退出前忘记回收资源，资源不会自己释放掉，可能影响系统内其他进程。</li>
<li>进程通过<code>xxxget</code>函数并指定参数key的方式获得一个id，通过id来使用和管理指定的资源；id是进程内管理资源的标识符，不具有全局性，key值才是全局标识符；两个进程指定同一个key值就能获取同一个资源，从而关联起来。</li>
</ol>
<h2 id="信号量">信号量</h2>
<p>信号量(semaphore)作为IPC的角色是专门用来控制多个进程访问共享资源的，实际就是一个计数器。</p>
<p>通过<code>semget</code>、<code>semctl</code>、<code>semop</code>管理信号量。</p>
<h2 id="共享内存和mmap">共享内存和mmap</h2>
<h3 id="mmap">mmap</h3>
<p><code>mmap</code>把磁盘上某个具体文件映射到进程的内存映射区中，以实现对文件更快的读写。</p>
<p>通过将同一文件映射到不同的进程中内存空间，就可以实现进程间共享内存通信。</p>
<h3 id="共享内存">共享内存</h3>
<p>共享内存可以看成是把内核中的一块内存映射到进程的内存映射区。这样，两个进程共享同一块内存就可以实现通信了，由于是直接对内存读写，这种IPC方式也是最快的。</p>
<p>通过<code>shmget</code>、<code>shmctl</code>、<code>shmat</code>、<code>shmdt</code>管理共享内存。</p>
]]></content>
		</item>
		
	</channel>
</rss>
