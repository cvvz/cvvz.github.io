<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Vic&#39;s Blog</title>
		<link>https://cvvz.github.io/post/</link>
		<description>Recent content in Posts on Vic&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>zh-hans</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Mon, 29 Nov 2021 15:37:20 +0800</lastBuildDate>
		<atom:link href="https://cvvz.github.io/post/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>读锁有什么用？</title>
			<link>https://cvvz.github.io/post/what-is-rlock-used-for/</link>
			<pubDate>Mon, 29 Nov 2021 15:37:20 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/what-is-rlock-used-for/</guid>
			<description>问这个问题的起因是我在进行code review时，对一个读map前加读锁的代码留下了如下comment： 这里从map中读出脏数据不会有什么问</description>
			<content type="html"><![CDATA[<p>问这个问题的起因是我在进行code review时，对一个读map前加读锁的代码留下了如下comment：</p>
<ol>
<li>这里从map中读出脏数据不会有什么问题。</li>
<li>即使加了读锁还是不能避免读脏数据的问题。所以这里没必要加读锁</li>
</ol>
<p>但随后自己隐约觉得哪里不对，查了一下在golang里map就是不允许并发读写的，其实对map加读写锁就跟 <code>if err != nil</code> 一样常见。自己犯了一个小白错误。</p>
<p>回过头来也庆幸自己会犯这种错误，不然我可能永远只记得 <strong>map是非线程安全的，使用时要加锁</strong> 这个结论，以及使用前map加锁的肌肉记忆，却并不会停下来想一想为什么要这么做。</p>
<p>之所以会犯这个“初学者”错误，原因在于我<strong>搞混了几种线程安全/数据竞争发生的维度</strong>。虽然锁都是为了解决线程安全/数据竞争的问题的，但是线程安全问题可以出现在如下几个维度，造成的问题也不尽相同，所以引入锁要解决的问题也就不相同。</p>
<h3 id="应用维度">应用维度</h3>
<p>最常见的就是数据库的隔离级别。<strong>假设我们都只考虑简单的悲观锁的情况</strong>，那么RC就是为了防止脏读，通过加写锁，避免执行事务写数据期间被读到脏数据；RR就是在读之前加读锁，这样就能保证一次事务中，多次读到的数据是相同的。</p>
<p><strong>我在code review中犯的错误，是因为我以为给map加读锁就是为了避免数据不一致。然而又因为业务逻辑中并不涉及事务操作，所以我认为没必要加读锁，而且仅仅在读数据的时候加一下锁也避免不了脏读，因为不是一把事务锁。</strong></p>
<h3 id="语言运行时维度">语言运行时维度</h3>
<ol>
<li>
<p>golang的slice在append时，如果没有超出cap大小，那么是不会重新分配内存的，这时数据是直接append到底层的数组中的。如果两个线程并发的append同一个slice，那么就可能写同一片内存，这样可能会导致append后的总数不符合预期（变少）。这种情况我们也要用锁，这是语言运行时实现层面对程序员的约束。</p>
</li>
<li>
<p>golang的map被设计为非并发安全的（<a href="https://go.dev/doc/faq#atomic_maps">原因</a>），在应用层如果并发时不加读锁或者写锁，就可能会报错，<code>fatal error: concurrent map read and map write</code>。我们可以通过<a href="https://go.dev/doc/articles/race_detector">golang race detector</a>进行检查。那为什么map的读写需要加锁呢（不管是由应用程序加，还是由语言特性加）？原因在于map类型的一次读写不是原子性的（需要进行哈希计算、解决哈希冲突等等），并且map底层的数据结构非常复杂，一次写操作可能涉及到多个数据结构的调整，并发读写可能造成读数据不正确（<strong>是写的过程中的中间数据，不是脏读</strong>）。<strong>注意这里所说的原子性，不是指上面说的应用层的原子性；而是语言运行时实现层面对程序员的约束。</strong></p>
</li>
<li>
<p>还有一种是在语言实现时就设计为并非原子性赋值的，可以看看这篇文章中的<a href="https://cloud.tencent.com/developer/article/1810536">讨论</a>，典型的有复数类型。</p>
</li>
</ol>
<h3 id="编译器操作系统维度">编译器/操作系统维度</h3>
<p><strong>这个原子指的是编译器/操作系统层面的原子性，而不是上述两种原子性</strong>！</p>
<p>这里又分为三种情形：</p>
<ol>
<li>
<p>一种是并发执行i++，由于i++在编译后在底层的实现是先读i，再写i，分为两步，所以并发时可能有问题。</p>
</li>
<li>
<p>另一种是读写超过一个计算机字长的数据（比如struct，或者复合类型，比如string），这时肯定无法通过一条机器指令进行读写的</p>
</li>
<li>
<p>第三种是<strong>编译器或处理器可能会对单线程中的读写操作进行重新排序</strong>，只要保证重新排序后不影响单线程的执行即可。但是由于进行了重排序，所以对于多线程而言，读写操作的顺序就可能变化，就不能想当然的认为不用加锁！！</p>
<blockquote>
<p>所以<a href="https://go.dev/ref/mem">go内存模型</a>建议我们<code>Don't be clever.</code>，绝大多数情况下，请不要自作聪明。<code>To serialize access, protect the data with channel operations or other synchronization primitives such as those in the sync and sync/atomic packages.</code><strong>为了保证读写顺序，使用channel或者其他同步原语比如sync和sync/atomic包中提供的方法来保护你的数据。</strong></p>
</blockquote>
</li>
</ol>
<h3 id="golang中的cow">golang中的COW</h3>
<p>虽然加锁很快，并且在大多数场景下我们都不会碰到锁性能问题。但是在某些极端场景下，如果对map频繁的加读写锁，还是会带来一些性能损失。我们可以采取copy-on-write的方式避免对map加锁，从而提高性能。</p>
<p>方法就是对map的写操作变成整个map的替换，由于map替换本身可以看成是进行一次指针赋值，而指针赋值在golang中是原子性的，所以就不会存在map并发问题。</p>
<p>典型代码可以查看<a href="https://github.com/Terry-Mao">煎鱼</a>的<a href="https://github.com/Terry-Mao/gopush-cluster/blob/master/rpc/rand_lb.go#L221-L232">这段代码</a></p>
<blockquote>
<p>但是这段代码也引起了一些<a href="https://github.com/Terry-Mao/gopush-cluster/issues/44">争议</a>，主要争议在于golang的指针赋值到底是不是原子的。关于这个问题，可以看看<a href="https://stackoverflow.com/questions/21447463/is-assigning-a-pointer-atomic-in-go">这个问答</a>，简单来说就是，除了 <code>sync.atomic</code> 中的操作以外，其他任何操作都不建议看作是原子性的。因为即使当前版本golang中的实现是原子的，不代表以后某一天不会被改成非原子的。</p>
<p>这可能也是<a href="https://go.dev/ref/mem">go内存模型</a>里让我们<code>Don't be clever.</code>的原因吧。<strong>我个人的理解是，如果你写golang，那么你需要能够接受一些性能损耗，而不要自作聪明的想一些奇技淫巧；如果你要追求极致的性能，你可以用C/C++/Rust实现 :)</strong></p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>怎么让controller周期性的reconcile</title>
			<link>https://cvvz.github.io/post/controller-reconcile/</link>
			<pubDate>Sat, 20 Nov 2021 14:17:23 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/controller-reconcile/</guid>
			<description>问题 怎么让controller每隔1分钟进行一次reconcile，而不需要借助任何外部事件触发？ 虽然解决的方法看似很简单，但是知其然还要知</description>
			<content type="html"><![CDATA[<h2 id="问题">问题</h2>
<p>怎么让controller每隔1分钟进行一次reconcile，而不需要借助任何外部事件触发？</p>
<figure>
    <img src="/informer.jpeg" width="500px"/> 
</figure>

<p>虽然解决的方法看似很简单，但是知其然还要知其所以然，借着解决这个问题的契机，我们来仔细阅读一下infomer和controller-runtime的源码实现。这才是最重要的部分（当然是对于个人而言😁）</p>
<h2 id="方法一">方法一</h2>
<p>创建informerFactory对象时，设置defaultResync参数</p>
<figure>
    <img src="/1.png" width="800px&#34;"/> 
</figure>

<h3 id="原理">原理</h3>
<p>reflector除了会watch apiserver，还会每隔 defaultResync 从indexer中重新获取Object，并将其入队fifo，这样就会重新触发一次informer的Add事件并入队工作队列。</p>
<h3 id="client-go源码">client-go源码</h3>
<p>reflector在进行<a href="https://github.com/kubernetes/client-go/blob/10e087ca394e2987f09e759438f9949a746c1ca0/tools/cache/reflector.go#L254">ListAndWatch</a>的同时也会周期性的做resync：</p>
<figure>
    <img src="/2.png" width="500px&#34;"/> 
</figure>

<p>这里的store就是fifo，fifo的Resync实现如下：</p>
<figure>
    <img src="/3.png" width="500px&#34;"/> 
</figure>

<p>这里调用knownObjects.ListKeys()来获取所有的Object key然后再入队fifo，这个knownObjects其实就是indexer cache（一个带锁的map）</p>
<figure>
    <img src="/00.png" width="600px&#34;"/> 
</figure>

<h3 id="controller-runtime源码">controller-runtime源码</h3>
<p>对于controller-runtime库，reflector、informer、indexer等组件被封装在cache对象中，cache对象是Manager对象的属性，它们之间的关系如下图所示：</p>
<figure>
    <img src="/controller-runtime.drawio.svg" width="500px&#34;"/> 
</figure>

<p>我们可以通过在创建Manager对象时，传入SyncPeriod参数来达到这一目的，当然SyncPeriod应该是可配置的：</p>
<figure>
    <img src="/4.png" width="700px&#34;"/> 
</figure>

<h2 id="方法二">方法二</h2>
<p>通过在Reconcile中，设置返回的Result的RequeueAfter为1分钟：</p>
<figure>
    <img src="/5.png" width="700px&#34;"/> 
</figure>

<h3 id="原理-1">原理</h3>
<p>先找到Reconcile的调用点：</p>
<ol>
<li>
<p>ControllerManagedBy通过<strong>Builder模式</strong>将Controller添加进Manager中</p>
<figure>
    <img src="/6.png" width="700px&#34;"/> 
</figure>

</li>
<li>
<p>Manager启动时会启动所有controller，对于controller，“启动”的含义就是启动多个goroutine循环的从workqueue中取key，然后执行Reconcile，顺着Manager.Start一层层的找到<a href="https://github.com/kubernetes-sigs/controller-runtime/blob/master/pkg/internal/controller/controller.go#L148">Controller的Start入口</a>，最终可以看到熟悉的 processNextWorkItem：</p>
<figure>
    <img src="/7.png" width="700px&#34;"/> 
</figure>

<p>processNextWorkItem的逻辑当然就是从workqueue里取key，然后执行Reconcile的业务逻辑：</p>
<figure>
    <img src="/8.png" width="700px&#34;"/> 
</figure>

</li>
<li>
<p>可以看到当result.RequeueAfter &gt; 0时，执行了c.Queue.Forget(obj)和c.Queue.AddAfter(req, result.RequeueAfter)，分别是什么意思呢？要搞清楚这一点，首先我们要弄清楚workqueue的实现。</p>
</li>
</ol>
<h3 id="workqueue">workqueue</h3>
<ol>
<li>
<p>workqueue的创建方法定义在controller中：：</p>
<figure>
    <img src="/9.png" width="700px&#34;"/> 
</figure>

</li>
<li>
<p>这里创建的是一个限速队列，限速队列由<strong>延迟队列</strong>和<strong>限速器</strong>两部分组成：</p>
<figure>
    <img src="/10.png" width="700px&#34;"/> 
</figure>

</li>
</ol>
<h3 id="addafter">AddAfter</h3>
<p>AddAfter是延迟队列提供的方法，它向waitingForAddCh这个channel中传入了一个构造的waitFor对象</p>
<figure>
    <img src="/11.png" width="700px&#34;"/> 
</figure>

<p>而这个channel的接收方，则是在创建延迟队列时启动的一个goroutine：</p>
<figure>
    <img src="/12.png" width="700px&#34;"/> 
</figure>

<p>在这个goroutine中，收到waitFor对象后，如果还没到执行时间，则会插入优先级队列中（<strong>可以看到，高性能定时器一般用堆实现</strong>）</p>
<figure>
    <img src="/13.png" width="700px&#34;"/> 
</figure>

<p>随后会判断优先级队列中堆顶元素的时间是否到达，如果时间到了，就取出堆顶元素，并入队workqueue，时间没到就计算需要等多长时间，然后启动一个timer进行等待</p>
<figure>
    <img src="/14.png" width="700px&#34;"/> 
</figure>

<h3 id="forget">Forget</h3>
<p>在看Forget方法前，先看限速队列中我们最常用的AddRateLimited方法，一般这个方法会在我们Reconcile失败的时候进行调用，目的就是以某种限定的速率重新入队workqueue，从而达到限制重试速度的目的：</p>
<figure>
    <img src="/15.png" width="700px&#34;"/> 
</figure>

<p>可以看到其实就是调用延迟队列的AddAfter方法，只是AddAfter的方法的参数不是固定的时间，而是由限速器说了算</p>
<p><a href="https://github.com/kubernetes/client-go/blob/10e087ca394e2987f09e759438f9949a746c1ca0/util/workqueue/default_rate_limiters.go">workqueue</a>包中提供的默认限速器是<strong>指数退避限速器 + 令牌桶限速器</strong>：</p>
<figure>
    <img src="/16.png" width="700px&#34;"/> 
</figure>

<p>Forget是限速器提供的方法，其实就是把失败的对象从限速器中移除，这样限速器就不会再根据该对象的失败次数对其进行限速计算了</p>
<figure>
    <img src="/17.png" width="700px&#34;"/> 
</figure>

<p>因此，再Reconcile执行成功后，<strong>需要调用Forget将对象（也就是字符串namespace/name）从限速器中移除</strong>，否则会重复入队workqueue一次并且会影响后续限速器对于相同key的限速计算。</p>
]]></content>
		</item>
		
		<item>
			<title>分布式数据库上k8s面临的困境</title>
			<link>https://cvvz.github.io/post/the-difficulty-of-distributed-db-on-cloud/</link>
			<pubDate>Sun, 25 Jul 2021 08:58:26 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/the-difficulty-of-distributed-db-on-cloud/</guid>
			<description>说点虚的 云原生数据库、shared-nothing、算存分离&amp;hellip; 这些概念性的东西，网上资料一大把，看完以后感觉懂了，但是尝试用自</description>
			<content type="html"><![CDATA[<h2 id="说点虚的">说点虚的</h2>
<p><code>云原生数据库</code>、<code>shared-nothing</code>、<code>算存分离</code>&hellip; 这些概念性的东西，网上资料一大把，看完以后感觉懂了，但是尝试用自己的话复述出来时，又感觉没懂。</p>
<blockquote>
<p><strong>为什么会有这种感觉呢？我觉得原因在于看完了网上的资料，我知道了what；但是很多资料并没有解释why，所以我无法把知识转变成自己的，也就无法用自己的语言把这些概念解释一遍。只有搞清楚为什么会出现这种设计，才能够消化知识，只知道what的话，只能靠死记硬背才能“掌握”知识。</strong></p>
</blockquote>
<figure>
    <img src="/database-architecture.jpg" width="800px"/> 
</figure>

<p>这张图来自于李飞飞的一片<a href="https://mp.weixin.qq.com/s/rOL1drNzhWW1HBkgTz2wHQ">文章</a>，介绍了数据库的过去和未来。我尝试在这张图的基础上补充自己的理解：</p>
<h3 id="单机数据库">单机数据库</h3>
<p>经常听到说传统单机数据库是一种<code>shared-everything</code>的架构，怎么理解呢？实际上这里的<code>everything</code>指的是冯·诺依曼架构中的「计算」和「存储」，而<code>shared</code>指的是单机数据库可以随意使用本地的所有「计算」和「存储」资源。</p>
<h3 id="分布式数据库">分布式数据库</h3>
<p>很快，单机数据库就面临着可扩展性问题，这时就需要通过加资源的方式解决，于是出现了两种解决方案：Scale up和Scale out。</p>
<p>这里Scale up并不是指单机维度的scale up，而是从资源视角的scale up，更具体地说，也就是存储池化：数据库的底层存储由原来的单机磁盘（磁盘阵列）、单机文件系统，演变为基于分布式块存储、分布式文件存储、对象存储等的<code>shared-storage</code>分布式数据库。</p>
<p>Scale out则是各个数据库实例独立运行，实例之间通过raft/paxos等共识算法实现数据同步，而不依赖底层的分布式存储系统。这就是所谓的<code>shared-nothing</code>分布式数据库，数据库不共享任何IaaS层的资源，完全依赖于PaaS层（DB）本身，去做高可用和强一致，实现分布式事务。</p>
<h3 id="云原生数据库">云原生数据库</h3>
<p><strong>云原生数据库 = 分布式数据库(scale out) + 资源池化(scale up)</strong>。</p>
<p><strong>云原生 = 云 + 原生</strong>。「云」就代表着IaaS资源池化，「原生」意味着应用（PaaS、SaaS）天然就是针对这种池化的特性进行设计的。</p>
<p>现在的分布式数据库大多是<code>shared-nothing</code>的，例如tidb和ob，使用了本地盘。一旦使用本地盘，就意味着无法上云，因为云的特性就是资源池化，所以要上云，就要使用公有云厂商提供的EBS、S3等云盘。而云盘的性能没有本地盘好，这就要求应用层，也就是DB这一层，是面向公有云的基础服务进行设计的。这就是云原生的数据库，即在数据库设计的时候，就考虑各种资源是在云上，以池化的方式提供。这种方式意味着<code>shared-nothing</code>和<code>shared-everything</code>
的结合：宏观上看，是<code>shared-everything</code>的（未来内存也会池化），从微观上看，又是分布式的<code>shared-nothing</code>。</p>
<p>这是一种<code>真正的</code><strong>算存分离</strong>：<strong>在单机部署情况下，通信就是计算通过 Memory Bus、IO Bus和内存、存储通信。但在集群部署的情况下，计算和存储的通信就是网络</strong>。数据库刚诞生的年代，单机的存储访问速度肯定要快于集群，但是随着网络、存储等基础设施的不断发展，未来这个情况可能就不一定了，IaaS池化一定是未来，云计算一定是未来，数据库上云一定是未来。</p>
<h2 id="搞点实际的">搞点实际的</h2>
<p>分布式数据库上k8s会遇到哪些问题呢？</p>
<blockquote>
<p>由于分布式数据库在设计上就不是云原生的，一般比较适合<code>on-primises</code>部署，也就是直接部署在物理机上，而不是部署到云上。</p>
<p><strong>由于使用本地盘，分布式数据库不适合通过k8s进行部署。但是，随着基础设施硬件的不断发展，池化后的资源不会再成为性能瓶颈，所以云原生数据库一定是数据库的未来，现在的分布式数据库也在往云原生数据库的方向演进，到那一天，有状态应用就可以在k8s上发挥它最大的威力</strong>。</p>
</blockquote>
<h3 id="本地盘">本地盘</h3>
<ol>
<li>
<p>本地盘使用的是静态PV，不支持动态scale up，灵活性差。</p>
</li>
<li>
<p>cgroup v1的IO隔离机制有缺陷，无法对buffered IO的IOPS进行很好的限制。</p>
</li>
<li>
<p>本地盘在做节点迁移时，需要迁移数据。众所周知移动计算比移动数据更方便。</p>
</li>
<li>
<p>没法利用k8s的自我修复能力。比如节点挂了，你可以通过起一个新的Pod的方式进行修复。但是如果用了本地盘，这个Pod却必须调度到原节点。</p>
</li>
</ol>
<h3 id="网盘">网盘</h3>
<p>在公有云上，使用网盘最大的问题第一是延迟抖动；第二是性能比本地盘要差很多。如何在软件层面克服这种问题是云原生数据库要攻克的难关。</p>
<p><strong>现有的云原生数据库（比如snowflake）一般都是面向OLAP的数据仓库，原因在于数据仓库对于吞吐的要求其实是更高的，对于延迟并不是那么在意，一个 query 可能跑五秒出结果就行了，不用要求五毫秒之内给出结果，特别是对于一些 Point Lookup 这种场景来说，Shared Nothing 的 database 可能只需要从客户端的一次 rpc，但是对于计算与存储分离的架构，中间无论如何要走两次网络，这是一个核心的问题。Aurora 是一个计算存储分离架构，但它是一个单机数据库，Spanner 是一个纯分布式的数据库，纯 Shared Nothing 的架构并没有利用到云基础设施提供的一些优势。</strong></p>
]]></content>
		</item>
		
		<item>
			<title>重学数据结构和算法</title>
			<link>https://cvvz.github.io/post/data-structure-and-algorithm/</link>
			<pubDate>Sun, 18 Jul 2021 21:14:55 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/data-structure-and-algorithm/</guid>
			<description>常见数据结构 数组 数组的时间效率很高，但是空间效率很低，而且不安全，比如访问越界造成踩内存。 很多高级语言都基于基础的数组实现了动态数组，比如J</description>
			<content type="html"><![CDATA[<h2 id="常见数据结构">常见数据结构</h2>
<h3 id="数组">数组</h3>
<p>数组的时间效率很高，但是空间效率很低，而且不安全，比如访问越界造成踩内存。</p>
<p>很多高级语言都基于基础的数组实现了<strong>动态数组</strong>，比如Java中的ArrayList、C++ STL中的vector和golang中的slice，动态数组的优势在于可以动态扩容，使用起来很方便，<strong>在实现算法时更加handy</strong>。但是由于封装了额外的数据迁移等操作，时间效率上不如数组高。</p>
<h3 id="链表">链表</h3>
<h3 id="单链表双链表循环链表">单链表、双链表、循环链表</h3>
<p>技巧：<strong>使用哨兵节点（带头链表）</strong>。这样在插入第一个节点和删除最后一个节点时，就不需要做特殊判断，可以简化实现逻辑</p>
<blockquote>
<p>所有高级数据结构都是在数组和链表的基础上衍生出来的。</p>
</blockquote>
<h3 id="栈和队列">栈和队列</h3>
<p>“操作受限”的线性表，只支持两种基本操作：push, pop。</p>
<p>递归的算法都可以用栈来实现。</p>
<blockquote>
<p>高性能定时器，除了可以用堆实现（<strong>比如golang的timer就是用最小四叉堆</strong>），还可以用<strong>环形队列</strong>，详见 <a href="https://zhuanlan.zhihu.com/p/65835110">时间轮算法 HashedWheelTimer</a>、[http://russellluo.com/2018/10/golang-implementation-of-hierarchical-timing-wheels.html](层级时间轮的 Golang 实现)</p>
</blockquote>
<h3 id="hash表">hash表</h3>
<p>高级语言内置了hash表，比如Java 中的 HashMap，golang中的map数据类型。</p>
<blockquote>
<p><strong>Java JDK 中自带 TreeMap</strong>，可以按 key 进行排序，任何一个 Javaer 应该都使用过。</p>
<p>但是在 Go 语言的“简约设计”面前，这些都是不存在的——Go 只提供了最基础的 hash map。并且，在借助 range 关键字对 Go 的 map 进行遍历访问的时候，会对 map 的 key 的顺序做随机化处理，也就是说即使是同一个 map 在同一个程序里进行两次相同的遍历，前后两轮访问 key 的顺序也是随机化的。(可以在<a href="https://go.dev/play/p/LYJSbQBjWa6">这里</a>进行验证)。</p>
<p>我们可以自己实现，或者借助其他开源解决方案，比如<a href="https://github.com/emirpasic/gods">emirpasic/gods</a>。</p>
</blockquote>
<ol>
<li>
<p>hash表来源于<strong>数组</strong>，借助<strong>散列函数</strong>对数组这种数据结构进行扩展，也就是将key映射为数组下标index。</p>
</li>
<li>
<p>将key转化为数组下标的方法称为<strong>散列函数</strong>，散列函数的计算结果称为<strong>hash值</strong>。数据存储在<strong>hash值</strong>对应的<strong>数组下标</strong>位置。</p>
</li>
</ol>
<blockquote>
<p>实现hash表所使用的hash算法要求执行<strong>速度快</strong>，值是否能<strong>平均分布</strong>在各个槽中（比如简单的取模算法）。并不是很在乎<strong>安全性</strong>（是否能反向解密出原始数据）和<strong>hash冲突</strong>（哈希值相同）。所以不会使用<strong>加密用</strong>的哈希算法。</p>
<p>hash函数,有加密型和非加密型。加密型的一般用于加密数据、数字摘要等，典型代表就是md5、sha1、sha256、aes256 。非加密型的一般就是查找。</p>
</blockquote>
<h3 id="hash算法">hash算法</h3>
<p><strong>hash算法在hash表中的应用就是散列函数。</strong></p>
<p><a href="https://time.geekbang.org/column/article/67388">在分布式系统中的应用</a>：</p>
<ol>
<li>负载均衡</li>
<li>数据分片</li>
<li>分布式存储（<strong>一致性哈希</strong>）</li>
</ol>
<blockquote>
<p>取模似乎是用的最多的一种哈希算法。MD5、SHA256等哈希算法，一般会用在把一个大的二进制文件转换为一个唯一的二进制数值。</p>
</blockquote>
<h3 id="树">树</h3>
<h4 id="二叉树">二叉树</h4>
<ul>
<li>二叉树的遍历：<strong>前中后指的是当前节点和左右子树谁先打印</strong></li>
<li>完全二叉树和满二叉树：可以用<strong>数组存储</strong></li>
<li>二叉查找树：<strong>和有序数组的二分查找类比记忆</strong></li>
<li>平衡二叉查找树：二叉查找树在频繁的动态更新过程中，可能会出现树的高度远大于 log2n 的情况，从而导致各个操作的效率下降。<strong>极端情况下，二叉树会退化为链表</strong>，时间复杂度会退化到 O(n)。所以又发明了<strong>平衡二叉查找树</strong>。
<blockquote>
<p>“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。</p>
</blockquote>
</li>
<li>红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。<strong>红黑树在Java中的实现&ndash;TreeMap</strong>。</li>
</ul>
<h4 id="堆httpsleetcode-cncomtagheap-priority-queueproblemset"><a href="https://leetcode-cn.com/tag/heap-priority-queue/problemset/">堆</a></h4>
<p><strong>堆的核心操作：</strong></p>
<ol start="0">
<li>核心中的核心：堆化（heapify）
<ol>
<li><strong>从上往下</strong></li>
<li><strong>从下往上</strong></li>
</ol>
</li>
<li>交换堆顶和堆尾，并进行从上往下堆化</li>
<li>插入堆尾，并进行从下往上堆化</li>
<li>建堆
<ol>
<li>从上往下堆化</li>
<li>从下往上堆化</li>
</ol>
</li>
</ol>
<p><a href="https://time.geekbang.org/column/article/70187"><strong>堆的应用</strong></a>:</p>
<ol>
<li>优先级队列
<ol>
<li>合并有序小文件</li>
<li>定时器</li>
</ol>
</li>
<li><a href="https://leetcode-cn.com/problems/find-median-from-data-stream/">数据流的中位数</a>、99线问题</li>
<li>TopK问题
<ol>
<li><a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/">静态topK</a>（从上往下堆化）</li>
<li><a href="https://leetcode-cn.com/problems/kth-largest-element-in-a-stream/">动态topK</a>（从下往上堆化）</li>
</ol>
</li>
</ol>
<h3 id="图">图</h3>
<p><strong>度（degree）</strong>：in-degree、out-degree</p>
<p><strong>数据结构（存储方法）</strong>：</p>
<ul>
<li>邻接矩阵</li>
<li>邻接表</li>
</ul>
<blockquote>
<p><strong>面试的时候更多的是把二叉树和图结合起来考察，所以会用二叉树（链表）来表示图</strong></p>
<p>DAG</p>
</blockquote>
<p><strong>图的搜索算法</strong>：BFS、DFS</p>
<h2 id="常见算法">常见算法</h2>
<h3 id="排序">排序</h3>
<p><strong>冒泡排序、插入排序、选择排序</strong>：三种O(n2)的<strong>简单无脑的</strong>算法，数据量不大时可以用一用。</p>
<p><strong>归并排序</strong>：不断二分，递归下去，然后“<strong>从下往上</strong>”merge。由于这个merge无法原地执行，因此空间复杂度为O(n)。</p>
<blockquote>
<p>虽然归并排序用到了递归，但是空间复杂度不是O(n2)，因为每次merge时，下面那一层的内存就被释放掉了。</p>
<p>归并排序是stable的，所以<strong>golang的<a href="https://github.com/golang/go/blob/master/src/sort/sort.go#L378-L404">sort.Stable</a>使用归并排序实现</strong>。</p>
</blockquote>
<p><strong>快速排序</strong>：选择一个pivot，然后“<strong>从上往下</strong>”不断进行<strong>原地的</strong>partition操作，由于partition是原地的，因此空间复杂度为O(1)。</p>
<p>因为快速排序优化了内存使用，所以应用比归并排序要广泛。但是快速排序在最坏情况下的时间复杂度是 O(n2)，<strong>需要解决这个“复杂度恶化”的问题</strong>。这个问题的根因还是我们选择的分区点（pivot）不合理导致的，理想的分区点应该是左右两边的数据量差不多，最好能二分，这样递归的层次就最少。pivot的选择方法最常见的有两种：</p>
<ol>
<li>三数取中法：选择三个或者更多的数，选择他们的中间值作为pivot。</li>
<li>随机法：从概率上说不会一直选的都是最差的点作为pivot。</li>
</ol>
<p><strong>归并排序</strong>和<strong>快速排序</strong>都用到了<strong>分治</strong>思想。我们可以借鉴快排的思想，来解决非排序的问题，比如<a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/">静态topK</a>问题。</p>
<p><strong>堆排序</strong>：步骤分为</p>
<ol>
<li>建堆：堆化
<ol>
<li>方法一：<strong>从第一个非叶子结点开始</strong>，依次执行从上往下堆化</li>
<li>方法二：不断插入尾部，并对新插入节点执行从下往上堆化</li>
</ol>
</li>
<li>调整：不断交换堆顶和堆尾元素 + 重新堆化</li>
</ol>
<blockquote>
<p><strong>注意，在做堆排序时，由于调整这一步是从上往下堆化，所以建堆时最好用方法一，这样heapify函数才能复用。</strong></p>
</blockquote>
<h3 id="搜索">搜索</h3>
<blockquote>
<p>算法是作用于具体数据结构之上的，深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构的</p>
</blockquote>
<h4 id="广度优先搜索">广度优先搜索</h4>
<p>通俗的理解就是，地毯式层层推进，从起始顶点开始，依次往外遍历。广度优先搜索需要借助<strong>队列</strong>来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。</p>
<h4 id="深度优先搜索">深度优先搜索</h4>
<p>用的是回溯思想，非常适合用递归实现。换种说法，深度优先搜索是借助<strong>栈</strong>来实现的。</p>
<h3 id="二分查找">二分查找</h3>
<p>二分查找的<strong>三个容易出错的地方</strong>：</p>
<ul>
<li>循环退出条件</li>
<li>mid 的取值可能越界</li>
<li>low 和 high 的更新。</li>
</ul>
<p>二分查找可以用递归实现。</p>
<h2 id="基本算法思想">基本算法思想</h2>
<h3 id="贪心httpsleetcode-cncomtaggreedyproblemset"><a href="https://leetcode-cn.com/tag/greedy/problemset/">贪心</a></h3>
<blockquote>
<p>严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。</p>
</blockquote>
<h3 id="分治httpsleetcode-cncomtagdivide-and-conquerproblemset"><a href="https://leetcode-cn.com/tag/divide-and-conquer/problemset/">分治</a></h3>
<blockquote>
<p>分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突。</p>
<p>分治经常用在海量数据处理的场景下，内存无法直接装载全部数据，就将数据分批装载进内存处理，再将结果进行合并。（给1TB的订单排序）</p>
<p>要判断清楚数据规模是不是可以直接装载进内存，比如：10亿个整数 = 80亿Byte( int=64bit ) ≈（不足）8GB，这个时候要考虑单机的实际可用内存大小是否可以直接装载8GB。</p>
</blockquote>
<h3 id="动态规划httpsleetcode-cncomtagdynamic-programmingproblemset"><a href="https://leetcode-cn.com/tag/dynamic-programming/problemset/">动态规划</a></h3>
<blockquote>
<p>DP的主要学习难点跟递归类似，那就是，求解问题的过程不太符合人类常规的思维方式。</p>
</blockquote>
<h3 id="回溯httpsleetcode-cncomtagbacktrackingproblemset"><a href="https://leetcode-cn.com/tag/backtracking/problemset/">回溯</a></h3>
<blockquote>
<p>DFS利用的就是回溯算法思想。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>重学设计模式</title>
			<link>https://cvvz.github.io/post/design-pattern/</link>
			<pubDate>Sun, 18 Jul 2021 20:40:19 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/design-pattern/</guid>
			<description>设计模式和设计原则的合理应用非常依赖个人经验，用不好有时候会适得其反。学生时代时学习设计模式觉得枯燥，是因为没有实践经验。要多实践，然后再温</description>
			<content type="html"><![CDATA[<blockquote>
<p>设计模式和设计原则的合理应用非常依赖个人经验，用不好有时候会适得其反。学生时代时学习设计模式觉得枯燥，是因为没有实践经验。要多实践，然后再温故知新。</p>
</blockquote>
<h2 id="为什么要学设计模式设计原则">为什么要学设计模式/设计原则？</h2>
<ol>
<li>在经典的开源软件库、框架中，大量使用了设计模式，<strong>不懂设计模式很难看懂开源代码</strong>！即使看懂了也无法领会其中的精髓。更别说自己去创造一个开源项目。</li>
<li>一些设计模式会使得代码变得<strong>不直观</strong>，<strong>可读性变差</strong>，但是可扩展性、可维护性更强了。能写出直观的代码的人很多，但能写出“复杂”代码（<strong>指引入了设计模式，而不是指复杂的业务逻辑</strong>）的人很少。
<blockquote>
<p>设计模式/SOLID设计原则是解决代码的扩展性问题，KISS设计原则是解决代码的可读性问题。</p>
</blockquote>
</li>
<li>有能力去做<strong>持续重构</strong>。初级工程师在维护代码，高级工程师在设计代码，资深工程师在重构代码</li>
</ol>
<h2 id="面向对象和golang">面向对象和golang</h2>
<blockquote>
<p><strong>面向对象分析、设计</strong>：程序被拆解为哪些类、类里面有哪些方法（<strong>golang的interface</strong>）和属性（<strong>golang的struct</strong>）、类和类之间如何交互（<strong>golang里应该使用接口进行交互</strong>）。</p>
<p><strong>面向对象编程</strong>：把设计翻译成代码。</p>
</blockquote>
<h3 id="封装encapsulation">封装（Encapsulation）</h3>
<p>封装也叫作<strong>信息隐藏</strong>或者<strong>数据访问保护</strong>：仅<strong>暴露有限的方法，并且限制类中的部分属性的访问权限。</strong></p>
<p>比如将属性设置为private，避免直接修改对象属性；只提供部分属性的get、set方法，对于不可变更的属性，如id，不提供任何访问或修改方法。</p>
<blockquote>
<p><strong>golang中，struct中大写字母开头的字段相当于public，小写字母开头的字段相当于private。</strong></p>
</blockquote>
<h3 id="抽象abstraction">抽象（Abstraction）</h3>
<p>封装的主要目的是隐藏数据，而抽象的目的是<strong>隐藏方法的具体实现</strong>。</p>
<p>函数就可以看成是一种抽象，即使用者无需关注底层实现，只需要通过注释、文档等知道这个接口/函数是干啥的、怎么用就行了。其实就是帮助大脑过滤非必要信息，让我们只关注功能点。</p>
<p>可以看出来抽象是一个非常通用的设计思想，并非面向对象设计特有。<strong>所以抽象有的时候会被排除在面向对象的四大特性之外。</strong></p>
<h3 id="继承inheritance">继承（Inheritance）</h3>
<p><strong>继承最大的好处是代码复用。</strong></p>
<blockquote>
<p>代码复用的问题也可以利用组合来解决。<strong>golang就是利用组合而不是继承来实现代码复用</strong>。</p>
<p>通过组合匿名接口或者匿名struct，还可以进行“覆盖”（其实不是真正意义上的覆盖）。</p>
</blockquote>
<h3 id="多态polymorphism">多态（Polymorphism）</h3>
<p>多态是指，子类可以替换父类。利用继承+覆盖实现。</p>
<blockquote>
<p>在golang中，通过接口来实现多态，也就是说任何实现了接口的对象都能当参数传入。而golang本身是支持duck type语法的，所以这些对象之间可以没有任何关系。</p>
</blockquote>
<h2 id="设计原则">设计原则</h2>
<blockquote>
<p>同时这也是 Code Review 的重要标准之一</p>
</blockquote>
<ol>
<li>
<p>针对接口编程，而不是针对实现编程。</p>
<blockquote>
<p>在golang里，即使一个接口只有一个实现类，也要用接口，而不要操作具体类，因为要为后续的可扩展性做好准备；</p>
</blockquote>
</li>
<li>
<p>多用组合，少用继承；换句话说，“has-a”，比“is-a”更好。因为继承可能导致层次过深的问题。</p>
<blockquote>
<p>golang没有继承的概念，通过组合多个小接口来实现一个更大的接口；</p>
<p>使用匿名接口/匿名结构体可以达到<strong>类似继承</strong>的效果，但这不是继承。</p>
</blockquote>
</li>
<li>
<p>SOLID：</p>
<ol>
<li>单一职责原则：一个类只负责一件事情。为了能做到单一职责，应该进行<strong>持续重构</strong>。</li>
<li>开闭原则：对扩展开放，对修改关闭。<strong>开闭原则讲的就是代码的扩展性问题</strong>。在23种经典设计模式中，大部分设计模式都是为了解决代码的<strong>扩展性</strong>问题而存在的，主要遵从的设计原则就是开闭原则。只要它<strong>没有破坏原有的代码的正常运行，没有破坏原有的单元测试</strong>，我们就可以说，这是一个合格的代码改动。</li>
<li>里氏替换原则：按照“协议”来设计子类，也就是说<strong>子类在覆盖父类的方法的时候，不要违背父类对某个方法的“约定”</strong>，这样，当代码里用到父类的地方，才<strong>真正的</strong>可以用子类去进行替换，而不会引发问题（这里要区分它和多态的区别）。判断子类的设计实现是否违背里式替换原则，有一个小窍门，<strong>那就是拿父类的单元测试去验证子类的代码。如果某些单元测试运行失败，就有可能说明，子类的设计实现没有完全地遵守父类的约定，子类有可能违背了里式替换原则。</strong></li>
<li>接口隔离原则：不应该让调用方看到他不关心/不应该调用的接口。<strong>在golang中，提倡设计小接口，并将小接口组合成大的接口。</strong></li>
<li>依赖反转原则：用来指导框架层面的设计，而不是业务代码开发。高层模块不依赖低层模块，二者中间通过接口抽象进行连接，低层模块依赖接口抽象层。<strong>比如web服务器 &lt;-&gt; gunicorn &lt;-&gt; web框架</strong>。</li>
</ol>
</li>
<li>
<p>KISS和YAGNI</p>
<p>KISS和YAGNI原则用来保持代码的<strong>可读性和可维护性</strong>。但是可读性很多时候和<strong>可扩展性</strong>互相矛盾。过度引入设计模式会导致可读性降低，我们需要进行权衡。</p>
<p>此外，实践KISS原则时，也可能会和<strong>性能</strong>相互冲突（比如直接引用现成的三方库中的通用接口和自己来实现一种更高效的算法）。但是，除非遇到性能瓶颈，否则可读性更重要。</p>
<p>YAGNI：You Ain&rsquo;t Gonna Need It.不要去设计你用不到的东西，不要过度设计。但是还是要保持代码的可扩展性。</p>
</li>
</ol>
<h2 id="重构与编程规范">重构与编程规范</h2>
<h3 id="重构">重构</h3>
<h4 id="why">why</h4>
<p><strong>技术在更新、需求在变化、人员在流动，代码质量总会在下降，代码总会存在不完美，重构就会持续在进行</strong>。时刻具有持续重构意识，才能避免开发初期就过度设计，避免代码维护的过程中质量的下降。</p>
<p><strong>一旦出现“破窗效应”，一个人往里堆了一些烂代码，之后就会有更多的人往里堆更烂的代码</strong>。毕竟往项目里堆砌烂代码的成本太低了。</p>
<h4 id="when">when</h4>
<p>不要等到问题堆得太多了去做大刀阔斧的重构，甚至重写，要时刻有人对代码整体质量负责任，<strong>平时没事就改改代码，持续性的进行小重构</strong>。</p>
<h3 id="编程规范">编程规范</h3>
<ol>
<li>
<p>单元测试。保证代码质量的两个手段：Code Review和单测。单元测试本身的代码质量可以放低要求，copy-paste、有重复代码也是可以允许的。单元测试只关心被测函数实现了什么功能，不用逐行阅读函数里面的代码。</p>
</li>
<li>
<p>命名。对于接口的命名，一般有两种比较常见的方式。一种是加前缀“I”，表示一个 Interface。比如 IUserService，对应的实现类命名为 UserService。另一种是不加前缀，比如 UserService，对应的实现类加后缀“Impl”，比如 UserServiceImpl。</p>
</li>
<li>
<p>当函数参数过多时，可以考虑将函数参数变成对象，函数变成方法。</p>
</li>
<li>
<p>不要在函数中使用布尔类型的标识参数来控制内部逻辑，true 的时候走这块逻辑，false 的时候走另一块逻辑。</p>
</li>
</ol>
<h2 id="设计模式基于golang">设计模式(基于golang)</h2>
<blockquote>
<p>创建型：主要解决“对象的创建”问题</p>
<p>结构型：主要解决“类或对象的组合或组装”问题</p>
<p>行为型：主要解决“类或对象之间的交互”问题</p>
</blockquote>
<ol>
<li>创建型
<ul>
<li><a href="https://github.com/cvvz/go-design-pattern/tree/master/golang/singleton">单例</a></li>
<li><a href="https://github.com/cvvz/go-design-pattern/tree/master/golang/factory">工厂</a></li>
<li><a href="https://github.com/cvvz/go-design-pattern/tree/master/golang/builder">建造者</a></li>
</ul>
</li>
<li>结构型
<ul>
<li><a href="https://github.com/cvvz/go-design-pattern/tree/master/golang/decorator">装饰器/Functional Option</a></li>
</ul>
</li>
<li>行为型</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>容器2</title>
			<link>https://cvvz.github.io/post/container2/</link>
			<pubDate>Fri, 23 Apr 2021 16:52:20 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/container2/</guid>
			<description>进程 单进程模型 容器中的1号进程对于宿主机而言就是一个普通的进程，它的父进程是runC，runC的父进程是containerd-shim。这个</description>
			<content type="html"><![CDATA[<h2 id="进程">进程</h2>
<h3 id="单进程模型">单进程模型</h3>
<p>容器中的1号进程对于宿主机而言就是一个普通的进程，它的父进程是runC，runC的父进程是containerd-shim。这个containerd-shim用于管理容器进程，类似于init或者systemd进程的作用(回收僵尸进程)，当进程退出时，containerd-shim会通过runC重新将进程拉起。</p>
<p>容器的“单进程模型”意味着容器进程本身，虽然是1号进程，但是它并不具有通常意义上1号进程，如systemd或init所具有的进程管理能力，比如托管孤儿进程，回收僵尸进程等，它就是一个普通的应用进程。</p>
<p>当然也可以给这个1号进程赋予这种能力，如docker启动容器的时候，加上<code>--init</code>参数，起来的容器就强制使用 <a href="https://github.com/krallin/tini">tini</a> 作为 init 进程了。这种1号进程非应用容器，而是由专门的init进程拉起其他所有应用进程的做法，称为“富容器”（rich container）。富容器的好处是可以把容器当成虚拟机一样对待，方便和经典PaaS体系对接。</p>
<p>云原生提倡使用轻量级容器，因为只有当1号进程就是应用进程本身时，才能准确的向容器运行时暴露进程的实际状况，方便使用kubernetes探针，以及依赖这些探针的周边组件，如service等。</p>
<h3 id="信号">信号</h3>
<p>缺省状态下，</p>
<ul>
<li>C 语言程序里，一个信号 handler 都没有注册；</li>
<li>Golang 程序里，很多信号都注册了自己的 handler；</li>
<li>bash 程序里注册了两个 handler，bit 2 和 bit 17，也就是 <code>SIGINT</code> 和 <code>SIGCHLD</code>。</li>
</ul>
<blockquote>
<p>可以通过查看 <code>/proc/$PID/status</code>中的<code>SigCgt</code> 行来了解哪些信号被捕获了（注册了信号处理函数）。</p>
</blockquote>
<p>虽然SIGTERM（15）的默认行为是终止进程，但是当1号进程<strong>没有为SIGTERM注册信号处理函数</strong>时，</p>
<ul>
<li>通过<code>kubectl exec</code>进入容器后，通过<code>kill</code>命令去优雅终止1号进程，是不会退出的</li>
<li>通过宿主机kill $PID，进程也不会退出</li>
</ul>
<p>此外，<strong>无论什么情况下，在容器中通过<code>kill -9</code>尝试强杀1号进程都不可能成功</strong>。</p>
<p>具体原因是，<code>kill</code> 命令实际上调用了 <code>kill()</code> 这个系统调用，内核尝试将信号发送给1号进程之前，在 <a href="https://github.com/torvalds/linux/blob/master/kernel/signal.c#L88-L89">sig_task_ignored</a> 函数中对一些特殊情况进行了过滤。</p>
<p>注册了信号处理函数后，1号进程又应该怎样处理 <code>SIGTERM</code> 呢？<strong>如果直接退出的话，1号进程会向同 Namespace 中的其他进程都发送一个 <code>SIGKILL</code> 信号。这会导致容器中的其他进程没有优雅退出。</strong></p>
<p>所以 <a href="https://github.com/krallin/tini">tini</a> 的实现方式是：把除了 <code>SIGCHILD</code> 以外的其他所有信号都转发给它的子进程；自己则负责通过 <code>waitpid</code> 来回收子进程资源，避免僵尸进程的产生。</p>
<blockquote>
<p>僵尸进程本质上是一个空的<code>task_struct</code>，它所拥有的资源（内存、文件句柄、信号量等）都已经被内核回收了，唯一消耗的资源是pid。</p>
<p>进程实际退出前的僵尸态是有必要的，它会通过<code>SIGCHILD</code>信号告诉父进程自己已经死了，让父进程知道子进程的终止状态，进行相应的处理，比如异常退出重新拉起。</p>
<p>僵尸进程过多会导致pid被占满，无法再运行新的进程。容器的最大进程数量由/sys/fs/cgroup/pids（pid cgroup）下的 <code>pids.max</code> 文件限制。</p>
</blockquote>
<h2 id="cpu">CPU</h2>
<h3 id="使用率">使用率</h3>
<p>kubernetes中Pod的cpu资源的<code>request</code> 和 <code>limit</code>字段限制的是cpu的<strong>使用率</strong>。</p>
<blockquote>
<p>top命令可以查看cpu的使用率，100%表示瞬时使用了1个CPU，200%表示2个。这个时间是从怎么来的？<strong>是从proc文件系统里拿到指标计算得来的。</strong></p>
<p>进程cpu使用率的具体定义是：（进程用户态和内核态在cpu调度中获得的cpu ticks/ 单个 CPU 产生的总 ticks）*100%</p>
<p>tick：Linux 时钟周期性地（比如1/100秒）产生中断，每次中断都会触发 Linux 内核去做一次进程调度，而这一次中断就是一个 tick。</p>
</blockquote>
<p><code>limit</code>意味着最大cpu的使用率能达到多少，这个值是通过cpu cgroup的<code>cpu.cfs_quota_us</code>（一个调度周期里这个控制组被允许的运行时间）除以 <code>cpu.cfs_period_us</code>（CPU调度周期）得来的；</p>
<p><code>request</code>表示即使当整个节点cpu被完全用满时，我的cpu利用率也能达到这么多，它是通过设置<code>cpu.shares</code>（节点上cgroup 可用cpu的相对比例）来实现的。</p>
<blockquote>
<p>对于系统<strong>各个类型的 CPU 使用率</strong>，则需要读取 /proc/stat 文件，得到瞬时各项 CPU 使用率的 ticks 值，相加得到一个总值，单项值除以总值就是各项 CPU 的使用率。</p>
</blockquote>
<h3 id="容器资源视图隔离">容器资源视图隔离</h3>
<p>相比使用虚拟机，使用容器，最大的问题在于<strong>资源视图的隔离</strong>。由于容器没有对/proc，/sys等文件系统进行隔离，因此在容器中使用free、top等命令看到的其实是物理机的数据。此外，应用程序可能会从<code>/sys/devices/system/cpu/online</code>中获取cpu的核数，来决定默认线程数，比如<code>GOMAXPROCS</code>。</p>
<p>我们可以通过<a href="https://github.com/lxc/lxcfs">lxcfs</a>来对容器资源视图进行隔离，让容器“表现的”更像一台虚拟机。对于go程序，还可以通过<a href="https://github.com/uber-go/automaxprocs">automaxprocs</a>这个包来在容器中正确设置<code>GOMAXPROCS</code>值。</p>
<h2 id="内存">内存</h2>
<h3 id="memoryusage_in_bytes">memory.usage_in_bytes</h3>
<p><code>malloc()</code>申请的其实是虚拟内存，容器根据进程的实际物理内存使用值<code>memory.stat[rss]</code>是否超过了<code>memory.limit_in_bytes</code>，再加上<code>memory.oom_control</code>来判断是否进行oom。</p>
<blockquote>
<p>你可以调整<code>memory.oom_control</code>参数，这样即使物理内存已经达到上限了，容器还是不会被cgroup干掉，可是这样的话，<strong>由于申请不到物理内存资源，进程会处于可中断睡眠状态。</strong></p>
</blockquote>
<p>cgroup当中的<code>memory.usage_in_bytes</code>实际上是由三部分组成：用户态物理内存(<code>memory.stat[rss]</code>) + 内核态内存(<code>memory.kmem.usage_in_bytes</code>) + page cache(<code>memory.stat[cache]</code>)，即<code>memory.usage_in_bytes</code> = <code>memory.stat[rss]</code> + <code>memory.stat[cache]</code> + <code>memory.kmem.usage_in_bytes</code>。</p>
<p>有时候我们发现容器的内存使用量<code>memory.usage_in_bytes</code>一直等于<code>memory.limit_in_bytes</code>，但是也不会发生OOM，是因为实际上每次以<strong>Buffered IO</strong>的方式读写磁盘时，Linux都会先将数据缓存到page cache当中来加快write/read系统调用的速度，也就是<code>memory.stat[rss]</code>值比较高，当进程需要物理内存时，操作系统会自动释放一部分page cache内存给rss内存使用。</p>
<h3 id="swap">swap</h3>
<p>kubelet缺省不能在打开swap的节点上运行。配置<code>--fail-swap-on=false</code>，kubelet可以在swap enabled的节点上运行。</p>
<p>rss内存中大部分<code>没有磁盘文件对应</code>，这种内存称为匿名内存。swap用于在内存资源紧张时，释放部分匿名内存到磁盘的swap空间。</p>
<p>内核的<code>/proc/sys/vm/swappiness</code>参数作用是当系统存在swap空间时，是优先释放page cache还是优先释放匿名内存，即写入swap。</p>
<p>cgroup中的<code>memory.swappiness</code>和全局的<code>/proc/sys/vm/swappiness</code>作用差不多。<strong>唯一区别是设置<code>memory.swappiness</code>为0，可以让这个cgroup控制组里的内存禁止使用swap。</strong></p>
<h2 id="存储">存储</h2>
<h3 id="容器文件系统">容器文件系统</h3>
<p>容器文件系统UnionFS，从原理上说，就是多个目录联合挂载到一个目录下，读/写这个目录就相当于读/写了对应目录中的内容。常用的有：aufs（没有合到linux kernel主干）、devicemapper和overlayFS。</p>
<p>以OverlayFS为例， OverlayFS有两层，分别是 lowerdir 和 upperdir。lowerdir 里是容器镜像中的文件，对于容器来说是只读的；upperdir 存放的是容器对文件系统里的所有改动，它是可读写的。lower和upper联合挂载到merged。</p>
<h3 id="blkio-cgroup">blkio cgroup</h3>
<p>磁盘io的两个主要性能指标：</p>
<ul>
<li>iops：每秒钟磁盘进行IO的次数</li>
<li>吞吐量（带宽）：以MB/s为单位，一次IO读写的数据块越大，吞吐量越大。即<strong>吞吐量 = IOPS * 数据块大小</strong>。</li>
</ul>
<p>cgroup v1的限制：每一个子系统都是独立的，对于某进程，只能<strong>独立的</strong>在各个cgroup子系统中限制它的资源使用。这样的问题在于，对于buffered I/O，它是先把数据写入page cache，再从page cache刷到磁盘；由于blkio和memory两个子系统相互独立，对于buffered I/O就无法限速了。</p>
<p>Cgroup v2的变化：一个进程属于一个<strong>控制组</strong>，在这个控制组里多个子系统可以<strong>协同运行</strong>。对某个进程，在控制组里同时限制memory + blkio就能对Buffered I/O 作磁盘读写的限速</p>
<h2 id="网络">网络</h2>
<p>容器 Network Namespace 的网络参数并不是完全从宿主机 Host Namespace 里继承的，也不是完全在新的 Network Namespace 建立的时候重新初始化的。在内核函数 <a href="https://github.com/torvalds/linux/blob/v5.4/net/ipv4/tcp_ipv4.c#L2631">tcp_sk_init()</a> 里，可以看到 <code>tcp_keepalive</code> 的三个参数都是重新初始化的，而 <code>tcp_congestion_control</code> 的值则是从 Host Namespace 里复制过来的。</p>
<p>在 Linux 中，管理员可以通过 sysctl 接口修改内核运行时的参数。在 <code>/proc/sys/</code> 虚拟文件系统下存放许多内核参数。这些参数涉及了多个内核子系统，比如内核子系统（通常前缀为: kernel.）、网络子系统（通常前缀为: net.）等。通过 <code>sysctl -a</code> 可以获取所有内核参数列表。</p>
<p>在kubernetes中，如果对内核网络参数有特殊需求，可以通过 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/sysctl-cluster/#%E8%AE%BE%E7%BD%AE-pod-%E7%9A%84-sysctl-%E5%8F%82%E6%95%B0">设置Pod的sysctl参数</a>，或者在给init container赋予特权，并通过 sysctl 修改内核网络参数。</p>
<h2 id="安全">安全</h2>
<h3 id="capabilityhttpsman7orglinuxman-pagesman7capabilities7html"><a href="https://man7.org/linux/man-pages/man7/capabilities.7.html">capability</a></h3>
<p>k8s没有对user namespace进行隔离，所以我们在容器里运行的是root用户。但是由于缺省启动容器时，系统只为1号进程开启了 <a href="https://github.com/opencontainers/runc/blob/v1.0.0-rc92/libcontainer/SPEC.md#security">15个capabilities</a>。而通过<code>kubectl exec -- sh</code>进入到容器里，启动的<code>sh</code>进程（<strong>所有命令的父进程</strong>）和容器的1号进程的 capabilities 相同。</p>
<p>我们可以通过配置容器的 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#securitycontext-v1-core">SecurityContext</a> 里的<code>capabilities</code>，或者配置容器为<code>privileged</code>。</p>
<h3 id="user-namespace">user namespace</h3>
<p>尽管容器中 root 用户的 Linux capabilities 已经减少了很多，但是在没有 User Namespace 的情况下，容器中 root 用户和宿主机上的 root 用户的 uid 是完全相同的，没有隔离。一旦有软件的漏洞，容器中的 root 用户就可以操控整个宿主机。</p>
<p>为了减少安全风险，业界都是建议在容器中以非 root 用户来运行进程。不过在<a href="https://github.com/kubernetes/enhancements/pull/2101">kubernetes目前还不支持 User Namespace</a> 的情况下，在容器中使用非 root 用户的话，对 uid 的管理和分配就比较麻烦了。</p>
]]></content>
		</item>
		
		<item>
			<title>kubernetes网络之service</title>
			<link>https://cvvz.github.io/post/k8s-network-service/</link>
			<pubDate>Wed, 30 Dec 2020 15:42:01 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-service/</guid>
			<description>在kubernetes中，service其实只是一个保存在etcd里的API对象，并不对应任何具体的实例。service即k8s中的“微服务</description>
			<content type="html"><![CDATA[<p>在kubernetes中，service其实只是一个保存在etcd里的API对象，并不对应任何具体的实例。service即k8s中的“微服务”，而它的服务注册与发现、健康检查、负载均衡等功能其实是底层watch service、endpoint、pod等资源的DNS、kube-proxy，以及iptables等共同配合实现的。</p>
<h2 id="从集群内部访问clusterip服务">从集群内部访问ClusterIP服务</h2>
<p>在<a href="https://cvvz.github.io/post/k8s-network-dns/">kubernetes网络之DNS
</a>一文中，已经详细说明了从域名到ClusterIP的转换过程。</p>
<p>下面以kubernetes集群中某个Pod访问<code>kubernetes</code>服务（kube-apiserver）为例，分析一下kubernetes是怎么将对ClusterIP的访问转变成对某个后端Pod的访问的。</p>
<blockquote>
<p>注：kube-proxy以iptables模式工作</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k get svc <span class="p">|</span> grep kubernetes
<span class="ln">2</span>kubernetes                      ClusterIP      192.168.0.1       &lt;none&gt;                  443/TCP                                             348d
<span class="ln">3</span>
<span class="ln">4</span>➜  ~ k get ep kubernetes
<span class="ln">5</span>NAME         ENDPOINTS                                                AGE
<span class="ln">6</span>kubernetes   10.20.126.169:6443,10.28.116.8:6443,10.28.126.199:6443   348d
</code></pre></div><ol>
<li>首先数据包从容器中被路由到cni网桥，出现在宿主机网络栈中。</li>
<li>Netfilter在<code>PREROUTING</code>链中处理该数据包，最终会将其转到<code>KUBE-SERVICES</code>链上进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A PREROUTING -m comment --comment <span class="s2">&#34;kubernetes service portals&#34;</span> -j KUBE-SERVICES
</code></pre></div><ol start="3">
<li><code>KUBE-SERVICES</code>链将目的地址为<code>192.168.0.1</code>的数据包跳转到<code>KUBE-SVC-NPX46M4PTMTKRN6Y</code>链进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SERVICES -d 192.168.0.1/32 -p tcp -m comment --comment <span class="s2">&#34;default/kubernetes:https cluster IP&#34;</span> -m tcp --dport <span class="m">443</span> -j KUBE-SVC-NPX46M4PTMTKRN6Y
</code></pre></div><ol start="4">
<li><code>KUBE-SVC-NPX46M4PTMTKRN6Y</code>链以<strong>相等概率</strong>将数据包跳转到<code>KUBE-SEP-A66XJ5Q22M6AZV5X</code>、<code>KUBE-SEP-TYGT5TFZZ2W5DK4V</code>或<code>KUBE-SEP-KQD4HGXQYU3ORDNS</code>链进行处理：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-A66XJ5Q22M6AZV5X
<span class="ln">2</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-TYGT5TFZZ2W5DK4V
<span class="ln">3</span>-A KUBE-SVC-NPX46M4PTMTKRN6Y -j KUBE-SEP-KQD4HGXQYU3ORDNS
</code></pre></div><ol start="5">
<li>而这三条链，其实代表了三条 DNAT 规则。DNAT 规则的作用，就是将 IP 包的目的地址和端口，改成 <code>--to-destination</code> 所指定的新的目的地址和端口。可以看到，这个目的地址和端口，正是后端 Pod 的 IP 地址和端口。而这一切发生在Netfilter的<code>PREROUTING</code>链上，接下来Netfilter就会根据这个目的地址，对数据包进行路由。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SEP-A66XJ5Q22M6AZV5X -p tcp -m tcp -j DNAT --to-destination 10.20.126.169:6443
<span class="ln">2</span>-A KUBE-SEP-TYGT5TFZZ2W5DK4V -p tcp -m tcp -j DNAT --to-destination 10.28.116.8:6443
<span class="ln">3</span>-A KUBE-SEP-KQD4HGXQYU3ORDNS -p tcp -m tcp -j DNAT --to-destination 10.28.126.199:6443
</code></pre></div><ol start="6">
<li>如果目的Pod的IP地址就在本节点，则数据包会被路由回cni网桥，由cni网桥进行转发；如果目的Pod的IP地址在其他节点，则要进行一次容器跨节点通信，跨节点通信的过程可以参考<a href="https://cvvz.github.io/post/k8s-network-cross-host/">kubernetes网络之CNI与跨节点通信原理</a>这篇文章。</li>
</ol>
<h2 id="从集群外部访问nodeport服务">从集群外部访问NodePort服务</h2>
<p>以下面这个服务(<strong>NodePort为<code>31849</code></strong>)为例：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k get svc webapp
<span class="ln">2</span>NAME     TYPE       CLUSTER-IP       EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>          AGE
<span class="ln">3</span>webapp   NodePort   192.168.15.113   &lt;none&gt;        8081:31849/TCP   319d
</code></pre></div><ol>
<li>kube-proxy会在主机上打开31849端口，并配置一系列iptables规则：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ sudo lsof -i:31849
<span class="ln">2</span>COMMAND      PID USER   FD   TYPE     DEVICE SIZE/OFF NODE NAME
<span class="ln">3</span>kube-prox <span class="m">253942</span> root   12u  IPv6 <span class="m">1852002168</span>      0t0  TCP *:31849 <span class="o">(</span>LISTEN<span class="o">)</span>
</code></pre></div><ol start="2">
<li>入口链<code>KUBE-NODEPORTS</code>是<code>KUBE-SERVICES</code>中的<strong>最后一条规则</strong>：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-SERVICES -m comment --comment <span class="s2">&#34;kubernetes service nodeports; NOTE: this must be the last rule in this chain&#34;</span> -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
</code></pre></div><ol start="3">
<li>先跳到<code>KUBE-MARK-MASQ</code>链打上<strong>特殊记号<code>0x4000/0x4000</code></strong>，这个特殊记号<strong>后续在<code>POSTROUTING</code>链中进行SNAT时用到</strong>。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-MARK-MASQ
<span class="ln">2</span>
<span class="ln">3</span>-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
</code></pre></div><ol start="4">
<li>然后跳到<code>KUBE-SVC-BL7FHTIPVYJBLWZN</code>链：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-SVC-BL7FHTIPVYJBLWZN
</code></pre></div><ol start="5">
<li>后续的处理流程和上一节描述的相同，直到找到了目的Pod IP。</li>
<li>如果目的Pod IP地址就在本节点，则路由给cni网桥转发；如果目的Pod IP在其他节点，则需要进行容器跨节点通信。<strong>注意，这种情形下，本节点相当于网关的角色，在将源数据包转发出去之前，需要进行SNAT，将源数据包的源IP地址，转换为网关（本节点）的IP地址，这样，数据包才可能原路返回，即从目的节点经过本节点返回到实际的k8s集群外部的客户端</strong>：</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-POSTROUTING -m comment --comment <span class="s2">&#34;kubernetes service traffic requiring SNAT&#34;</span> -m mark --mark 0x4000/0x4000 -j MASQUERADE
</code></pre></div><p>这条规则的意思就是：带有<code>0x4000/0x4000</code>这个特殊标记的数据包在离开节点之前，在<code>POSTROUTING</code>链上进行一次SNAT，即<code>MASQUERADE</code>。而这个特殊标记，如前所述，是在外部客户端数据流入节点时打上去的。</p>
<h2 id="总结">总结</h2>
<p>从上面的分析中，可以看出来，kube-proxy iptables模式中，最重要的是下面这五条链：</p>
<ul>
<li><strong>KUBE-SERVICES</strong>：ClusterIP方式访问的入口链；</li>
<li><strong>KUBE-NODEPORTS</strong>：NodePort方式访问的入口链；</li>
<li><strong>KUBE-SVC-</strong>*：相当于一个负载均衡器，将数据包平均分发给<code>KUBE-SEP-*</code>链；</li>
<li><strong>KUBE-SEP-</strong>*：通过DNAT将Service的目的IP和端口，替换为后端Pod的IP和端口，从而将流量转发到后端Pod。</li>
<li><strong>KUBE-POSTROUTING</strong>：通过对路由到其他节点的数据包进行SNAT，使其能够原路返回。</li>
</ul>
<blockquote>
<p>对于NodePort类型的service，<strong>如果本节点上没有目的Pod，则本节点起到的是网关的作用</strong>，将数据路由到其他节点。在这种情况下，<strong>访问Pod IP的链路会多一跳</strong>。我们可以通过将<code>externalTrafficPolicy</code>字段设置为<code>local</code>，当这样本节点上不存在Pod时，<code>FORWARD</code>链上的<code>filter</code>表规则会直接把包drop掉，而不会从本节点转发出去：</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="s2">&#34;default/webapp:&#34;</span> -m tcp --dport <span class="m">31849</span> -j KUBE-XLB-BL7FHTIPVYJBLWZN
<span class="ln">2</span>
<span class="ln">3</span>-A KUBE-XLB-BL7FHTIPVYJBLWZN -m comment --comment <span class="s2">&#34;default/webapp: has no local endpoints&#34;</span> -j KUBE-MARK-DROP
<span class="ln">4</span>
<span class="ln">5</span>-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
<span class="ln">6</span>
<span class="ln">7</span>-A KUBE-FIREWALL -m comment --comment <span class="s2">&#34;kubernetes firewall for dropping marked packets&#34;</span> -m mark --mark 0x8000/0x8000 -j DROP
</code></pre></div><h2 id="kube-proxy的ipvs模式">kube-proxy的IPVS模式</h2>
<p>上述流程描述的是kube-proxy的iptables模式的工作流程，这个模式最大的问题在于：</p>
<ul>
<li>kube-proxy需要为service配置大量的iptables规则，并且刷新这些规则以确保正确性；</li>
<li>iptables的规则是以链表的形式保存的，对iptables的刷新需要遍历链表</li>
</ul>
<p>解决办法就是使用IPVS模式的kube-proxy。IPVS是Linux内核实现的四层负载均衡，因此相比于通过配置iptables规则进行“投机取巧”式的负载均衡，IPVS更加专业。IPVS
和iptables一样底层也是基于netfilter，但使用更高效的数据结构（散列表），允许几乎无限的规模扩张。</p>
<p>创建一个service时，IPVS模式kube-proxy会创建一块虚拟网卡，并且把service的ClusterIP绑在网卡上，然后设置这个网卡的后端real server，对应的是EndPoints，并设置负载均衡规则。这样，数据包就会先发送到kube-proxy的虚拟网卡上，然后转发到后端Pod。</p>
<p>IPVS没有SNAT的能力，所以在一些场景下，依然需要依赖iptables。但是使用IPVS模式的kube-proxy，不存在上述两个问题，性能要优于iptables模式。</p>
]]></content>
		</item>
		
		<item>
			<title>kubernetes网络之CNI与跨节点通信原理</title>
			<link>https://cvvz.github.io/post/k8s-network-cross-host/</link>
			<pubDate>Wed, 30 Dec 2020 09:51:44 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-cross-host/</guid>
			<description>初始化infra容器网络环境 当kubelet通过调用CRI的RunPodSandbox创建好PodSandbox，即infra容器后，就需要</description>
			<content type="html"><![CDATA[<h2 id="初始化infra容器网络环境">初始化infra容器网络环境</h2>
<p>当kubelet通过调用CRI的<a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/cri-api/pkg/apis/services.go#L66">RunPodSandbox</a>创建好<code>PodSandbox</code>，即infra容器后，就需要调用<a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/dockershim/network/plugins.go#L73">SetUpPod</a>方法为Pod（infra容器）创建网络环境，底层是调用CNI的<a href="https://github.com/containernetworking/cni/blob/master/libcni/api.go#L80">AddNetwork</a>为infra容器配置网络环境。</p>
<p>这个配置网络环境的过程，就是kubelet从cni配置文件目录（<code>--cni-conf-dir</code>参数指定）中读取文件，并使用该文件中的CNI配置配置infra网络。kubelet根据配置文件，需要使用CNI插件二进制文件（存放在<code>--cni-bin-dir</code>参数指定的目录下）实际配置infra网络。</p>
<p>这些 CNI 的基础可执行文件，按照功能可以分为三类：</p>
<ol>
<li><strong>Main 插件</strong>，它是用来创建具体网络设备的二进制文件，比如bridge（网桥设备）、loopback（lo 设备）、ptp（Veth Pair 设备）等等</li>
<li><strong>IPAM（IP Address Management）插件</strong>，用来给容器分配IP地址，比如dhcp和host-local。</li>
<li><strong>CNI 社区维护的第三方 CNI 插件</strong>，比如<code>flannel</code>，提供跨主机通信方案</li>
</ol>
<p>初始化一个容器网络环境的过程大致如下：</p>
<ol>
<li>没有网桥就使用<code>bridge</code>创建一个网桥设备</li>
<li>使用<code>ptp</code>创建一个veth pair设备，并且把一端插在容器里，成为容器的eth0网卡，另一端插在网桥上</li>
<li>使用<code>dhcp</code>或<code>host-local</code>为eth0网卡分配IP地址</li>
<li>调用第三方CNI插件，比如<code>flannel</code>，实现容器跨主机通信方案</li>
</ol>
<h2 id="容器跨节点通信">容器跨节点通信</h2>
<p>在<a href="https://cvvz.github.io/post/container-network/">浅谈单机容器网络</a>一文中，已经详细分析了同一主机内部容器之间通过veth + 网桥的方式通信的过程，下面分析一下容器跨主机通信的过程。</p>
<p>容器的跨主机网络方案可以分为两类：<strong>overlay</strong>和<strong>underlay</strong>。</p>
<h3 id="underlay和overlay">underlay和overlay</h3>
<p>所谓underlay，也就是没有在宿主机网络上的虚拟层，容器和宿主机处于同一个网络层面上。</p>
<blockquote>
<p>在这种情形下，Kubernetes 内外网络是互通的，运行在kubernetes中的容器可以很方便的和公司内部已有的非云原生基础设施进行联动，比如DNS、负载均衡、配置中心等，而不需要借助kubernetes内部的DNS、ingress和service做服务发现和负载均衡。</p>
</blockquote>
<p>所谓overlay，其实就是在容器的IP包外面附加额外的数据包头，然后<strong>整体作为宿主机网络报文中的数据进行传输</strong>。容器的IP包加上额外的数据包头就用于跨主机的容器之间通信，<strong>容器网络就相当于覆盖(overlay)在宿主机网络上的一层虚拟网络</strong>。如下图所示：</p>
<figure>
    <img src="/overlay-network.png" width="600px"/> 
</figure>

<h3 id="flannel-udp模式">Flannel UDP模式</h3>
<p>Flannel的UDP模式的工作流程：</p>
<ol>
<li>container-1根据默认路由规则，将IP包发往cni网桥，出现在宿主机的网络栈上；</li>
<li>flanneld预先在宿主机上创建好了路由规则，数据包到达cni网桥后，随即被转发给了flannel0</li>
<li>flannel0的功能就是将数据包传给用户态的flanneld进程</li>
<li>flanneld进程查询etcd，找到目的容器ip地址和目的宿主机ip的对应关系，然后将原ip包封装在一个udp包中发送到目的宿主机上的flanneld进程。</li>
<li>目的宿主机的flanneld收到包后，反向处理一遍就发送到了目的容器中。</li>
</ol>
<p>整个过程如下图所示：</p>
<figure>
    <img src="/flannel-udp.jpg" width="600px"/> 
</figure>

<p>由于这中间数据从flannel0发送到了用户态的flanneld，又从flanneld发送到宿主机的eth0网卡，用户态和内核态发生了两次数据传递，且在用户态还进行了封包操作，所以udp模式性能很差。</p>
<h3 id="flannel-vxlan模式">Flannel VXLAN模式</h3>
<p>Flannel VXLAN模式的原理和UDP模式差不多，区别在于：</p>
<ol>
<li>UDP模式创建的是TUN设备(flannel0)，VXLAN模式创建的是VTEP设备（flannel.1）。</li>
<li>VTEP设备全程工作在内核态，性能比UDP模式更好。</li>
</ol>
<p>VXLAN模式的工作流程：</p>
<ol>
<li>container-1根据默认路由规则，将IP包发往cni网桥，出现在宿主机的网络栈上；</li>
<li>flanneld预先在宿主机上创建好了路由规则，数据包到达cni网桥后，随即被转发给了flannel.1，flannel.1是一个VTEP设备，<strong>它既有 IP 地址，也有 MAC 地址</strong>；</li>
<li><strong>在node2上的目的VTEP设备启动时，node1上的flanneld会将目的VTEP设备的IP地址和MAC地址分别写到node1上的路由表和ARP缓存表中</strong>。</li>
<li>因此，node1上的flannel.1通过查询路由表，知道要发往目的容器，需要经过10.1.16.0这个网关。<strong>其实这个网关，就是目的VTEP设备的ip地址</strong>。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ route -n
<span class="ln">2</span>Kernel IP routing table
<span class="ln">3</span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
<span class="ln">4</span>...
<span class="ln">5</span>10.1.16.0       10.1.16.0       255.255.255.0   UG    <span class="m">0</span>      <span class="m">0</span>        <span class="m">0</span> flannel.1
</code></pre></div><ol start="5">
<li>又由于<strong>这个网关的MAC地址，事先已经被flanneld写到了ARP缓存表中</strong>，所以内核直接把目的VTEP设备的MAC地址封装到链路层的帧头即可：
<figure>
    <img src="/flannel-vxlan-frame.jpg" width="500px"/> 
</figure>
</li>
<li><strong>flanneld还负责维护FDB（转发数据库）中的信息</strong>，查询FDB，就可以通过这个目的VTEP设备的MAC地址找到宿主机Node2的ip地址。</li>
<li>有了目的IP地址，接下来进行一次常规的、宿主机网络上的封包即可。</li>
</ol>
<p>整个过程如下图所示：</p>
<figure>
    <img src="/flannel-vxlan.jpg" width="600px"/> 
</figure>

<p>可以看出，VXLAN模式中，flanneld维护的都是内核态数据：路由表、arp缓存表、FDB，VXLAN模式几乎全程运行在内核态。性能要比UDP模式好不少。</p>
]]></content>
		</item>
		
		<item>
			<title>kubernetes网络之DNS</title>
			<link>https://cvvz.github.io/post/k8s-network-dns/</link>
			<pubDate>Wed, 30 Dec 2020 09:41:51 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-network-dns/</guid>
			<description>默认DNS策略 Pod默认的dns策略是 ClusterFirst，意思是先通过kubernetes的权威DNS服务器（如CoreDNS）直接</description>
			<content type="html"><![CDATA[<h2 id="默认dns策略">默认DNS策略</h2>
<p>Pod默认的<a href="https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy">dns策略</a>是 <code>ClusterFirst</code>，意思是先通过kubernetes的<strong>权威DNS服务器</strong>（如CoreDNS）直接解析出A记录或CNAME记录；如果解析失败，再根据配置，将其转发给<strong>上游DNS服务器</strong>。以CoreDNS为例，它的配置文件Corefile如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln"> 1</span>➜  ~ kubectl get cm -n kube-system coredns -o yaml
<span class="ln"> 2</span>apiVersion: v1
<span class="ln"> 3</span>data:
<span class="ln"> 4</span>  Corefile: <span class="p">|</span>
<span class="ln"> 5</span>    .:53 <span class="o">{</span>
<span class="ln"> 6</span>        errors
<span class="ln"> 7</span>        health <span class="o">{</span>
<span class="ln"> 8</span>           lameduck 5s
<span class="ln"> 9</span>        <span class="o">}</span>
<span class="ln">10</span>        ready
<span class="ln">11</span>        kubernetes cluster.local in-addr.arpa ip6.arpa <span class="o">{</span>
<span class="ln">12</span>           pods insecure
<span class="ln">13</span>           fallthrough in-addr.arpa ip6.arpa
<span class="ln">14</span>           ttl <span class="m">30</span>
<span class="ln">15</span>        <span class="o">}</span>
<span class="ln">16</span>        prometheus :9153
<span class="ln">17</span>        forward . /etc/resolv.conf
<span class="ln">18</span>        cache <span class="m">30</span>
<span class="ln">19</span>        loop
<span class="ln">20</span>        reload
<span class="ln">21</span>        loadbalance
<span class="ln">22</span>    <span class="o">}</span>
<span class="ln">23</span>kind: ConfigMap
<span class="ln">24</span>...
</code></pre></div><p>第17行使用<a href="https://coredns.io/plugins/forward/">forward插件</a>配置了上游域名服务器为主机的<code>/etc/resolv.conf</code>中指定的<code>nameserver</code>。</p>
<h2 id="service和dns">Service和DNS</h2>
<p>尽管kubelet在启动容器时，会将同namespace下的Service信息注入到容器的环境变量中：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln"> 1</span>➜  ~ kubectl get svc <span class="p">|</span> grep kubernetes
<span class="ln"> 2</span>kubernetes                      ClusterIP   192.168.0.1       &lt;none&gt;        443/TCP                                             347d
<span class="ln"> 3</span>
<span class="ln"> 4</span>➜  ~ kubectl <span class="nb">exec</span> -it debug-pod -n default -- env <span class="p">|</span> grep KUBERNETES
<span class="ln"> 5</span><span class="nv">KUBERNETES_SERVICE_PORT</span><span class="o">=</span><span class="m">443</span>
<span class="ln"> 6</span><span class="nv">KUBERNETES_PORT</span><span class="o">=</span>tcp://192.168.0.1:443
<span class="ln"> 7</span><span class="nv">KUBERNETES_PORT_443_TCP_ADDR</span><span class="o">=</span>192.168.0.1
<span class="ln"> 8</span><span class="nv">KUBERNETES_PORT_443_TCP_PORT</span><span class="o">=</span><span class="m">443</span>
<span class="ln"> 9</span><span class="nv">KUBERNETES_PORT_443_TCP_PROTO</span><span class="o">=</span>tcp
<span class="ln">10</span><span class="nv">KUBERNETES_PORT_443_TCP</span><span class="o">=</span>tcp://192.168.0.1:443
<span class="ln">11</span><span class="nv">KUBERNETES_SERVICE_PORT_HTTPS</span><span class="o">=</span><span class="m">443</span>
<span class="ln">12</span><span class="nv">KUBERNETES_SERVICE_HOST</span><span class="o">=</span>192.168.0.1
</code></pre></div><p>但是通常情况下我们使用DNS域名解析的方式进行服务注册和发现。</p>
<p>Kubernetes中的DNS应用部署好以后，会对外暴露一个服务，集群内的容器可以通过访问该服务的Cluster IP进行域名解析。DNS服务的Cluster IP由Kubelet的<code>cluster-dns</code>参数指定。并且在创建Pod时，由Kubelet将DNS Server的信息写入容器的<code>/etc/resolv.conf</code>文件中。</p>
<p>查看<code>resolv.conf</code>文件的配置：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- cat /etc/resolv.conf
<span class="ln">2</span>nameserver 192.168.0.2
<span class="ln">3</span>search default.svc.cluster.local svc.cluster.local cluster.local
<span class="ln">4</span>options ndots:5
</code></pre></div><ul>
<li>
<p><code>nameserver 192.168.0.2</code>这一行即表示DNS服务的地址（Cluster IP）为<code>192.168.0.2</code>。</p>
</li>
<li>
<p><code>search</code>这一行表示，如果无法直接解析域名，则会尝试加上<code>default.svc.cluster.local</code>, <code>svc.cluster.local</code>, <code>cluster.local</code>后缀进行域名解析。</p>
<blockquote>
<p>其中<code>default</code>是namespace，<code>cluster.local</code>是默认的集群域名后缀，kubelet也可以通过<code>--cluster-domain</code>参数进行配置。</p>
</blockquote>
</li>
</ul>
<p>也就是说：</p>
<ul>
<li>同namespace下，可以通过<code>nslookup</code> + <code>kubernetes</code>解析域名</li>
<li>不同namespace下，可以通过<code>nslookup</code> + <code>kubernetes.default</code>、<code>kubernetes.default.svc</code>、<code>kubernetes.default.svc.cluster.local</code>解析域名</li>
</ul>
<p>因为dns服务器会帮你补齐全域名：<code>kubernetes.default.svc.cluster.local</code></p>
<blockquote>
<p><code>{svc name}.{svc namespace}.svc.{cluster domain}</code>就是kubernetes的FQDN格式。</p>
</blockquote>
<h2 id="headless-service的域名解析">Headless Service的域名解析</h2>
<p><strong>无论是kube-dns还是CoreDNS，基本原理都是通过watch Service和Pod，生成DNS记录</strong>。常规的ClusterIP类型的Service的域名解析如上所述，DNS服务会返回一个<code>A记录</code>，即域名和ClusterIP的对应关系：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup kubernetes.default
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>Name:	kubernetes.default.svc.cluster.local
<span class="ln">6</span>Address: 192.168.0.1
</code></pre></div><p>Headless Service的域名解析稍微复杂一点。</p>
<blockquote>
<p>ClusterIP可以看作是Service的头，而Headless Service，顾名思义也就是指定他的ClusterIP为None的Service。</p>
</blockquote>
<h3 id="直接解析">直接解析</h3>
<p>当你直接解析它的域名时，返回的是EndPoints中的Pod IP列表：</p>
<blockquote>
<p>这个EndPoints后端的Pod，不仅可以通过在service中指定selector来选择，也可以自己定义，只要名字和service同名即可。</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln"> 1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup headless
<span class="ln"> 2</span>Defaulting container name to debug.
<span class="ln"> 3</span>Use <span class="s1">&#39;kubectl describe pod/debug-pod -n default&#39;</span> to see all of the containers in this pod.
<span class="ln"> 4</span>Server:		192.168.0.2
<span class="ln"> 5</span>Address:	192.168.0.2#53
<span class="ln"> 6</span>
<span class="ln"> 7</span>Name:	headless.default.svc.cluster.local
<span class="ln"> 8</span>Address: 1.1.1.1
<span class="ln"> 9</span>Name:	headless.default.svc.cluster.local
<span class="ln">10</span>Address: 2.2.2.2
<span class="ln">11</span>Name:	headless.default.svc.cluster.local
<span class="ln">12</span>Address: 3.3.3.3
</code></pre></div><h3 id="给pod生成a记录">给Pod生成A记录</h3>
<p>如果<strong>在<code>Pod.spec</code>中指定了<code>hostname</code>和<code>subdomain</code>，并且<code>subdomain</code>和headleass service的名字相同</strong>，那么kubernetes DNS会额外给这个Pod的FQDN生成A记录：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup mywebsite.headless.default.svc.cluster.local
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>Name:	mywebsite.headless.default.svc.cluster.local
<span class="ln">6</span>Address: 10.189.97.217
</code></pre></div><blockquote>
<p>Pod的FQDN是：<code>{hostname}.{subdomain}.{pod namespace}.svc.{cluster domain}</code></p>
</blockquote>
<h3 id="externalname-service">ExternalName Service</h3>
<p>ExternalName 类型的Service，kubernetes DNS会根据<code>ExternalName</code>字段，为其生成<strong>CNAME记录</strong>，在DNS层进行重定向。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="ln">2</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span><span class="ln">3</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">external</span><span class="w">
</span><span class="ln">5</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="ln">6</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="ln">7</span><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">ExternalName</span><span class="w">
</span><span class="ln">8</span><span class="w">  </span><span class="nt">externalName</span><span class="p">:</span><span class="w"> </span><span class="l">my.example.domain.com</span><span class="w">
</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>➜  ~ k <span class="nb">exec</span> -it debug-pod -n default -- nslookup external
<span class="ln">2</span>Server:		192.168.0.2
<span class="ln">3</span>Address:	192.168.0.2#53
<span class="ln">4</span>
<span class="ln">5</span>external.default.svc.cluster.local	canonical <span class="nv">name</span> <span class="o">=</span> my.example.domain.com.
<span class="ln">6</span>Name:	my.example.domain.com
<span class="ln">7</span>Address: 66.96.162.92
</code></pre></div>]]></content>
		</item>
		
		<item>
			<title>容器</title>
			<link>https://cvvz.github.io/post/container/</link>
			<pubDate>Thu, 24 Dec 2020 10:33:00 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/container/</guid>
			<description>容器镜像 容器镜像就是容器的rootfs。通过 Dockerfile 制作容器镜像时，就相当于增加 rootfs 层。通过容器镜像运行一个容器时，操作系统内核先将镜像中的每一层联</description>
			<content type="html"><![CDATA[<h2 id="容器镜像">容器镜像</h2>
<p>容器镜像就是容器的rootfs。通过 Dockerfile 制作容器镜像时，就相当于增加 rootfs 层。通过容器镜像运行一个容器时，操作系统内核先将镜像中的每一层<strong>联合挂载</strong>在一个统一的目录下，然后再通过<code>chroot</code>把容器的根目录挂载到这个统一的目录下。</p>
<p>通过 Dockerfile 生成容器镜像时，每个原语执行后，都会生成一个对应的镜像层。需要注意的是，即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，<strong>这个层是空的</strong>。</p>
<p>Docker 中最常用的联合文件系统（<code>UnionFS</code>）有三种：<code>AUFS</code>、<code>Devicemapper</code> 和 <code>OverlayFS</code>。</p>
<blockquote>
<p>overlay2 文件系统最多支持 128 个层数叠加，换句话说 Dockerfile 最多只能写 128 行。</p>
</blockquote>
<h2 id="namespace">namespace</h2>
<p>通过查看宿主机上的 <code>/proc/${pid}/ns</code> 目录可以知道容器进程当前的namespace。同一个Pod下的容器，共享哪些namespace呢？看一眼就知道了：</p>
<figure>
    <img src="/namespace.png" width="650px"/> 
</figure>

<p>可以看出：</p>
<ul>
<li>不共享的namespace是：mnt（挂载点）、pid（进程号）和uts（主机名）</li>
<li>共享的namespace是：ipc（进程间通信）、net（网络）和user（用户）。</li>
</ul>
<p>我用 <code> kubectl exec -it ${pod} -c ${container} -n ${ns} -- sh</code> 命令运行的sh进程，它的namespace和我指定的<code>${container}</code>容器一模一样。<code>kubectl exec</code> 本质上是通过<code>setns</code>系统调用加入了指定进程的namespace。</p>
<figure>
    <img src="/exec-namespace.png" width="650px"/> 
</figure>

<h2 id="cgroups">cgroups</h2>
<h3 id="cpu-cgroup">cpu cgroup</h3>
<ul>
<li>
<p>cpu.cfs_period_us：CFS（Completely Fair Scheduler）调度算法的一个调度周期</p>
</li>
<li>
<p>cpu.cfs_quota_us：CFS 调度算法中，在一个调度周期里这个控制组被允许的运行时间</p>
</li>
<li>
<p>cpu.shares：这个值决定了 CPU Cgroup 下控制组可用 CPU 的相对比例。<strong>不过只有当系统上 CPU 完全被占满的时候，这个比例才会在各个控制组间起作用</strong>。</p>
<blockquote>
<p><code>cpu.cfs_quota_us</code> / <code>cpu.cfs_period_us</code> 的值就限制了容器进程的最大cpu使用率。</p>
<p>在操作系统里，<code>cpu.cfs_period_us</code> 的值一般是个固定值，所以在kubernetes中，当你设置了Pod的<code>limits.cpu</code>的值后，kubelet会去修改cgroup中的<code>cpu.cfs_quota_us</code>这个参数来调整容器cpu的使用上限。</p>
<p>在kubernetes中，当设置了 Pod的<code>requests.cpu</code> 的值时，kubelet会去调整 <code>cpu.shares</code> 这个参数，来保证即使节点cpu使用率被打满了，容器仍然能分得一定量的cpu时间。</p>
</blockquote>
</li>
</ul>
<h3 id="cpu-使用率">cpu 使用率</h3>
<p>cpu时间的使用类型如下图所示：</p>
<figure>
    <img src="/cpu-usage.jpeg" width="650px"/> 
</figure>

<p>有两种情形可以认为进程处于R（运行态）：</p>
<ul>
<li>在运行队列中，等待cpu调度</li>
<li>获得了cpu资源，正在进行cpu运算</li>
</ul>
<p>进程处于睡眠态（在cpu调度器的等待队列中）也有两种情形：</p>
<ul>
<li>可中断，显示为 S 状态，可能是因为<strong>申请不到资源</strong>导致被挂起</li>
<li>不可中断睡眠，显示为 D 状态，可能是因为<strong>等待I/O操作完成</strong>，为了保证数据的一致性，这时进程不响应任何信号</li>
</ul>
<p>对于进程的 CPU 使用率，只包含两部分:</p>
<ul>
<li>一个是用户态， us 和 ni；</li>
<li>还有一部分是内核态，也就是 sy。</li>
</ul>
<p>至于 wa、hi、si，这些 I/O 或者中断相关的 CPU 使用，CPU Cgroup 不会去做限制。因为本身这些也不属于某个进程的cpu时间。</p>
<h3 id="cpu-负载">cpu 负载</h3>
<p>cpu 使用率和 cpu 平均负载的区别：</p>
<ul>
<li>cpu使用率是进程使用cpu的时间，包括用户态和内核态的时间之和。</li>
<li>cpu平均负载≈CPU可运行队列中的进程数+<strong>CPU休眠队列中不可中断状态的进程数</strong>。</li>
</ul>
<p>当节点上处于D状态的进程数量变多的时候，cpu的平均负载会升高，此时大量进程排队竞争disk I/O资源，但cpu可运行队列中的进程数却很少，所以虽然使用率很低，但是仍然会拖慢进程速度。</p>
<h3 id="cpu-cgroup-1">cpu cgroup</h3>
<p>cpu cgroup能限制cpu的使用率，但是cpu cgroup并没有办法解决平均负载升高的问题。</p>
<p>我们可以做的是，在生产环境中监控容器的宿主机节点里 D 状态的进程数量，然后对 D 状态进程数目异常的节点进行分析，比如磁盘硬件出现问题引起 D 状态进程数目增加，这时就需要更换硬盘。</p>
<h3 id="cpuset-cgroup">cpuset cgroup</h3>
<p>cpuset cgroup用于进程绑核，主要通过设置<code>cpuset.cpus</code>和<code>cpuset.mems</code>两个字段来实现。</p>
<p>在kubernetes中，当 Pod 属于 Guaranteed QoS 类型，并且 requests 值与 limits 被设置为同一个相等的<strong>整数值</strong>就相当于声明Pod中的容器要进行绑核。</p>
<h3 id="memory-cgroup">memory cgroup</h3>
<ul>
<li>memory.limit_in_bytes：一个控制组里所有进程可使用内存的最大值。一旦达到了这个值，可能会触发OOM。
<blockquote>
<p>在kubernetes中，当你指定了 Pod 的 <code>limits.memory=128Mi</code> 之后，相当于将 memory cgroup 中的 <code>memory.limit_in_bytes</code> 字段 设置为 128 * 1024 * 1024</p>
</blockquote>
</li>
<li>memory.usage_in_bytes：当前控制组里所有进程实际使用的内存总和，<strong>包括rss和page cache两部分</strong>。</li>
<li>memory.oom_control：决定了内存使用达到上限时，会不会触发OOM Killer。触发OOM时，会选择控制组里的某个进程杀掉。</li>
<li>memory.stat：显示了各种内存类型的实际开销。<strong>其中&quot;cache&quot;代表page cache；&ldquo;rss&quot;代表进程真正申请到的物理内存大小。RSS 内存和 Page Cache 内存的和，等于<code>memory.usage_in_bytes</code> 的值</strong>。判断容器真实的内存使用量，我们不能用<code>memory.usage_in_bytes</code>，而需要用 <code>memory.stat</code> 里的 rss 值。</li>
<li>memory.swappiness：定义Page Cache 内存和匿名内存释放的比例。</li>
</ul>
<blockquote>
<p>Q：当执行 <code>kubectl exec</code> 时，创建的进程会加入到容器的cgroup控制组吗？</p>
<p>A：会。以cpu cgroup为例，查看<code>/sys/fs/cgroup/cpu/kubepods.slice/kubepods-pod{$uid}.slice/docker-{$containerID}.scope/tasks</code>文件就能发现新创建的进程被加入到容器的cgroup控制组了。</p>
<p>Q：执行 <code>kubectl top</code> 命令获取到的pod指标是从哪里来的？</p>
<p>A：整个执行路径是：<code>kubectl -&gt; apiserver -&gt; aggregated-apiserver -&gt; metric-server -&gt; kubelet(cAdvisor) -&gt; cgroup</code>。最终来源就是cgroup。而Linux <code>top</code>命令的指标数据的来源是<code>/proc</code>文件系统。</p>
</blockquote>
<h2 id="kubeletdockercrioci">kubelet、Docker、CRI、OCI</h2>
<p>docker 架构图如下图所示：</p>
<figure>
    <img src="/docker.png" width="800px"/> 
</figure>

<p>kubelet和docker的集成方案：</p>
<figure>
    <img src="/kubelet-docker.png" width="800px"/> 
</figure>

<p>从这两幅图就能看出来，当前在kubernetes中，创建一个容器的调用链为：</p>
<p><code>kubelet -&gt; dockershim -&gt; docker daemon -&gt; containerd -&gt; containerd-shim -&gt; runc -&gt; container</code></p>
<p>dockershim实现了<a href="https://github.com/kubernetes/kubernetes/blob/8327e433590f9e867b1e31a4dc32316685695729/pkg/kubelet/apis/cri/services.go">CRI</a>定义的gRPC接口，实现方式就是充当docker daemon的客户端，向docker daemon发送命令。实际上dockershim和docker daemon都可以被干掉，<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#deprecation">kubernetes在v1.20也的确这么做了</a>。docker从kubernetes中被移除后，我们可以直接使用<a href="https://github.com/containerd/containerd">containerd</a>或<a href="https://github.com/cri-o/cri-o">CRI-O</a>作为CRI。</p>
<p><a href="https://github.com/opencontainers/runc">runC</a>则是一个<a href="https://github.com/opencontainers/runtime-spec">OCI</a>的参考实现，底层通过Linux系统调用为容器设置 namespaces 和 cgroups, 挂载 rootfs。当然kubernetes其实不关心OCI的底层是怎么实现的，只要能保证遵循OCI文档里的标准，就能自己实现一个OCI。<a href="https://github.com/kata-containers/kata-containers">Kata</a>就是遵循了OCI标准实现的安全容器。它的底层是用虚拟机实现的资源强隔离，而不是namespace。</p>
<p>Kata中的VM可以和Pod做一个类比：</p>
<ul>
<li>kubelet调用CRI的<code>RunPodSandbox</code>接口时，如果是runC实现的OCI，则会去创建<code>infra</code>容器，并执行<code>/pause</code>将容器挂起；如果是Kata，则会去创建一个虚拟机。</li>
<li>接着kubelet调用<code>CreateContainer</code>去创建容器，对于runC，就是创建容器进程并将他们的namespace加入<code>infra</code>容器中去；对于Kata，则是往VM中添加容器。</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>为什么删除Pod时webhook收到三次delete请求</title>
			<link>https://cvvz.github.io/post/k8s-3-deletion-webhook/</link>
			<pubDate>Sun, 13 Dec 2020 19:26:15 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-3-deletion-webhook/</guid>
			<description>最近在玩admission webhook时，发现一个奇怪的现象：我配置了validatingWebhookConfiguration使其监</description>
			<content type="html"><![CDATA[<p>最近在玩admission webhook时，发现一个奇怪的现象：我配置了validatingWebhookConfiguration使其监听pod的删除操作，结果发现每次删除Pod的时候，webhook会收到三次delete请求：</p>
<figure>
    <img src="/3-delete.png" width="1000px"/> 
</figure>

<p>从日志打印上可以分析出，第一次删除请求来自于kubectl客户端，后面两次来自于pod所在的node节点。为什么会收到三次delete请求呢？</p>
<h2 id="删除一个pod的过程">删除一个Pod的过程</h2>
<p>通过阅读kube-apiserver和kubelet源码，我把一个pod的删除过程总结成如下这幅流程图，三个红色加粗的请求即为webhook收到的三次delete请求。
<figure>
    <img src="/delete-pod.drawio.svg" width="800px"/> 
</figure>
</p>
<h3 id="kube-apiserver处理第一次删除请求">kube-apiserver处理第一次删除请求</h3>
<p>首先，由kubectl发来的delete请求，会经过kube-apiserver的admission-controller进行准入校验。我们定义了admission webhook，所以kube-apiserver会将该请求相关的信息封装在<strong>AdmissionReview</strong>结构体中发送给webhook。这是第一次webhook收到delete请求。</p>
<p>kube-apiserver作为一个http服务器，它的handler在<code>staging/src/k8s.io/apiserver/pkg/endpoints/installer.go</code>文件中的<code>registerResourceHandlers</code>函数中定义。其中<code>DELETE</code>请求的handler是<code>restfulDeleteResource</code>：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln">1</span><span class="k">case</span> <span class="s">&#34;DELETE&#34;</span><span class="p">:</span> <span class="c1">// Delete a resource.
</span><span class="ln">2</span><span class="c1"></span>    <span class="c1">// ...
</span><span class="ln">3</span><span class="c1"></span>
<span class="ln">4</span>    <span class="nx">handler</span> <span class="o">:=</span> <span class="nx">metrics</span><span class="p">.</span><span class="nf">InstrumentRouteFunc</span><span class="p">(</span><span class="nx">action</span><span class="p">.</span><span class="nx">Verb</span><span class="p">,</span> <span class="nx">group</span><span class="p">,</span> <span class="nx">version</span><span class="p">,</span> <span class="nx">resource</span><span class="p">,</span> <span class="nx">subresource</span><span class="p">,</span> <span class="nx">requestScope</span><span class="p">,</span> <span class="nx">metrics</span><span class="p">.</span><span class="nx">APIServerComponent</span><span class="p">,</span> <span class="nx">deprecated</span><span class="p">,</span> <span class="nx">removedRelease</span><span class="p">,</span> <span class="nf">restfulDeleteResource</span><span class="p">(</span><span class="nx">gracefulDeleter</span><span class="p">,</span> <span class="nx">isGracefulDeleter</span><span class="p">,</span> <span class="nx">reqScope</span><span class="p">,</span> <span class="nx">admit</span><span class="p">))</span>
<span class="ln">5</span>
<span class="ln">6</span>    <span class="o">...</span>
</code></pre></div><p><code>restfulDeleteResource</code>调用<code>DeleteResource</code>，后者则调用<code>staging/src/k8s.io/apiserver/pkg/registry/generic/registry/store.go</code>文件中的<code>Delete</code>方法对对象进行删除</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln">1</span><span class="kd">func</span> <span class="nf">restfulDeleteResource</span><span class="p">(</span><span class="nx">r</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">GracefulDeleter</span><span class="p">,</span> <span class="nx">allowsOptions</span> <span class="kt">bool</span><span class="p">,</span> <span class="nx">scope</span> <span class="nx">handlers</span><span class="p">.</span><span class="nx">RequestScope</span><span class="p">,</span> <span class="nx">admit</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Interface</span><span class="p">)</span> <span class="nx">restful</span><span class="p">.</span><span class="nx">RouteFunction</span> <span class="p">{</span>
<span class="ln">2</span>	<span class="k">return</span> <span class="kd">func</span><span class="p">(</span><span class="nx">req</span> <span class="o">*</span><span class="nx">restful</span><span class="p">.</span><span class="nx">Request</span><span class="p">,</span> <span class="nx">res</span> <span class="o">*</span><span class="nx">restful</span><span class="p">.</span><span class="nx">Response</span><span class="p">)</span> <span class="p">{</span>
<span class="ln">3</span>		<span class="nx">handlers</span><span class="p">.</span><span class="nf">DeleteResource</span><span class="p">(</span><span class="nx">r</span><span class="p">,</span> <span class="nx">allowsOptions</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">scope</span><span class="p">,</span> <span class="nx">admit</span><span class="p">)(</span><span class="nx">res</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">req</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span>
<span class="ln">4</span>	<span class="p">}</span>
<span class="ln">5</span><span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="nf">DeleteResource</span><span class="p">(</span><span class="nx">r</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">GracefulDeleter</span><span class="p">,</span> <span class="nx">allowsOptions</span> <span class="kt">bool</span><span class="p">,</span> <span class="nx">scope</span> <span class="o">*</span><span class="nx">RequestScope</span><span class="p">,</span> <span class="nx">admit</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Interface</span><span class="p">)</span> <span class="nx">http</span><span class="p">.</span><span class="nx">HandlerFunc</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="c1">//...
</span><span class="ln"> 3</span><span class="c1"></span>
<span class="ln"> 4</span>    <span class="nx">trace</span><span class="p">.</span><span class="nf">Step</span><span class="p">(</span><span class="s">&#34;About to delete object from database&#34;</span><span class="p">)</span>
<span class="ln"> 5</span>		<span class="nx">wasDeleted</span> <span class="o">:=</span> <span class="kc">true</span>
<span class="ln"> 6</span>		<span class="nx">userInfo</span><span class="p">,</span> <span class="nx">_</span> <span class="o">:=</span> <span class="nx">request</span><span class="p">.</span><span class="nf">UserFrom</span><span class="p">(</span><span class="nx">ctx</span><span class="p">)</span>
<span class="ln"> 7</span>		<span class="nx">staticAdmissionAttrs</span> <span class="o">:=</span> <span class="nx">admission</span><span class="p">.</span><span class="nf">NewAttributesRecord</span><span class="p">(</span><span class="kc">nil</span><span class="p">,</span> <span class="kc">nil</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Kind</span><span class="p">,</span> <span class="nx">namespace</span><span class="p">,</span> <span class="nx">name</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Resource</span><span class="p">,</span> <span class="nx">scope</span><span class="p">.</span><span class="nx">Subresource</span><span class="p">,</span> <span class="nx">admission</span><span class="p">.</span><span class="nx">Delete</span><span class="p">,</span> <span class="nx">options</span><span class="p">,</span> <span class="nx">dryrun</span><span class="p">.</span><span class="nf">IsDryRun</span><span class="p">(</span><span class="nx">options</span><span class="p">.</span><span class="nx">DryRun</span><span class="p">),</span> <span class="nx">userInfo</span><span class="p">)</span>
<span class="ln"> 8</span>		<span class="nx">result</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nf">finishRequest</span><span class="p">(</span><span class="nx">timeout</span><span class="p">,</span> <span class="kd">func</span><span class="p">()</span> <span class="p">(</span><span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 9</span>			<span class="nx">obj</span><span class="p">,</span> <span class="nx">deleted</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">r</span><span class="p">.</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">name</span><span class="p">,</span> <span class="nx">rest</span><span class="p">.</span><span class="nf">AdmissionToValidateObjectDeleteFunc</span><span class="p">(</span><span class="nx">admit</span><span class="p">,</span> <span class="nx">staticAdmissionAttrs</span><span class="p">,</span> <span class="nx">scope</span><span class="p">),</span> <span class="nx">options</span><span class="p">)</span>
<span class="ln">10</span>			<span class="nx">wasDeleted</span> <span class="p">=</span> <span class="nx">deleted</span>
<span class="ln">11</span>			<span class="k">return</span> <span class="nx">obj</span><span class="p">,</span> <span class="nx">err</span>
<span class="ln">12</span>		<span class="p">})</span>
<span class="ln">13</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">14</span>			<span class="nx">scope</span><span class="p">.</span><span class="nf">err</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">w</span><span class="p">,</span> <span class="nx">req</span><span class="p">)</span>
<span class="ln">15</span>			<span class="k">return</span>
<span class="ln">16</span>		<span class="p">}</span>
<span class="ln">17</span>        <span class="nx">trace</span><span class="p">.</span><span class="nf">Step</span><span class="p">(</span><span class="s">&#34;Object deleted from database&#34;</span><span class="p">)</span>
<span class="ln">18</span>        
<span class="ln">19</span>        <span class="o">...</span>
<span class="ln">20</span><span class="p">}</span>
</code></pre></div><p><code>Delete</code>方法中，在<code>BeforeDelete</code>函数中判断是否需要优雅删除，判断的标准是<code>DeletionGracePeriodSeconds</code>值是否为0，不为零则认为是优雅删除，kube-apiserver不会立即将这个API对象从etcd中删除，否则直接删除。</p>
<p>对于Pod而言，默认<code>DeletionGracePeriodSeconds</code>为30秒，因此这里不会被kube-apiserver立刻删除掉。而是将<code>DeletionTimestamp</code>设置为当前时间，<code>DeletionGracePeriodSeconds</code>设置为默认值30秒。</p>
<h3 id="kubelet杀掉容器">kubelet杀掉容器</h3>
<p>kube-apiserver设置好<code>DeletionTimestamp</code>和<code>DeletionGracePeriodSeconds</code>这两个字段后，kubelet 会watch到Pod的更新。那kubelet list-watch机制又是怎么实现的呢？</p>
<p>Kubelet在<code>makePodSourceConfig</code>函数中，监听了三种类型的Pod：通过<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/static-pod/#configuration-files">文件系统上的配置文件</a>配置的静态Pod，通过<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/static-pod/#pods-created-via-http">web 网络上的配置文件</a>配置的静态Pod，以及kube-apiserver中的pod。我们主要关心第三种。</p>
<p>Kubelet通过reflactor watch到Pod资源发生变化后，是通过channel的方式将Pod及其变化传递给syncLoop主控制循环中进行处理的，<strong>并没有使用informer+workqueque的方式</strong>。</p>
<p>kubelet的主控制循环在<code>pkg/kubelet/kubelet.go</code>文件中的<code>syncLoopIteration</code>函数：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">kl</span> <span class="o">*</span><span class="nx">Kubelet</span><span class="p">)</span> <span class="nf">syncLoopIteration</span><span class="p">(</span><span class="nx">configCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">PodUpdate</span><span class="p">,</span> <span class="nx">handler</span> <span class="nx">SyncHandler</span><span class="p">,</span>
<span class="ln"> 2</span>	<span class="nx">syncCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Time</span><span class="p">,</span> <span class="nx">housekeepingCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Time</span><span class="p">,</span> <span class="nx">plegCh</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="o">*</span><span class="nx">pleg</span><span class="p">.</span><span class="nx">PodLifecycleEvent</span><span class="p">)</span> <span class="kt">bool</span> <span class="p">{</span>
<span class="ln"> 3</span>	<span class="k">select</span> <span class="p">{</span>
<span class="ln"> 4</span>	<span class="k">case</span> <span class="nx">u</span><span class="p">,</span> <span class="nx">open</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="nx">configCh</span><span class="p">:</span>
<span class="ln"> 5</span>		<span class="c1">// Update from a config source; dispatch it to the right handler
</span><span class="ln"> 6</span><span class="c1"></span>		<span class="c1">// callback.
</span><span class="ln"> 7</span><span class="c1"></span>		<span class="k">if</span> <span class="p">!</span><span class="nx">open</span> <span class="p">{</span>
<span class="ln"> 8</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Update channel is closed. Exiting the sync loop.&#34;</span><span class="p">)</span>
<span class="ln"> 9</span>			<span class="k">return</span> <span class="kc">false</span>
<span class="ln">10</span>		<span class="p">}</span>
<span class="ln">11</span>
<span class="ln">12</span>		<span class="k">switch</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Op</span> <span class="p">{</span>
<span class="ln">13</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">ADD</span><span class="p">:</span>
<span class="ln">14</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (ADD, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">15</span>			<span class="c1">// After restarting, kubelet will get all existing pods through
</span><span class="ln">16</span><span class="c1"></span>			<span class="c1">// ADD as if they are new pods. These pods will then go through the
</span><span class="ln">17</span><span class="c1"></span>			<span class="c1">// admission process and *may* be rejected. This can be resolved
</span><span class="ln">18</span><span class="c1"></span>			<span class="c1">// once we have checkpointing.
</span><span class="ln">19</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodAdditions</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">20</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">UPDATE</span><span class="p">:</span>
<span class="ln">21</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (UPDATE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">PodsWithDeletionTimestamps</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">22</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodUpdates</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">23</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">REMOVE</span><span class="p">:</span>
<span class="ln">24</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (REMOVE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">25</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodRemoves</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">26</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">RECONCILE</span><span class="p">:</span>
<span class="ln">27</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">4</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (RECONCILE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">28</span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodReconcile</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">29</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">DELETE</span><span class="p">:</span>
<span class="ln">30</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (DELETE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">31</span>			<span class="c1">// DELETE is treated as a UPDATE because of graceful deletion.
</span><span class="ln">32</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodUpdates</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">33</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">RESTORE</span><span class="p">:</span>
<span class="ln">34</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;SyncLoop (RESTORE, %q): %q&#34;</span><span class="p">,</span> <span class="nx">u</span><span class="p">.</span><span class="nx">Source</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">))</span>
<span class="ln">35</span>			<span class="c1">// These are pods restored from the checkpoint. Treat them as new
</span><span class="ln">36</span><span class="c1"></span>			<span class="c1">// pods.
</span><span class="ln">37</span><span class="c1"></span>			<span class="nx">handler</span><span class="p">.</span><span class="nf">HandlePodAdditions</span><span class="p">(</span><span class="nx">u</span><span class="p">.</span><span class="nx">Pods</span><span class="p">)</span>
<span class="ln">38</span>		<span class="k">case</span> <span class="nx">kubetypes</span><span class="p">.</span><span class="nx">SET</span><span class="p">:</span>
<span class="ln">39</span>			<span class="c1">// TODO: Do we want to support this?
</span><span class="ln">40</span><span class="c1"></span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Kubelet does not support snapshot update&#34;</span><span class="p">)</span>
<span class="ln">41</span>        <span class="p">}</span>
<span class="ln">42</span>
<span class="ln">43</span>        <span class="o">...</span>
</code></pre></div><p>当Pod的<code>DeletionTimestamp</code>被设置时，Kubelet会走入<code>kubetypes.DELETE</code>这个分支，最终会调用到<code>pkg/kubelet/kubelet.go</code>中的<code>syncPod</code>函数，<strong><code>syncPod</code> 这个函数是 kubelet 核心处理函数</strong>。这个函数会调用到容器运行时的<code>KillPod</code>方法，该方法进而又会以goroutine的方式，使用<code>pkg/kubelet/kuberuntime/kuberuntime_container.go</code>中定义的<code>killContainer</code>方法<strong>并行的杀掉</strong>所有容器。<code>killContainer</code>的代码实现如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">kubeGenericRuntimeManager</span><span class="p">)</span> <span class="nf">killContainer</span><span class="p">(</span><span class="nx">pod</span> <span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Pod</span><span class="p">,</span> <span class="nx">containerID</span> <span class="nx">kubecontainer</span><span class="p">.</span><span class="nx">ContainerID</span><span class="p">,</span> <span class="nx">containerName</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">message</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">gracePeriodOverride</span> <span class="o">*</span><span class="kt">int64</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
<span class="ln"> 2</span>	<span class="o">...</span>
<span class="ln"> 3</span>
<span class="ln"> 4</span>	<span class="c1">// From this point, pod and container must be non-nil.
</span><span class="ln"> 5</span><span class="c1"></span>	<span class="nx">gracePeriod</span> <span class="o">:=</span> <span class="nb">int64</span><span class="p">(</span><span class="nx">minimumGracePeriodInSeconds</span><span class="p">)</span>
<span class="ln"> 6</span>	<span class="k">switch</span> <span class="p">{</span>
<span class="ln"> 7</span>	<span class="k">case</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">DeletionGracePeriodSeconds</span> <span class="o">!=</span> <span class="kc">nil</span><span class="p">:</span>
<span class="ln"> 8</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">pod</span><span class="p">.</span><span class="nx">DeletionGracePeriodSeconds</span>
<span class="ln"> 9</span>	<span class="k">case</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">Spec</span><span class="p">.</span><span class="nx">TerminationGracePeriodSeconds</span> <span class="o">!=</span> <span class="kc">nil</span><span class="p">:</span>
<span class="ln">10</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">pod</span><span class="p">.</span><span class="nx">Spec</span><span class="p">.</span><span class="nx">TerminationGracePeriodSeconds</span>
<span class="ln">11</span>	<span class="p">}</span>
<span class="ln">12</span>
<span class="ln">13</span>	<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nx">message</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
<span class="ln">14</span>		<span class="nx">message</span> <span class="p">=</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Sprintf</span><span class="p">(</span><span class="s">&#34;Stopping container %s&#34;</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Name</span><span class="p">)</span>
<span class="ln">15</span>	<span class="p">}</span>
<span class="ln">16</span>	<span class="nx">m</span><span class="p">.</span><span class="nf">recordContainerEvent</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">,</span> <span class="nx">v1</span><span class="p">.</span><span class="nx">EventTypeNormal</span><span class="p">,</span> <span class="nx">events</span><span class="p">.</span><span class="nx">KillingContainer</span><span class="p">,</span> <span class="nx">message</span><span class="p">)</span>
<span class="ln">17</span>
<span class="ln">18</span>	<span class="c1">// Run internal pre-stop lifecycle hook
</span><span class="ln">19</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">internalLifecycle</span><span class="p">.</span><span class="nf">PreStopContainer</span><span class="p">(</span><span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">20</span>		<span class="k">return</span> <span class="nx">err</span>
<span class="ln">21</span>	<span class="p">}</span>
<span class="ln">22</span>
<span class="ln">23</span>	<span class="c1">// Run the pre-stop lifecycle hooks if applicable and if there is enough time to run it
</span><span class="ln">24</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Lifecycle</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="nx">containerSpec</span><span class="p">.</span><span class="nx">Lifecycle</span><span class="p">.</span><span class="nx">PreStop</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="nx">gracePeriod</span> <span class="p">&gt;</span> <span class="mi">0</span> <span class="p">{</span>
<span class="ln">25</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="nx">gracePeriod</span> <span class="o">-</span> <span class="nx">m</span><span class="p">.</span><span class="nf">executePreStopHook</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">,</span> <span class="nx">containerSpec</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">26</span>	<span class="p">}</span>
<span class="ln">27</span>	<span class="c1">// always give containers a minimal shutdown window to avoid unnecessary SIGKILLs
</span><span class="ln">28</span><span class="c1"></span>	<span class="k">if</span> <span class="nx">gracePeriod</span> <span class="p">&lt;</span> <span class="nx">minimumGracePeriodInSeconds</span> <span class="p">{</span>
<span class="ln">29</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="nx">minimumGracePeriodInSeconds</span>
<span class="ln">30</span>	<span class="p">}</span>
<span class="ln">31</span>	<span class="k">if</span> <span class="nx">gracePeriodOverride</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">32</span>		<span class="nx">gracePeriod</span> <span class="p">=</span> <span class="o">*</span><span class="nx">gracePeriodOverride</span>
<span class="ln">33</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Killing container %q, but using %d second grace period override&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">34</span>	<span class="p">}</span>
<span class="ln">35</span>
<span class="ln">36</span>	<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Killing container %q with %d second grace period&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">(),</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">37</span>
<span class="ln">38</span>	<span class="nx">err</span> <span class="o">:=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">runtimeService</span><span class="p">.</span><span class="nf">StopContainer</span><span class="p">(</span><span class="nx">containerID</span><span class="p">.</span><span class="nx">ID</span><span class="p">,</span> <span class="nx">gracePeriod</span><span class="p">)</span>
<span class="ln">39</span>	<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">40</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;Container %q termination failed with gracePeriod %d: %v&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">(),</span> <span class="nx">gracePeriod</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
<span class="ln">41</span>	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
<span class="ln">42</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Container %q exited normally&#34;</span><span class="p">,</span> <span class="nx">containerID</span><span class="p">.</span><span class="nf">String</span><span class="p">())</span>
<span class="ln">43</span>	<span class="p">}</span>
<span class="ln">44</span>
<span class="ln">45</span>	<span class="nx">m</span><span class="p">.</span><span class="nx">containerRefManager</span><span class="p">.</span><span class="nf">ClearRef</span><span class="p">(</span><span class="nx">containerID</span><span class="p">)</span>
<span class="ln">46</span>
<span class="ln">47</span>	<span class="k">return</span> <span class="nx">err</span>
<span class="ln">48</span><span class="p">}</span>  
</code></pre></div><p>这个方法就是先调用prestop hook，然后在通过<code>runtimeService.StopContainer</code>方法杀掉容器进程，整个过程总时长不能超过<code>DeletionGracePeriodSeconds</code>。注意，prestop hook是不会进行重试的，失败了kubelet也不管，容器还是照杀不误。</p>
<h3 id="statusmanager发送删除请求">statusManager发送删除请求</h3>
<p>kubelet以goroutine的方式运行着一个<code>statusManager</code>，它的作用就是周期性的监听Pod的状态变化，然后执行<code>func (m *manager) syncPod(uid types.UID, status versionedPodStatus) {</code>。在<code>syncPod</code>中，注意到有如下的逻辑：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">manager</span><span class="p">)</span> <span class="nf">syncPod</span><span class="p">(</span><span class="nx">uid</span> <span class="nx">types</span><span class="p">.</span><span class="nx">UID</span><span class="p">,</span> <span class="nx">status</span> <span class="nx">versionedPodStatus</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>
<span class="ln"> 4</span>    <span class="k">if</span> <span class="nx">m</span><span class="p">.</span><span class="nf">canBeDeleted</span><span class="p">(</span><span class="nx">pod</span><span class="p">,</span> <span class="nx">status</span><span class="p">.</span><span class="nx">status</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 5</span>		<span class="nx">deleteOptions</span> <span class="o">:=</span> <span class="nx">metav1</span><span class="p">.</span><span class="nx">DeleteOptions</span><span class="p">{</span>
<span class="ln"> 6</span>			<span class="nx">GracePeriodSeconds</span><span class="p">:</span> <span class="nb">new</span><span class="p">(</span><span class="kt">int64</span><span class="p">),</span>
<span class="ln"> 7</span>			<span class="c1">// Use the pod UID as the precondition for deletion to prevent deleting a
</span><span class="ln"> 8</span><span class="c1"></span>			<span class="c1">// newly created pod with the same name and namespace.
</span><span class="ln"> 9</span><span class="c1"></span>			<span class="nx">Preconditions</span><span class="p">:</span> <span class="nx">metav1</span><span class="p">.</span><span class="nf">NewUIDPreconditions</span><span class="p">(</span><span class="nb">string</span><span class="p">(</span><span class="nx">pod</span><span class="p">.</span><span class="nx">UID</span><span class="p">)),</span>
<span class="ln">10</span>		<span class="p">}</span>
<span class="ln">11</span>		<span class="nx">err</span> <span class="p">=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">kubeClient</span><span class="p">.</span><span class="nf">CoreV1</span><span class="p">().</span><span class="nf">Pods</span><span class="p">(</span><span class="nx">pod</span><span class="p">.</span><span class="nx">Namespace</span><span class="p">).</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">TODO</span><span class="p">(),</span> <span class="nx">pod</span><span class="p">.</span><span class="nx">Name</span><span class="p">,</span> <span class="nx">deleteOptions</span><span class="p">)</span>
<span class="ln">12</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">13</span>			<span class="nx">klog</span><span class="p">.</span><span class="nf">Warningf</span><span class="p">(</span><span class="s">&#34;Failed to delete status for pod %q: %v&#34;</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pod</span><span class="p">(</span><span class="nx">pod</span><span class="p">),</span> <span class="nx">err</span><span class="p">)</span>
<span class="ln">14</span>			<span class="k">return</span>
<span class="ln">15</span>		<span class="p">}</span>
<span class="ln">16</span>		<span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;Pod %q fully terminated and removed from etcd&#34;</span><span class="p">,</span> <span class="nx">format</span><span class="p">.</span><span class="nf">Pod</span><span class="p">(</span><span class="nx">pod</span><span class="p">))</span>
<span class="ln">17</span>		<span class="nx">m</span><span class="p">.</span><span class="nf">deletePodStatus</span><span class="p">(</span><span class="nx">uid</span><span class="p">)</span>
<span class="ln">18</span>	<span class="p">}</span>
<span class="ln">19</span><span class="p">}</span>
</code></pre></div><p>也就是说，<strong><code>statusManager</code>发现Pod可以被删除的时候，就会去调用clientset的delete接口将Pod资源从kube-apiserver中删掉</strong>。那什么时候Pod可以被删除呢？自然是在上一步中，kubelet将Pod的容器、卷、cgroup sandbox等资源统统删除掉，就可以被删除了。</p>
<p>这里，webhook就会收到第二次删除请求，而且这次请求中，将<code>GracePeriodSeconds</code>设置为了0，这就代表着kube-apiserver收到这个DELETE请求后，可以将Pod从etcd中删除了。</p>
<h3 id="第三次delete请求">第三次delete请求</h3>
<p>webhook为什么会收到第三次delete请求，这个问题着实困扰了我很久。</p>
<p>从日志的serviceAccount的信息来看，很像是节点上的组件又发了一次DELETE请求。是kubelet吗？还是kube-proxy？但是查看相关日志和代码，没有发现任何可疑点。</p>
<p>其实，第三次DELETE请求是kube-apiserver自己发的。</p>
<p>在第一部分中，我提到kube-apiserver收到DELETE请求后最终会调用<code>staging/src/k8s.io/apiserver/pkg/registry/generic/registry/store.go</code>文件中的<code>Delete</code>方法，然后由于走的是优雅删除，它更新完Pod的<code>DeletionTimestamp</code>和<code>DeletionGracePeriodSeconds</code>两个字段后，就返回了。</p>
<p>现在，第二次DELETE请求将<code>GracePeriodSeconds</code>设置为了0，于是现在可以开始执行实际的删除操作了。</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">e</span> <span class="o">*</span><span class="nx">Store</span><span class="p">)</span> <span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span> <span class="nx">context</span><span class="p">.</span><span class="nx">Context</span><span class="p">,</span> <span class="nx">name</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">deleteValidation</span> <span class="nx">rest</span><span class="p">.</span><span class="nx">ValidateObjectFunc</span><span class="p">,</span> <span class="nx">options</span> <span class="o">*</span><span class="nx">metav1</span><span class="p">.</span><span class="nx">DeleteOptions</span><span class="p">)</span> <span class="p">(</span><span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="kt">bool</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>    <span class="c1">// delete immediately, or no graceful deletion supported
</span><span class="ln"> 4</span><span class="c1"></span>    <span class="nx">klog</span><span class="p">.</span><span class="nf">V</span><span class="p">(</span><span class="mi">6</span><span class="p">).</span><span class="nf">Infof</span><span class="p">(</span><span class="s">&#34;going to delete %s from registry: &#34;</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span>
<span class="ln"> 5</span>    <span class="nx">out</span> <span class="p">=</span> <span class="nx">e</span><span class="p">.</span><span class="nf">NewFunc</span><span class="p">()</span>
<span class="ln"> 6</span>    <span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">Storage</span><span class="p">.</span><span class="nf">Delete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">key</span><span class="p">,</span> <span class="nx">out</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">preconditions</span><span class="p">,</span> <span class="nx">storage</span><span class="p">.</span><span class="nf">ValidateObjectFunc</span><span class="p">(</span><span class="nx">deleteValidation</span><span class="p">),</span> <span class="nx">dryrun</span><span class="p">.</span><span class="nf">IsDryRun</span><span class="p">(</span><span class="nx">options</span><span class="p">.</span><span class="nx">DryRun</span><span class="p">));</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 7</span>        <span class="c1">// Please refer to the place where we set ignoreNotFound for the reason
</span><span class="ln"> 8</span><span class="c1"></span>        <span class="c1">// why we ignore the NotFound error .
</span><span class="ln"> 9</span><span class="c1"></span>        <span class="k">if</span> <span class="nx">storage</span><span class="p">.</span><span class="nf">IsNotFound</span><span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="nx">ignoreNotFound</span> <span class="o">&amp;&amp;</span> <span class="nx">lastExisting</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">10</span>            <span class="c1">// The lastExisting object may not be the last state of the object
</span><span class="ln">11</span><span class="c1"></span>            <span class="c1">// before its deletion, but it&#39;s the best approximation.
</span><span class="ln">12</span><span class="c1"></span>            <span class="nx">out</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">e</span><span class="p">.</span><span class="nf">finalizeDelete</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">lastExisting</span><span class="p">,</span> <span class="kc">true</span><span class="p">)</span>
<span class="ln">13</span>            <span class="k">return</span> <span class="nx">out</span><span class="p">,</span> <span class="kc">true</span><span class="p">,</span> <span class="nx">err</span>
<span class="ln">14</span>        <span class="p">}</span>
<span class="ln">15</span>        <span class="k">return</span> <span class="kc">nil</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="nx">storeerr</span><span class="p">.</span><span class="nf">InterpretDeleteError</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">qualifiedResource</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span>
<span class="ln">16</span>    <span class="p">}</span>
<span class="ln">17</span>    <span class="o">...</span>
<span class="ln">18</span><span class="p">}</span>
</code></pre></div><p>在<code>e.Storage.Delete</code>方法中，定义了<code>storage.ValidateObjectFunc(deleteValidation)</code>参数，仔细阅读这个方法的实现细节，原来，kube-apiserver在进行删除前，还会再对这个删除操作执行一次准入控制校验，即Validating和Mutating。代码逻辑见<code>staging/src/k8s.io/apiserver/pkg/storage/etcd3/store.go</code>中的<code>conditionalDelete</code>函数：</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="ln"> 1</span><span class="kd">func</span> <span class="p">(</span><span class="nx">s</span> <span class="o">*</span><span class="nx">store</span><span class="p">)</span> <span class="nf">conditionalDelete</span><span class="p">(</span><span class="nx">ctx</span> <span class="nx">context</span><span class="p">.</span><span class="nx">Context</span><span class="p">,</span> <span class="nx">key</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">out</span> <span class="nx">runtime</span><span class="p">.</span><span class="nx">Object</span><span class="p">,</span> <span class="nx">v</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">Value</span><span class="p">,</span> <span class="nx">preconditions</span> <span class="o">*</span><span class="nx">storage</span><span class="p">.</span><span class="nx">Preconditions</span><span class="p">,</span> <span class="nx">validateDeletion</span> <span class="nx">storage</span><span class="p">.</span><span class="nx">ValidateObjectFunc</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
<span class="ln"> 2</span>    <span class="o">...</span>
<span class="ln"> 3</span>    <span class="k">for</span> <span class="p">{</span>
<span class="ln"> 4</span>		<span class="nx">origState</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">s</span><span class="p">.</span><span class="nf">getState</span><span class="p">(</span><span class="nx">getResp</span><span class="p">,</span> <span class="nx">key</span><span class="p">,</span> <span class="nx">v</span><span class="p">,</span> <span class="kc">false</span><span class="p">)</span>
<span class="ln"> 5</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 6</span>			<span class="k">return</span> <span class="nx">err</span>
<span class="ln"> 7</span>		<span class="p">}</span>
<span class="ln"> 8</span>		<span class="k">if</span> <span class="nx">preconditions</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln"> 9</span>			<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">preconditions</span><span class="p">.</span><span class="nf">Check</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">obj</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">10</span>				<span class="k">return</span> <span class="nx">err</span>
<span class="ln">11</span>			<span class="p">}</span>
<span class="ln">12</span>		<span class="p">}</span>
<span class="ln">13</span>		<span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nf">validateDeletion</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">obj</span><span class="p">);</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
<span class="ln">14</span>			<span class="k">return</span> <span class="nx">err</span>
<span class="ln">15</span>		<span class="p">}</span>
<span class="ln">16</span>		<span class="nx">startTime</span> <span class="o">:=</span> <span class="nx">time</span><span class="p">.</span><span class="nf">Now</span><span class="p">()</span>
<span class="ln">17</span>		<span class="nx">txnResp</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">s</span><span class="p">.</span><span class="nx">client</span><span class="p">.</span><span class="nx">KV</span><span class="p">.</span><span class="nf">Txn</span><span class="p">(</span><span class="nx">ctx</span><span class="p">).</span><span class="nf">If</span><span class="p">(</span>
<span class="ln">18</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">Compare</span><span class="p">(</span><span class="nx">clientv3</span><span class="p">.</span><span class="nf">ModRevision</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span> <span class="s">&#34;=&#34;</span><span class="p">,</span> <span class="nx">origState</span><span class="p">.</span><span class="nx">rev</span><span class="p">),</span>
<span class="ln">19</span>		<span class="p">).</span><span class="nf">Then</span><span class="p">(</span>
<span class="ln">20</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">OpDelete</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span>
<span class="ln">21</span>		<span class="p">).</span><span class="nf">Else</span><span class="p">(</span>
<span class="ln">22</span>			<span class="nx">clientv3</span><span class="p">.</span><span class="nf">OpGet</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span>
<span class="ln">23</span>        <span class="p">).</span><span class="nf">Commit</span><span class="p">()</span>
<span class="ln">24</span>    <span class="o">...</span>
<span class="ln">25</span>
<span class="ln">26</span><span class="p">}</span>
</code></pre></div><p>validateDeletion 即为进行DELETE准入控制校验的地方，这个过程中必定会调用到Validating webhook，也就有了第三次delete请求。至于为什么要再做一次准入控制，我也不太明白。</p>
]]></content>
		</item>
		
		<item>
			<title>Kubernetes Volume实现原理</title>
			<link>https://cvvz.github.io/post/k8s-volume/</link>
			<pubDate>Sat, 12 Dec 2020 12:32:33 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-volume/</guid>
			<description>容器运行时挂载卷的过程 如果CRI是通过dockershim实现的话，kubelet通过CRI接口去拉起一个容器，就好比是通过docker-d</description>
			<content type="html"><![CDATA[<h2 id="容器运行时挂载卷的过程">容器运行时挂载卷的过程</h2>
<p>如果CRI是通过dockershim实现的话，kubelet通过CRI接口去拉起一个容器，就好比是通过docker-daemon执行<code>docker run</code>命令。</p>
<p>而如果想要在容器中挂载宿主机目录的话，就要带上<code>-v</code>参数，以下面这条命令为例：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>docker run -v /home:/test ...
</code></pre></div><p>它的具体的实现过程如下：</p>
<ol>
<li>
<p>创建容器进程并开启Mount namespace</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="ln">1</span><span class="kt">int</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">main_function</span><span class="p">,</span> <span class="n">stack_size</span><span class="p">,</span> <span class="n">CLONE_NEWNS</span> <span class="o">|</span> <span class="n">SIGCHLD</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span> 
</code></pre></div></li>
<li>
<p>将宿主机目录挂载到容器进程的目录中来</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="ln">1</span><span class="n">mount</span><span class="p">(</span><span class="s">&#34;/home&#34;</span><span class="p">,</span> <span class="s">&#34;/test&#34;</span><span class="p">,</span> <span class="s">&#34;&#34;</span><span class="p">,</span> <span class="n">MS_BIND</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span>
</code></pre></div><blockquote>
<p>此时虽然开启了mount namespace，只代表主机和容器之间mount点隔离开了，容器仍然可以看到主机的文件系统目录。</p>
</blockquote>
</li>
<li>
<p>调用 <code>pivot_root</code> 或 <code>chroot</code>，改变容器进程的根目录。至此，容器再也看不到宿主机的文件系统目录了。</p>
</li>
</ol>
<h2 id="kubelet挂载卷的过程">kubelet挂载卷的过程</h2>
<p>当一个Pod被调度到一个节点上之后，kubelet首先为这个Pod在宿主机上创建一个Volume目录：</p>
<p><strong>/var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt;</strong>。</p>
<p>在kubernetes中，卷<code>volumes</code>是Pod的一个属性，而不是容器的。kubelet先以Pod为单位，在宿主机这个Volume目录中准备好Pod需要的卷。接着启动容器，容器启动时，根据<code>volumeMounts</code>的定义将主机的这个目录下的部分卷资源挂载进来。挂载的过程如前所述，相当于为每个容器执行了命令：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>docker run -v /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt;:/&lt;容器内的目标目录&gt; 我的镜像 ...
</code></pre></div><p>而kubelet是怎么把卷挂载到主机的volumes目录下的呢？这取决于Volume的类型。</p>
<h3 id="远程块存储">远程块存储</h3>
<ol>
<li>
<p>Attach：将远程磁盘挂载到本地，成为一个主机上的一个块设备，通过<code>lsblk</code>命令可以查看到。</p>
<blockquote>
<p>Attach 这一步，由<code>kube-controller-manager</code>中的<code>Volume Controller</code>负责</p>
</blockquote>
</li>
<li>
<p>Mount：本地有了新的块设备后，先将其格式化为某种文件系统格式后，就可以进行mount操作了。</p>
<blockquote>
<p>Mount 这一步，由kubelet中的<code>VolumeManagerReconciler</code>这个控制循环负责，它是一个独立于kubelet主循环的goroutine。</p>
</blockquote>
</li>
</ol>
<h3 id="nfs">NFS</h3>
<p>NFS本身已经是一个远程的文件系统了，所以可以直接进行mount，相当于执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>mount -t nfs &lt;NFS服务器地址&gt;:/ /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt; 
</code></pre></div><h3 id="hostpath">hostPath</h3>
<p>hostPath类型的挂载方式，和宿主机上的Volume目录没啥关系，就是容器直接挂载指定的宿主机目录。</p>
<h3 id="emptydirdownwardapiconfigmapsecret">emptyDir、downwardAPI、configMap、secret</h3>
<p>这几种挂载方式，数据都会随着Pod的消亡而被删除。原因是kubelet在创建Pod的Volume资源时，其实是在主机的Volume目录下创建了一些子目录供容器进行挂载。Pod被删除时，kubelet也会把这个Volume目录删掉，从而这个Volume目录中的子目录也都被删除，这几种类型的数据就被删掉了。</p>
<blockquote>
<p>远程块存储、NFS存储等持久化的存储，和hostPath、emptyDir、downwardAPI、configMap、secret不一样，<strong>不是在Pod或任何一种workload中的volume字段中直接定义的</strong>，而是在PV中定义的。</p>
</blockquote>
<h2 id="pvcpv和storageclass">PVC、PV和StorageClass</h2>
<p>在Pod中，如果想使用持久化的存储，如上面提到的远程块存储、NFS存储，或是本地块存储（非hostPath），则在volumes字段中，定义<code>persistentVolumeClaim</code>，即PVC。</p>
<p>PVC和PV进行绑定的过程，由<code>Volume Controller</code>中的<code>PersistentVolumeController</code>这个控制循环负责。所谓“绑定”，也就是填写PVC中的<code>spec.volumeName</code>字段而已。<code>PersistentVolumeController</code>只会将StorageClass相同的PVC和PV绑定起来。</p>
<p>StorageClass主要用来动态分配存储(Dynamic Provisioning)。StorageClass中的<code>provisioner</code>字段用于指定使用哪种<a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner">存储插件</a>进行动态分配，当然，前提是你要在kubernetes中装好对应的存储插件。<code>parameters</code>字段就是生成出来的PV的参数。</p>
<blockquote>
<p><code>PersistentVolumeController</code>只是在找不到对应的PV资源和PVC进行绑定时，借助StorageClass生成了一个PV这个API对象。具体这个PV是怎么成为主机volume目录下的一个子目录的，则是靠前面所述的Attach + Mount两阶段处理后的结果。当然如果是NFS或本地持久化卷，就不需要<code>Volume Controller</code>进行Attach操作了。</p>
</blockquote>
<h2 id="本地持久化卷">本地持久化卷</h2>
<p>对于本地持久化卷，通过在PV模版中</p>
<ul>
<li>定义<code>spec.nodeAffinity</code>来指定持久化卷位于哪个宿主机上</li>
<li>定义<code>spec.local.path</code>来指定宿主机的持久化卷的路径。</li>
</ul>
<p>此外，由于<code>PersistentVolumeController</code>只会将StorageClass相同的PVC和PV绑定起来，所以还需要创建一个StorageClass，并且使PVC和PV中的<code>StorageClassName</code>相同。</p>
<p>在 StorageClass 里，进行了如下定义：<code>volumeBindingMode: WaitForFirstConsumer</code>，这个字段的作用是<strong>延迟绑定PV和PVC</strong>。定义了这个字段，PVC和PV的绑定就不会在<code>PersistentVolumeController</code>中进行，而是由<strong>调度器</strong>在调度Pod的时候，根据Pod中声明的PVC，来决定和哪个PV进行绑定。</p>
<p>本地持久化卷是没办法进行 Dynamic Provisioning的，所以StorageClass字段中的<code>provisioner</code>定义的是<code>kubernetes.io/no-provisioner</code>。但是它的Static Provisioning也并不需要纯手工操作。运维人员可以使用<a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">local-static-provisioner</a>对PV进行自动管理。它的原理是通过DaemonSet检测节点的<code>/mnt/disks</code>目录，这个目录下如果存在挂载点，则根据这个路径自动生成对应的PV。所以，运维人员只需要在node节点上，在<code>/mnt/disks</code>目录下准备好挂载点即可。</p>
<blockquote>
<p>Q：hostPath可以是挂载在宿主机上的一块磁盘，而不是宿主机的主目录，这种情况使用hostPath作为持久化存储不会导致宿主机宕机。那是不是可以使用hostPath代替PVC/PV作为本地持久化卷？</p>
<p>A：不可以。这种玩法失去了<code>PersistentVolumeController</code>对PVC和PV进行自动绑定、解绑的灵活性。也失去了通过<code>local-static-provisioner</code>对PV进行自动管理的灵活性。最关键的是失去了<strong>延迟绑定</strong>的特性，调度器进行调度的时候，无法参考节点存储的使用情况。</p>
<p>Q：删除一个被Pod使用中的PVC/PV时，kubectl会卡住，为什么？</p>
<p>A：PVC和PV中定义了<code>kubernetes.io/pvc-protection</code>、<code>kubernetes.io/pv-protection</code>这个finalizer字段，删除时，资源不会被apiserver立即删除，要等到<code>volume controller</code>进行<strong>pre-delete</strong>操作后，将finalizer字段删掉，才会被实际删除。而<code>volume controller</code>的<strong>pre-delete</strong>操作实际上就是检查PVC/PV有没有被Pod使用。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>浅谈单机容器网络</title>
			<link>https://cvvz.github.io/post/container-network/</link>
			<pubDate>Thu, 03 Dec 2020 00:16:18 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/container-network/</guid>
			<description>容器网络环境隔离怎么理解？ 容器的网络环境是隔离的，这个隔离就体现在不共用内核网络协议栈，即不共用网络协议栈要用到的数据和设备了： 传输层：端口</description>
			<content type="html"><![CDATA[<h2 id="容器网络环境隔离怎么理解">容器网络环境隔离怎么理解？</h2>
<p>容器的网络环境是隔离的，这个隔离就体现在不共用内核网络协议栈，即<strong>不共用网络协议栈要用到的数据和设备</strong>了：</p>
<ul>
<li>传输层：端口号</li>
<li>网络层：路由表、iptables规则</li>
<li>数据链路层：网卡设备、arp缓存表</li>
</ul>
<p>如果在容器中执行<code>iptables</code>、<code>ifconfig</code>、<code>arp</code>和<code>route</code>命令看到的肯定是不同的iptables规则、网络设备、arp缓存表和路由表。</p>
<h2 id="网桥和veth-pair">网桥和veth pair</h2>
<p>同一个宿主机的容器之间通信是通过二层网络进行通信的。物理机如果想通过二层网络通信，那么必须要有两样东西，一个是网线，一个是交换机。</p>
<p>在Linux系统中，扮演虚拟交换机角色的，叫做网桥；扮演网线角色的，叫做veth pair。</p>
<p>以Docker为例，在bridge模式下：</p>
<ul>
<li>Docker Daemon第一次启动时会创建<code>docker0</code>网桥；</li>
<li>在创建容器时，会创建一个veth pair，即veth设备对。</li>
</ul>
<p>veth pair有两个端点：</p>
<ul>
<li>一端在宿主机中，可以看成是宿主机的一块虚拟网卡，但被关联到docker0网桥上；</li>
<li>另一端，则借助net namespace技术，变成了容器中的eth0网卡。</li>
</ul>
<blockquote>
<p>veth pair之所以可以被看成“网线”，是因为它的特殊之处在于，只要有一端收到了数据包，同样的数据包也会在另一端出现。不受namespace的约束。</p>
</blockquote>
<p>网桥：Linux的网桥提供了在同一个机器上各种网络设备之间互相转发数据的设备。<strong>普通的交换机对于接收到的报文，要么转发，要么丢弃，网桥除了具备普通交换机的功能以外，它还可以调用内核协议栈，处理发送给本机的报文</strong>。</p>
<h2 id="同宿主机中的容器通信过程">同宿主机中的容器通信过程</h2>
<p>同一台宿主机中的两个容器（容器A -&gt; 容器B）建立通信的过程如下（<strong>容器B的ip地址为172.17.0.3</strong>）：</p>
<ol>
<li>
<p>容器A中的内核网络协议栈对网络层进行处理时，去查路由表：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>$ route
<span class="ln">2</span>Kernel IP routing table
<span class="ln">3</span>Destination     Gateway        Genmask       Flags  Metric Ref Use Iface
<span class="ln">4</span>default         172.17.0.1     0.0.0.0        UG     <span class="m">0</span>     <span class="m">0</span>   <span class="m">0</span>   eth0
<span class="ln">5</span>172.17.0.0      0.0.0.0        255.255.0.0    U      <span class="m">0</span>     <span class="m">0</span>   <span class="m">0</span>   eth0
</code></pre></div><p>发现路由表中容器B的网络地址和第二条规则匹配。这条路由规则的网关（Gateway）是 <code>0.0.0.0</code>，这就意味着这是一条直连规则，即：凡是匹配到这条规则的 IP 包，应该经过 eth0 网卡，通过二层网络直接发往目的主机。</p>
</li>
<li>
<p>容器A于是查询本地的arp缓存表，如果没有找到目的MAC地址，则发一条arp广播，通过容器的eth0网卡发送出去。</p>
</li>
<li>
<p>veth pair的另一端收到这个arp消息，把它转发给docker0网桥。</p>
<blockquote>
<p>这个另一端是宿主机的一块虚拟网卡，本来是应该可以调用网络协议栈来处理收到的数据包的，但是它被和docker0网桥绑定了，所以它的功能被降级为交换机的一个端口，只能无脑把数据包发给网桥去处理。</p>
</blockquote>
</li>
<li>
<p>docker0网桥扮演二层交换机的角色，把arp请求广播出去，收到容器B返回的MAC地址后，再通过原链路把MAC地址返回给容器A。</p>
</li>
<li>
<p>容器A使用目的MAC地址和源MAC地址封装链路层头部，将消息通过eth0网卡发送出去。</p>
</li>
<li>
<p>docker0网桥收到数据包，直接根据目的MAC地址将其转发给容器B。</p>
</li>
</ol>
<p>整个过程可以用下面这张图概括：</p>
<figure>
    <img src="/container-network.png" width="600px"/> 
</figure>

<h2 id="pod中的容器网络">Pod中的容器网络</h2>
<p>创建一个Pod前，首先要创建infra容器，这个infra容器就通过veth设备连接到网桥，接着创建其他容器，其他容器<strong>加入</strong>infra容器的net namespace，这样，就能做到和infra容器之间以localhost的方式通信，<strong>因为同一个namespace中的进程，共享内核数据和网络设备</strong>。</p>
]]></content>
		</item>
		
		<item>
			<title>以aggregated apiserver的方式部署admission webhook</title>
			<link>https://cvvz.github.io/post/why-aggregated-api-server-webhook/</link>
			<pubDate>Tue, 01 Dec 2020 07:19:06 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/why-aggregated-api-server-webhook/</guid>
			<description>热身概念：apiserver认证客户端的方式 apiserver为客户端提供三种认证方式： https双向认证（注意是双向认证，例如kubeco</description>
			<content type="html"><![CDATA[<h2 id="热身概念apiserver认证客户端的方式">热身概念：apiserver认证客户端的方式</h2>
<p>apiserver为客户端提供三种认证方式：</p>
<ol>
<li>https<strong>双向</strong>认证（注意是双向认证，例如kubeconfig文件中既要配置客户端证书和私钥，又要配置CA证书）</li>
<li>http token认证（例如serviceaccount对应的secret中，包含token文件、ca证书，容器就是通过这两个文件和apiserver进行http token认证的）</li>
<li>http base认证（用户名+密码）</li>
</ol>
<h2 id="admission-webhook和扩展apiserver">admission webhook和扩展apiserver</h2>
<p>对于这两种情形，<strong>apiserver是作为客户端</strong>，admission webhook和扩展apiserver作为服务端。</p>
<h3 id="apiserver通过https连接admission-webhook">apiserver通过HTTPS连接admission webhook</h3>
<p>当apiserver作为客户端连接admission webhook时，要求admission webhook必须提供https安全认证，但是默认是<strong>单向</strong>认证即可。<strong>也就是admission webhook负责提供服务端证书供apiserver进行验证，但webhook默认可以不验证apiserver</strong>。apiserver所需要的CA证书在webhookconfiguration文件中的<code>caBundle</code>字段中进行配置。如果不配置，则默认使用apiserver自己的CA证书。</p>
<p>我们可以自己签发webhook的证书，如<code>istio</code>项目中使用的<a href="https://github.com/istio/istio/blob/release-0.7/install/kubernetes/webhook-create-signed-cert.sh">脚本</a>，或者像<code>openkruise</code>项目一样<a href="https://github.com/openkruise/kruise/blob/master/pkg/webhook/util/controller/webhook_controller.go#L262">在controller中生成证书</a>，当然也可以使用cert-manager自动生成和管理证书。</p>
<h3 id="admission-webhook验证apiserver">admission webhook验证apiserver</h3>
<p>如果你的admission webhook想要验证客户端（也就是apiserver），那么就需要额外给apiserver提供一个配置文件，这个配置文件的内容和kubeconfig很像，可以指定apisever使用http base认证、http token或者证书来向webhook提供身份证明，具体过程详见<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#authenticate-apiservers">官方文档</a>。</p>
<p>简单来讲就是：在启动 apiserver时，通过<code>--admission-control-config-file</code> 这个参数指定了客户端认证的配置文件，这个文件的格式和用 kubectl 连接 apiserver 时用到的 <code>kubeconfig</code> 格式几乎一样。只不过这里，客户端是apiserver，服务端是admission webhook。</p>
<p>通过这种方式验证客户端，最麻烦的地方是需要手工维护kubeconfig，且对于每个webhook都需要维护一个。</p>
<h3 id="apiserver通过https双向连接扩展apiserver">apiserver通过HTTPS（双向）连接扩展apiserver</h3>
<p>aggregated apiserver在设计之初就解决了客户端认证的问题，具体实现过程详见<a href="https://kubernetes.io/zh/docs/tasks/extend-kubernetes/configure-aggregation-layer/#kubernetes-apiserver-%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%A4%E8%AF%81">官方文档</a>。</p>
<h2 id="以扩展apiserver的方式部署admission-webhook">以扩展apiserver的方式部署admission webhook</h2>
<p>openshift 的 <a href="https://github.com/openshift/generic-admission-server#generic-admission-server">generic-admission-server库</a> 是一种用来编写admission webhook的lib库，它声称<strong>使用它可以避免apiserver为每一个admission webhook维护一个kubeconfig。（不过我觉得它最大的好处是可以不部署服务端证书，这是通过正常方式部署admission webhook时所办不到的）</strong>。我们来看下它是如何实现的。</p>
<ol>
<li>
<p>在(Validating/Mutating)WebhookConfiguration中，配置admission webhook为kubernetes服务：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">webhooks</span><span class="p">:</span><span class="w">
</span><span class="ln">2</span><span class="w"></span>- <span class="nt">clientConfig</span><span class="p">:</span><span class="w">
</span><span class="ln">3</span><span class="w">    </span><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes</span><span class="w">
</span><span class="ln">5</span><span class="w">      </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="ln">6</span><span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/apis/{group}/{version}/{resource}</span><span class="w">
</span><span class="ln">7</span><span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span></code></pre></div></li>
<li>
<p>在ApiService中，配置group、version，以及admission webhook的service：</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="ln">1</span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="ln">2</span><span class="w">  </span><span class="nt">group</span><span class="p">:</span><span class="w"> </span>{<span class="l">group}</span><span class="w">
</span><span class="ln">3</span><span class="w">  </span><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="ln">4</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span>{<span class="l">webhook-service}</span><span class="w">
</span><span class="ln">5</span><span class="w">    </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span>{<span class="l">namespace}</span><span class="w">
</span><span class="ln">6</span><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span><span class="ln">7</span><span class="w">  </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span>{<span class="l">version}</span><span class="w">
</span></code></pre></div></li>
</ol>
<p>这种方式部署的admission webhook的整个工作流程如下图所示：
<figure>
    <img src="/webhook.drawio.svg" width="400px"/> 
</figure>
</p>
<ol>
<li>
<p>apiserver过滤指定的请求，<strong>将它发到自己的路径下</strong>。</p>
</li>
<li>
<p>由aggregator转发到扩展apiserver，也就是真正的admission webhook进行处理。</p>
</li>
</ol>
<p>这样就省去了为apiserver配置和维护kubeconfig文件的步骤。</p>
<p><strong>并且还有一个额外的“好处”是，可以设置apiservice配置文件中的 <code>spec.insecureSkipTLSVerify</code>字段为true，这样连服务端证书都可以偷懒省去了：）</strong></p>
]]></content>
		</item>
		
		<item>
			<title>kubectl patch</title>
			<link>https://cvvz.github.io/post/k8s-kubectl-patch/</link>
			<pubDate>Sun, 22 Nov 2020 23:16:44 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-kubectl-patch/</guid>
			<description>kubectl patch 用来修改 Kubernetes API 对象的字段。可以通过 --type 参数指定三种不同类型的 patch 方式： strategic：strategic merge patch merge： json merge patch json： json</description>
			<content type="html"><![CDATA[<p><code>kubectl patch</code> 用来修改 Kubernetes API 对象的字段。可以通过 <code>--type</code> 参数指定三种不同类型的 patch 方式：</p>
<ul>
<li><code>strategic</code>：strategic merge patch</li>
<li><code>merge</code>： json merge patch</li>
<li><code>json</code>： json patch</li>
</ul>
<p>实际使用情况：</p>
<ul>
<li>strategic merge patch 用的比较少；大多使用 json merge patch 和 json patch</li>
<li>json merge patch 和 json patch 的具体区别可以查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a></li>
<li>json patch 相比于 json merge patch 使用起来复杂一点，但使用方法更灵活，功能更强大，副作用更少。因此更推荐使用。</li>
</ul>
<h2 id="strategic-merge-patch">strategic merge patch</h2>
<p>这是默认的patch类型，strategic merge patch 在进行 patch 操作时，到底是进行<strong>替换</strong>还是进行<strong>合并</strong>，由 Kubernetes 源代码中字段标记中的 <code>patchStrategy</code> 键的值指定。</p>
<p>具体来说：</p>
<ul>
<li>如果你对deployment的 <code>.spec.template.spec.containers</code> 字段进行 strategic merge patch，那么新的 containers 中的字段值会合并到原来的字段中去，因为 <code>PodSpec</code> 结构体的 <code>Containers</code> 字段的 <code>patchStrategy</code> 为 <code>merge</code>。</li>
<li>如果你对deployment的 <code>.spec.template.spec.tolerations</code> 字段进行 strategic merge patch，那么会用新的 tolerations 字段值将老的字段值直接替换。</li>
</ul>
<h2 id="json-merge-patch">json merge patch</h2>
<p><strong>有相同的字段就替换，没有相同的字段就合并</strong>。这在语义上非常容易理解，但是有以下弊端：</p>
<ul>
<li>键值无法被设置为 <code>null</code>，设置为 <code>null</code> 的字段会直接被 json merge patch 删除掉</li>
<li>操作数组非常吃力。如果你想添加或修改数组中的元素，必须在copy原来的数组，并在其基础上进行改动。因为<strong>新的数组会覆盖原来的数组</strong>。</li>
</ul>
<p>特别是第二点，这导致只要是和数组相关的patch操作，最好使用json patch。</p>
<h2 id="json-patch">json patch</h2>
<p>json patch 的格式如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="ln">1</span><span class="p">[</span>
<span class="ln">2</span>    <span class="p">{</span>
<span class="ln">3</span>        <span class="nt">&#34;op&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
<span class="ln">4</span>        <span class="nt">&#34;path&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span> <span class="p">,</span>
<span class="ln">5</span>        <span class="nt">&#34;value&#34;</span> <span class="p">:</span> <span class="s2">&#34;&#34;</span>
<span class="ln">6</span>    <span class="p">}</span>
<span class="ln">7</span><span class="p">]</span>
</code></pre></div><p>即由操作、字段路径、新值组成。具体例子查看<a href="https://erosb.github.io/post/json-patch-vs-merge-patch/">这篇文章</a>。可以看到这种操作方式非常灵活。</p>
<h2 id="json-patch-转义字符">json patch 转义字符</h2>
<ul>
<li>&ldquo;~&quot;（波浪线）对应的是：&quot;~0&rdquo;</li>
<li>&ldquo;/&quot;（斜杠）对应的是：&quot;~1&rdquo;</li>
</ul>
<p>具体可以查看这个<a href="https://github.com/json-patch/json-patch-tests/issues/42">issue</a>中的讨论。</p>
]]></content>
		</item>
		
		<item>
			<title>浅谈kubernetes监控体系</title>
			<link>https://cvvz.github.io/post/k8s-monitor/</link>
			<pubDate>Fri, 20 Nov 2020 00:24:35 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/k8s-monitor/</guid>
			<description>监控和指标 理解监控 我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。 存储使用时序数据库TSDB、前端展示使用grafana、告警</description>
			<content type="html"><![CDATA[<h2 id="监控和指标">监控和指标</h2>
<h3 id="理解监控">理解监控</h3>
<p>我们可以把监控系统划分为：采集指标、存储、展示和告警四个部分。</p>
<p>存储使用时序数据库TSDB、前端展示使用grafana、告警系统也有多种开源实现。我重点介绍一下和指标采集相关的内容。</p>
<h3 id="理解指标">理解指标</h3>
<blockquote>
<p><strong>我们所采集的指标 (metrics)，追根溯源，要么来自于操作系统，要么来自于应用进程自身</strong>。</p>
</blockquote>
<p>在kubernetes中，有三种指标需要被关注，分别来自于：</p>
<ul>
<li>kubernetes基础组件。也就是组成kubernetes的应用进程，如api-server、controller-manager、scheduler、kubelet等。</li>
<li>node节点。也就是组成kubernetes的机器。</li>
<li>Pod/容器。也就是业务进程的<strong>运行环境</strong>。</li>
</ul>
<p>基础设施和kubernetes运维人员主要关注前两项指标，保证kubernetes集群的稳定运行。</p>
<p>而业务方开发/运维主要关注<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics">Pod/容器指标</a>，这和以往关注<a href="https://book.open-falcon.org/zh_0_2/faq/linux-metrics.html">操作系统性能指标</a>大不一样。<strong>在云原生时代，业务进程的运行环境从物理机/虚拟机转变为了Pod/容器。可见，Pod/容器就是云原生时代的<code>不可变基础设施</code></strong>。</p>
<h3 id="采集容器指标的过程">采集容器指标的过程</h3>
<ol>
<li>kubelet内置的cAdvisor负责采集容器指标</li>
<li>kubelet对外暴露出API</li>
<li>Promeheus、Metrics-Server（取代了Heapster）通过这些API采集容器指标</li>
</ol>
<h2 id="prometheus">Prometheus</h2>
<p>Prometheus是Kubernetes监控体系的核心。它的<a href="https://prometheus.io/docs/introduction/overview/#architecture">架构</a>如官网的这幅示意图所示：</p>
<figure>
    <img src="/prometheus.png" width="700px"/> 
</figure>

<p>从左到右就分别是采集指标、存储、展示和告警这四大模块。我还是只介绍采集指标相关的内容。</p>
<h3 id="prometheus是如何采集指标的">Prometheus是如何采集指标的</h3>
<ol>
<li>直接采集。Prometheus提供了各语言的<a href="https://prometheus.io/docs/instrumenting/clientlibs/#client-libraries">lib库</a>，使应用能够对外暴露HTTP端口供prometheus拉取指标值。</li>
<li>间接采集。对于无法通过直接引入lib库或改代码的方式接入Prometheus的应用程序和操作系统，则需要借助<a href="https://prometheus.io/docs/instrumenting/exporters/#third-party-exporters">exporter</a>，代替被监控对象来对 Prometheus 暴露出可以被抓取的 Metrics 信息。</li>
</ol>
<h3 id="prometheus是如何采集kubernetes的指标的">Prometheus是如何采集Kubernetes的指标的</h3>
<ul>
<li>kubernetes基础组件：Prometheus是Kubernetes监控体系的核心，所以这些基础组件当然直接使用lib库采集自己的指标并暴露出API。</li>
<li>node节点：操作系统的性能指标肯定只能借助<a href="https://github.com/prometheus/node_exporter#node-exporter">node exporter</a>来采集了。
<blockquote>
<p><strong>如果node exporter运行在容器里，那么为了让容器里的进程获取到主机上的网络、PID、IPC指标，就需要设置<code>hostNetwork: true</code>、<code>hostPID: true</code>、<code>hostIPC: true</code>，来与主机共用网络、PID、IPC这三个namespace</strong>。</p>
</blockquote>
</li>
<li>Pod/容器。如前所述，Prometheus可以通过kubelet(cAdvisor)暴露出来的API采集指标。</li>
</ul>
<h2 id="kubernetes-hpa">kubernetes HPA</h2>
<p>采集到了性能指标之后，发送发送告警，让运维介入，这只是最初级的运维方式。更高级的方式是让系统自身具备根据指标进行水平弹性伸缩 (HPA) 的能力。</p>
<h3 id="metrics-server">Metrics-Server</h3>
<p>Metrics-server（heapster的替代品）<strong>从kubelet中</strong>获取Pod的监控指标，并通过<a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">apiserver聚合层</a>的方式暴露API，API路径为：<code>/apis/metrics.k8s.io/</code>，也就是说，当你访问这个api路径时，apiserver会帮你转发到Metrics-server里去处理，而不是自己处理。<strong>这样，Kubernetes中的HPA组件就可以通过访问这个API获得指标来进行垂直扩缩容决策了</strong>。</p>
<blockquote>
<p><code>kubectl top</code>命令也是通过这个API获得监控指标的。</p>
</blockquote>
<h3 id="custom-metrics">Custom Metrics</h3>
<p><strong>但是应用程序往往更依赖进程本身的监控指标（如http请求数、消息队列的大小）而不是运行环境的监控指标做决策</strong>。所以只有Metrics-Server暴露出来的API肯定是不够的，因此，Kubernetes提供了另一个API供应用程序暴露自定义监控指标，路径为<code>/apis/custom.metrics.k8s.io/</code>。</p>
<p>Custom Metrics的玩法应该是这样的：</p>
<p><figure>
    <img src="/hpa.drawio.svg" width="600px"/> 
</figure>

如上图所示</p>
<ol>
<li>应用Pod，或者它的exporter暴露出API供Prometheus采集</li>
<li>编写Custom Metrics Server，从Prometheus中获取监控数据</li>
<li>HPA组件通过访问<code>/apis/custom.metrics.k8s.io/</code>进行扩缩容决策。</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>【问题定位】Celery Worker产生僵尸进程</title>
			<link>https://cvvz.github.io/post/celery-worker-zombie/</link>
			<pubDate>Mon, 30 Mar 2020 10:36:36 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/celery-worker-zombie/</guid>
			<description>组内有一个基于Flask + rabbitMQ + Celery搭建的web平台，最近在上面开发需求时碰到了一个比较有趣的问题，在这里记录下来。 问题背景 web平台</description>
			<content type="html"><![CDATA[<blockquote>
<p>组内有一个基于Flask + rabbitMQ + Celery搭建的web平台，最近在上面开发需求时碰到了一个比较有趣的问题，在这里记录下来。</p>
</blockquote>
<h2 id="问题背景">问题背景</h2>
<p>web平台整体架构图如下所示：</p>
<figure>
    <img src="/platform.drawio.svg" width="700px"/> 
</figure>

<p>Flask向rabbitMQ发送任务消息，后者再将任务分发给不同的Celery worker进行处理。由于每一个任务的处理时间较长，为了不阻塞worker处理下一个任务，在worker中，通过两次fork的方式，生成孤儿进程在后台进行任务处理。</p>
<h2 id="问题现象">问题现象</h2>
<ol>
<li>
<p>worker 生成的孤儿进程在抛出异常后，没有自动退出，仍然处于运行状态。</p>
</li>
<li>
<p>kill worker的父进程（SIGTERM），父进程不退出，很多worker变成僵尸进程。（<strong>所有的celery worker都是由同一个父进程fork出来的</strong>）</p>
</li>
</ol>
<h2 id="排查过程">排查过程</h2>
<p>这个问题基本上是通过走读代码定位出来的，下面给出简化后的worker代码便于后面分析。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="ln"> 1</span><span class="k">def</span> <span class="nf">worker</span><span class="p">():</span>
<span class="ln"> 2</span>    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
<span class="ln"> 3</span>        <span class="c1"># 等待任务...</span>
<span class="ln"> 4</span>        <span class="n">wait_task</span><span class="p">()</span>
<span class="ln"> 5</span>
<span class="ln"> 6</span>        <span class="k">try</span><span class="p">:</span>
<span class="ln"> 7</span>            <span class="c1"># 处理任务</span>
<span class="ln"> 8</span>            <span class="n">execute</span><span class="p">()</span>
<span class="ln"> 9</span>        <span class="k">except</span><span class="p">:</span>
<span class="ln">10</span>            <span class="n">on_failure</span><span class="p">()</span>
<span class="ln">11</span>        
<span class="ln">12</span>        <span class="o">...</span>
<span class="ln">13</span>
<span class="ln">14</span>
<span class="ln">15</span><span class="k">def</span> <span class="nf">execute</span><span class="p">():</span>
<span class="ln">16</span>    <span class="k">try</span><span class="p">:</span>
<span class="ln">17</span>        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">18</span>        <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">19</span>            <span class="k">raise</span> <span class="ne">Exception</span>
<span class="ln">20</span>        <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">21</span>            <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">22</span>            <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">23</span>                <span class="k">raise</span> <span class="ne">Exception</span>
<span class="ln">24</span>            <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">25</span>                <span class="c1"># 实际执行任务处理，遇到异常直接raise</span>
<span class="ln">26</span>                <span class="n">do_execute</span><span class="p">()</span>
<span class="ln">27</span>                <span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="ln">28</span>            <span class="k">else</span><span class="p">:</span>
<span class="ln">29</span>                <span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="ln">30</span>        <span class="k">else</span><span class="p">:</span>
<span class="ln">31</span>            <span class="k">return</span>
<span class="ln">32</span>    <span class="k">except</span><span class="p">:</span>
<span class="ln">33</span>        <span class="k">raise</span>
</code></pre></div><h2 id="问题原因">问题原因</h2>
<p>在分析问题原因前，先来运行这样一段代码：</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="ln">1</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="ln">2</span>    <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fork</span><span class="p">()</span>
<span class="ln">3</span>    <span class="k">if</span> <span class="n">pid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">4</span>        <span class="k">print</span> <span class="s2">&#34;fork failed&#34;</span>
<span class="ln">5</span>    <span class="k">elif</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="ln">6</span>        <span class="k">print</span> <span class="s2">&#34;child pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="ln">7</span>    <span class="k">else</span><span class="p">:</span>
<span class="ln">8</span>        <span class="k">print</span> <span class="s2">&#34;parent pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="ln">9</span>    <span class="k">print</span> <span class="s2">&#34;pid &#34;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
</code></pre></div><p>运行结果是：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>parent pid  <span class="m">78216</span>
<span class="ln">2</span>pid  <span class="m">78216</span>
<span class="ln">3</span>child pid  <span class="m">78217</span>
<span class="ln">4</span>pid  <span class="m">78217</span>
</code></pre></div><p>从这个结果我们可以看出，<strong>fork出来的子进程虽然和父进程不共享堆栈（子进程获得父进程堆栈的副本），但是他们共享正文段</strong>，所以他们都执行了程序的最后一行，各自输出了自己的pid。</p>
<p>接着来分析上述worker的代码，在<code>execute()</code>中，通过两次fork，最终使得<code>do_execute()</code>运行在一个孤儿进程中，如果正常运行，最终会执行<code>os._exit(0)</code>正常退出。然而，如果运行过程中抛出异常又会发生什么呢？根据父子进程共享正文段这一结论，我们可以知道这个孤儿进程抛出的异常会被第32行的<code>except</code>捕获到，并继续向上抛出异常，然后会被第9行<code>worker()</code>中的<code>except</code>捕获，并执行<code>on_failure()</code>。<strong>也就是说，这个孤儿进程最终执行到了worker的代码里去了，而worker本身是一个死循环，因此这个孤儿进程就不会退出了。理论上来说，最终它会运行到第4行，成为一个“worker副本”，等待接收任务</strong>。</p>
<p>至于为什么kill worker的父进程会导致worker变僵尸进程，需要深入研究一下celery源码中的信号处理方法。猜测是父进程在退出前，会先保证所有worker子进程已经退出，而它误以为这个“worker副本”也是自己的子进程，但是却没办法通过向子进程发送信号的方式使其退出，于是就阻塞住了自己的退出流程。而其他已经正常退出的worker就会一直处于僵尸状态。</p>
]]></content>
		</item>
		
		<item>
			<title>用树莓派分析函数调用栈</title>
			<link>https://cvvz.github.io/post/call-stack/</link>
			<pubDate>Tue, 03 Sep 2019 18:44:12 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/call-stack/</guid>
			<description>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。 寄存器 分析函数调用栈涉及到的几个特</description>
			<content type="html"><![CDATA[<blockquote>
<p>理解本篇文章需要具备一些GDB、汇编、寄存器的基础知识。可以在阅读的过程中碰到不理解的地方再针对性的学习。</p>
</blockquote>
<h2 id="寄存器">寄存器</h2>
<p>分析函数调用栈涉及到的几个特殊用途的寄存器如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">ARM</th>
<th style="text-align:center">X86</th>
<th style="text-align:center">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">r11（fp）</td>
<td style="text-align:center">rbp（ebp）</td>
<td style="text-align:center">栈帧指针</td>
</tr>
<tr>
<td style="text-align:center">r13（sp）</td>
<td style="text-align:center">rsp（esp）</td>
<td style="text-align:center">栈顶指针</td>
</tr>
<tr>
<td style="text-align:center">r14（lr）</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center">返回地址</td>
</tr>
<tr>
<td style="text-align:center">r15（pc）</td>
<td style="text-align:center">rip</td>
<td style="text-align:center">指令指针（程序计数器）</td>
</tr>
</tbody>
</table>
<h2 id="函数调用栈">函数调用栈</h2>
<p>如下图（《程序员的自我修养》图10-4）所示：</p>
<figure>
    <img src="/%e6%a0%88.jpg" width="500px"/> 
</figure>

<p>图中，栈帧指针（ebp）指向的内存空间中保存的是上一个栈的栈帧指针（old ebp）。这是X86的情形，在树莓派中分析函数调用栈时发现，ARM的栈帧指针（fp）指向的是函数返回地址。</p>
<p>这只是不同架构CPU的底层实现的不同，并没有优劣之分。</p>
<h3 id="入栈过程">入栈过程</h3>
<p>一个函数的调用过程可以分为如下几步：</p>
<ul>
<li>首先压栈的是参数，且<strong>从右向左</strong>依次压栈；</li>
<li>接着压入返回地址；</li>
<li>接着被调函数执行“标准开头”（x86）：</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>push rbp
<span class="ln">2</span>mov rbp rsp
</code></pre></div><p>“标准开头”执行过程如下：</p>
<ul>
<li>首先rbp入栈；</li>
<li>rbp入栈后，rsp自动加8（64位），rsp此时指向存放rbp的栈帧地址；</li>
<li>接着令<code>%rbp=%rsp</code>，这就使得rbp指向存放着上一个栈的rbp的内存地址。</li>
</ul>
<p>而ARM（32位）的“标准开头”长这样：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>push {fp, lr}
<span class="ln">2</span>add fp, sp, #4
</code></pre></div><ul>
<li>返回地址(lr)入栈</li>
<li>栈帧指针(fp)入栈</li>
<li>接着令<code>%fp=%sp+4</code>，也就是<strong>使fp（栈帧指针）指向存放返回地址的内存</strong>。</li>
</ul>
<p>不论栈帧指针指向的是上一个栈帧指针，还是返回地址，都能<strong>通过函数的栈帧指针偏移找到调用函数的地址，因此根据栈帧指针的链式关系，可以回溯出整个函数的调用关系链</strong>。这对于一些复杂问题的定位是非常有帮助的。</p>
<blockquote>
<p>GCC的编译选项<code>--fomit-frame-pointer</code>可以使程序不使用栈帧指针，而使用栈指针顶定位函数的局部变量、参数、返回地址等。这么做的好处是可以多出一个寄存器（栈帧指针）供使用，程序运行速度更快，但是就没发很方便的使用GDB进行调试了。</p>
</blockquote>
<h3 id="出栈过程">出栈过程</h3>
<p>出栈与入栈动作刚好相反。</p>
<p>x86的“标准结尾”如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>leaveq
<span class="ln">2</span>retq
</code></pre></div><p>实际上<code>leaveq</code>内部分为两条指令：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>movq %rbp, %rsp
<span class="ln">2</span>popq %rbp
</code></pre></div><p>所以，出栈过程可以分解为如下三步：</p>
<ul>
<li>第一步是通过将rbp地址赋给rsp，即此时rsp指向的内存存放的是上一个栈的rbp。</li>
<li>第二步弹出栈顶的数据到rbp中，即rbp指向上一个栈的栈底，出栈动作导致rsp自增，于是rsp此时指向的内存中存放函数返回地址；</li>
<li>第三步通过<code>retq</code>指令将栈顶地址pop到rip，即rip此时指向函数退出后的下一条指令，rsp则指向上一个栈的栈顶。</li>
</ul>
<p>这三步做完后，rsp、rbp、rip就恢复到调用函数以前的现场。</p>
<p>ARM的行为和x86一致，它的“标准结尾”长这样：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>sub sp, fp, #4
<span class="ln">2</span>pop {fp, pc}
</code></pre></div><h2 id="基于树莓派3分析函数调用栈">基于树莓派3分析函数调用栈</h2>
<p>我在树莓派3中运行了如下所示的C语言代码，并用GDB进行了调试：</p>
<blockquote>
<p>树莓派3使用的是<strong>32位、arm架构CPU</strong>，因此下面的调试过程涉及到的寄存器以及地址信息和64位x86 CPU不同</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="ln"> 1</span><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="ln"> 2</span><span class="cp"></span>
<span class="ln"> 3</span><span class="kt">void</span> <span class="nf">test2</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="p">)</span>
<span class="ln"> 4</span><span class="p">{</span>
<span class="ln"> 5</span>    <span class="kt">int</span> <span class="n">ii</span><span class="p">;</span>
<span class="ln"> 6</span>    <span class="n">ii</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
<span class="ln"> 7</span><span class="p">}</span>
<span class="ln"> 8</span>
<span class="ln"> 9</span><span class="kt">char</span> <span class="nf">test</span><span class="p">(</span><span class="kt">char</span> <span class="n">c</span><span class="p">)</span>
<span class="ln">10</span><span class="p">{</span>
<span class="ln">11</span>    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
<span class="ln">12</span>    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;%c&#34;</span><span class="p">,</span><span class="n">c</span><span class="p">);</span>
<span class="ln">13</span>    <span class="n">test2</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="ln">14</span>    <span class="k">return</span> <span class="n">c</span><span class="p">;</span>
<span class="ln">15</span><span class="p">}</span>
<span class="ln">16</span>
<span class="ln">17</span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="ln">18</span><span class="p">{</span>
<span class="ln">19</span>    <span class="kt">char</span> <span class="n">c</span> <span class="o">=</span> <span class="sc">&#39;a&#39;</span><span class="p">;</span>
<span class="ln">20</span>    <span class="kt">char</span> <span class="n">ret</span><span class="p">;</span>
<span class="ln">21</span>    <span class="n">ret</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
<span class="ln">22</span>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="ln">23</span><span class="p">}</span>
</code></pre></div><h3 id="分析函数调用入栈过程">分析函数调用（入栈）过程</h3>
<p>使用GDB进行调试，将断点打在main函数调用test之前，并使用<code>disassemble</code>查看反汇编结果：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) b *0x000104bc
<span class="ln"> 2</span>Breakpoint 2 at 0x104bc: file main.c, line 21.
<span class="ln"> 3</span>(gdb) disassemble /m main
<span class="ln"> 4</span>Dump of assembler code for function main:
<span class="ln"> 5</span>18 {
<span class="ln"> 6</span>   0x000104a0 &lt;+0&gt;: push {r11, lr}
<span class="ln"> 7</span>   0x000104a4 &lt;+4&gt;: add r11, sp, #4
<span class="ln"> 8</span>   0x000104a8 &lt;+8&gt;: sub sp, sp, #8
<span class="ln"> 9</span>
<span class="ln">10</span>19 char c = &#39;a&#39;;
<span class="ln">11</span>   0x000104ac &lt;+12&gt;: mov r3, #97 ; 0x61
<span class="ln">12</span>   0x000104b0 &lt;+16&gt;: strb r3, [r11, #-5]
<span class="ln">13</span>
<span class="ln">14</span>20 char ret;
<span class="ln">15</span>21 ret = test(c);
<span class="ln">16</span>   0x000104b4 &lt;+20&gt;: ldrb r3, [r11, #-5]
<span class="ln">17</span>   0x000104b8 &lt;+24&gt;: mov r0, r3
<span class="ln">18</span>=&gt; 0x000104bc &lt;+28&gt;: bl 0x10468 &lt;test&gt;
<span class="ln">19</span>   0x000104c0 &lt;+32&gt;: mov r3, r0
<span class="ln">20</span>   0x000104c4 &lt;+36&gt;: strb r3, [r11, #-6]
<span class="ln">21</span>
<span class="ln">22</span>22 return 0;
<span class="ln">23</span>   0x000104c8 &lt;+40&gt;: mov r3, #0
<span class="ln">24</span>
<span class="ln">25</span>23 }
<span class="ln">26</span>   0x000104cc &lt;+44&gt;: mov r0, r3
<span class="ln">27</span>   0x000104d0 &lt;+48&gt;: sub sp, r11, #4
<span class="ln">28</span>   0x000104d4 &lt;+52&gt;: pop {r11, pc}
<span class="ln">29</span>
<span class="ln">30</span>End of assembler dump.
</code></pre></div><p>查看此时栈帧指针和栈顶指针的值：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) i r r11 sp
<span class="ln">2</span>r11            0x7efffaec 2130705132
<span class="ln">3</span>sp             0x7efffae0 0x7efffae0
<span class="ln">4</span>(gdb) x /xw 0x7efffaec
<span class="ln">5</span>0x7efffaec: 0x76e8f678
<span class="ln">6</span>(gdb) info symbol 0x76e8f678
<span class="ln">7</span>__libc_start_main + 276 in section .text of /lib/arm-linux-gnueabihf/libc.so.6
</code></pre></div><p>可以看到，栈帧指针指向的返回地址是<code>__libc_start_main + 276</code>，即<strong>main函数是由__libc_start_main调用的</strong>。</p>
<p>由前面分析得知，栈帧指针-4地址处存放的是上一个函数的栈帧指针，于是我们继续向上追溯<code>__libc_start_main</code>的调用者地址，可以发现其值为0：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) x /xw 0x7efffaec-4
<span class="ln">2</span>0x7efffae8: 0x00000000
</code></pre></div><p><strong>因此可以认为<code>__libc_start_main</code>是所有进程真正的起点。</strong></p>
<p>接着执行调用test函数的命令，使用<code>si</code>单步运行，并查看汇编指令：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) si
<span class="ln"> 2</span>test (c=0 &#39;\000&#39;) at main.c:10
<span class="ln"> 3</span>10 {
<span class="ln"> 4</span>(gdb) disassemble
<span class="ln"> 5</span>Dump of assembler code for function test:
<span class="ln"> 6</span>=&gt; 0x00010468 &lt;+0&gt;: push {r11, lr}
<span class="ln"> 7</span>   0x0001046c &lt;+4&gt;: add r11, sp, #4
<span class="ln"> 8</span>   0x00010470 &lt;+8&gt;: sub sp, sp, #16
<span class="ln"> 9</span>   0x00010474 &lt;+12&gt;: mov r3, r0
<span class="ln">10</span>   0x00010478 &lt;+16&gt;: strb r3, [r11, #-13]
<span class="ln">11</span>   0x0001047c &lt;+20&gt;: ldrb r3, [r11, #-13]
<span class="ln">12</span>   0x00010480 &lt;+24&gt;: mov r0, r3
<span class="ln">13</span>   0x00010484 &lt;+28&gt;: bl 0x10300 &lt;putchar@plt&gt;
<span class="ln">14</span>   0x00010488 &lt;+32&gt;: ldr r0, [r11, #-8]
<span class="ln">15</span>   0x0001048c &lt;+36&gt;: bl 0x10440 &lt;test2&gt;
<span class="ln">16</span>   0x00010490 &lt;+40&gt;: ldrb r3, [r11, #-13]
<span class="ln">17</span>   0x00010494 &lt;+44&gt;: mov r0, r3
<span class="ln">18</span>   0x00010498 &lt;+48&gt;: sub sp, r11, #4
<span class="ln">19</span>   0x0001049c &lt;+52&gt;: pop {r11, pc}
<span class="ln">20</span>End of assembler dump.
<span class="ln">21</span>(gdb) i r $lr
<span class="ln">22</span>lr             0x104c0 66752
<span class="ln">23</span>(gdb) info symbol $lr
<span class="ln">24</span>main + 32 in section .text of /root/main
</code></pre></div><p>可以看到此时lr寄存器中保存的指令即调用test后的下一条指令。继续向下执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) ni
<span class="ln">2</span>0x0001046c 10 {
<span class="ln">3</span>(gdb) i r r11 sp
<span class="ln">4</span>r11            0x7efffaec 2130705132
<span class="ln">5</span>sp             0x7efffad8 0x7efffad8
</code></pre></div><p>观察到将r11和lr入栈后，sp减少了8字节，不难猜测，高4字节存放了lr的值（返回地址），低4字节存放了sp的值（上一个栈的栈帧指针）：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) x /xw 0x7efffad8
<span class="ln">2</span>0x7efffad8: 0x7efffaec
<span class="ln">3</span>(gdb) x /xw 0x7efffadc
<span class="ln">4</span>0x7efffadc: 0x000104c0
<span class="ln">5</span>(gdb) i r $lr $r11
<span class="ln">6</span>lr             0x104c0 66752
<span class="ln">7</span>r11            0x7efffaec 2130705132
</code></pre></div><p>继续执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>(gdb) ni
<span class="ln">2</span>0x00010470 10 {
<span class="ln">3</span>(gdb) i r $r11
<span class="ln">4</span>r11            0x7efffadc 2130705116
</code></pre></div><p>此时r11指向的是函数返回地址，而不是像x86一样指向上一个栈帧指针，和前面所说的一致。</p>
<h2 id="分析函数返回出栈过程">分析函数返回（出栈）过程</h2>
<p>test函数的汇编指令如下所示：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) disassemble /m test
<span class="ln"> 2</span>Dump of assembler code for function test:
<span class="ln"> 3</span>10 {
<span class="ln"> 4</span>   0x00010468 &lt;+0&gt;:	push	{r11, lr}
<span class="ln"> 5</span>   0x0001046c &lt;+4&gt;:	add	r11, sp, #4
<span class="ln"> 6</span>   0x00010470 &lt;+8&gt;:	sub	sp, sp, #16
<span class="ln"> 7</span>   0x00010474 &lt;+12&gt;:	mov	r3, r0
<span class="ln"> 8</span>   0x00010478 &lt;+16&gt;:	strb	r3, [r11, #-13]
<span class="ln"> 9</span>
<span class="ln">10</span>11		int i;
<span class="ln">11</span>12		printf(&#34;%c&#34;,c);
<span class="ln">12</span>   0x0001047c &lt;+20&gt;:	ldrb	r3, [r11, #-13]
<span class="ln">13</span>   0x00010480 &lt;+24&gt;:	mov	r0, r3
<span class="ln">14</span>   0x00010484 &lt;+28&gt;:	bl	0x10300 &lt;putchar@plt&gt;
<span class="ln">15</span>
<span class="ln">16</span>13		test2(i);
<span class="ln">17</span>   0x00010488 &lt;+32&gt;:	ldr	r0, [r11, #-8]
<span class="ln">18</span>   0x0001048c &lt;+36&gt;:	bl	0x10440 &lt;test2&gt;
<span class="ln">19</span>
<span class="ln">20</span>14		return c;
<span class="ln">21</span>   0x00010490 &lt;+40&gt;:	ldrb	r3, [r11, #-13]
<span class="ln">22</span>
<span class="ln">23</span>15	}
<span class="ln">24</span>   0x00010494 &lt;+44&gt;:	mov	r0, r3
<span class="ln">25</span>=&gt; 0x00010498 &lt;+48&gt;:	sub	sp, r11, #4
<span class="ln">26</span>   0x0001049c &lt;+52&gt;:	pop	{r11, pc}
<span class="ln">27</span>
<span class="ln">28</span>End of assembler dump.
</code></pre></div><p>函数运行完毕进入出栈流程的执行过程分为如下几步：</p>
<ul>
<li>首先通过 <code>sub sp, r11, #4</code> 将栈顶指针指向上一个栈帧指针</li>
<li>接着通过 <code>pop {r11, pc}</code> 将上一个栈帧指针赋值给r11，并将返回地址赋值给pc</li>
<li>两次pop后，栈顶指针自动往栈底方向退两次</li>
</ul>
<p>最终，栈顶指针（sp）、栈帧指针（r11）和指令指针（pc）都还原成了main函数调用test前的样子，用GDB查看寄存器内容证实了这一点：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>(gdb) disassemble 
<span class="ln"> 2</span>Dump of assembler code for function main:
<span class="ln"> 3</span>   0x000104a0 &lt;+0&gt;:	push	{r11, lr}
<span class="ln"> 4</span>   0x000104a4 &lt;+4&gt;:	add	r11, sp, #4
<span class="ln"> 5</span>   0x000104a8 &lt;+8&gt;:	sub	sp, sp, #8
<span class="ln"> 6</span>   0x000104ac &lt;+12&gt;:	mov	r3, #97	; 0x61
<span class="ln"> 7</span>   0x000104b0 &lt;+16&gt;:	strb	r3, [r11, #-5]
<span class="ln"> 8</span>   0x000104b4 &lt;+20&gt;:	ldrb	r3, [r11, #-5]
<span class="ln"> 9</span>   0x000104b8 &lt;+24&gt;:	mov	r0, r3
<span class="ln">10</span>   0x000104bc &lt;+28&gt;:	bl	0x10468 &lt;test&gt;
<span class="ln">11</span>=&gt; 0x000104c0 &lt;+32&gt;:	mov	r3, r0
<span class="ln">12</span>   0x000104c4 &lt;+36&gt;:	strb	r3, [r11, #-6]
<span class="ln">13</span>   0x000104c8 &lt;+40&gt;:	mov	r3, #0
<span class="ln">14</span>   0x000104cc &lt;+44&gt;:	mov	r0, r3
<span class="ln">15</span>   0x000104d0 &lt;+48&gt;:	sub	sp, r11, #4
<span class="ln">16</span>   0x000104d4 &lt;+52&gt;:	pop	{r11, pc}
<span class="ln">17</span>End of assembler dump.
<span class="ln">18</span>(gdb) i r r11 sp pc
<span class="ln">19</span>r11            0x7efffaec	2130705132
<span class="ln">20</span>sp             0x7efffae0	0x7efffae0
<span class="ln">21</span>pc             0x104c0	0x104c0 &lt;main+32&gt;
</code></pre></div>]]></content>
		</item>
		
		<item>
			<title>安全知识总结</title>
			<link>https://cvvz.github.io/post/about-computer-security/</link>
			<pubDate>Thu, 22 Aug 2019 12:38:04 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/about-computer-security/</guid>
			<description>加解密算法 对称加密： 用同一个秘钥进行加密和解密，代表算法有AES/DES/RC2/RC5等； 非对称加密： 一次产生公钥和私钥两个秘钥，任意一个</description>
			<content type="html"><![CDATA[<h2 id="加解密算法">加解密算法</h2>
<p><strong>对称加密：</strong> 用同一个秘钥进行加密和解密，代表算法有<code>AES/DES/RC2/RC5</code>等；</p>
<p><strong>非对称加密：</strong> 一次产生公钥和私钥两个秘钥，任意一个都能进行加密，解密则需要用另外一个。具体的用法是：公钥用来“加密”（相应的私钥用来解密），私钥用来“签名”（相应的公钥用来校验）。代表算法有<code>RSA/DSA/ECC/DH</code>等。</p>
<p><strong>摘要：</strong> 摘要是对数据计算Hash值，Hash值不可逆，是一种单向加密。<code>shadow</code>文件中保存的用户密码就是密码明文的Hash值。代表算法有<code>MD5/SHA256</code>等。</p>
<h2 id="ssl协议">SSL协议</h2>
<p>SSL协议工作在传输层和应用层之间。在TCP协议的三次握手之后，进行SSL协议的握手。</p>
<p>SSL握手过程：</p>
<ul>
<li>客户端发送随机数x和自己支持的加密算法</li>
<li>服务端发送随机数y、公钥和选择的加密算法</li>
<li>客户端发送通过公钥加密的随机数z的密文</li>
<li>客户端、服务端用xyz算出对称加密的密钥</li>
<li>双方进行对称加密通信。</li>
</ul>
<h2 id="ssh协议">SSH协议</h2>
<h3 id="密码登录">密码登录</h3>
<ul>
<li>主机将自己的公钥（主机密钥HostKey）发到客户端（HostKey路径在sshd的配置文件中配置）</li>
<li>客户端计算公钥指纹（摘要），询问用户是否信任该kostkey，信任则将key值记录在known_hosts中，下次登录相同服务器时若hostkey相同不必再次确认；否则提示hostkey不一致</li>
<li>用户输入密码，客户端使用公钥加密密码明文并发送到服务端，服务端使用私钥解密并进行密码校验。</li>
</ul>
<p>由于存在发送服务器公钥的过程，因此存在中间人攻击的安全隐患。</p>
<h3 id="公钥登录">公钥登录</h3>
<p>SSH公钥登录解决了SSH协议中的中间人攻击的问题。</p>
<ul>
<li>用户事先生成一对公/私钥，将公钥提前导入到服务器，</li>
<li>登录时，服务器首先发送一个随机数到客户端，</li>
<li>客户端使用私钥加密随机数返回服务端，</li>
<li>服务端使用公钥校验通过则允许登录。</li>
</ul>
<h2 id="中间人攻击">中间人攻击</h2>
<p>SSL协议以及SSH密码登录方式，都存在着中间人攻击的威胁，主要安全隐患在于握手过程中服务端发送的公钥可能被中间人截取，客户端不能确定服务端发送的公钥是否可信。</p>
<h2 id="证书">证书</h2>
<p>证书解了服务端公钥不可信的问题。</p>
<p>证书中记录了服务器的公钥信息，服务器不直接发送公钥，而是发送从CA中心申请到的证书。CA中心把公钥及其他证书信息一起进行摘要计算，再对其进行签名，最终的证书中存放的是公钥、证书信息、数字签名。</p>
<p>因为有了CA中心的数字签名，只要用相应的CA中心的公钥对签名进行校验（即比较解密后的摘要值和本地计算的摘要值是否相同）通过，就能安全使用公钥进行加密。</p>
<p>CA中心的公钥一般预置在操作系统中的根CA证书中。既然CA中心的公钥是用来对签名进行校验的，那么相应的，这个根CA证书就是用来对服务器发来的证书进行校验的。</p>
<h2 id="证书链">证书链</h2>
<p>一般我们不会直接拿根CA证书对应的私钥去做证书的签发，因为频繁使用根证书对应的私钥会增加其泄露的可能性。</p>
<p>安全的做法是：CA中心给二级CA中心签发一个证书（即二级CA证书，二级CA中心严格保存其对应的私钥），二级CA中心再给三级CA中心签发证书&hellip;依次类推。</p>
<p>因此，服务提供者去N级CA中心签发证书时，生成的不再是证书，而是<code>证书链</code>，证书链中依次记录着服务器证书、N级CA证书、N-1级CA证书&hellip;二级CA证书。证书校验时，用根CA证书校验二级CA证书、二级CA证书校验三级CA证书&hellip;最后N级校验服务器证书，只有全部校验通过，服务器证书才算被客户端校验通过。</p>
<h2 id="浏览器通过https协议访问网站的过程">浏览器通过HTTPS协议访问网站的过程</h2>
<ol>
<li>通过本地的DNS配置文件找到DNS服务器地址。</li>
<li>DNS服务器将网址解析为ip地址返回。</li>
<li>本机通过链路层的arp协议找到局域网的路由器。（二层）</li>
<li>路由器通过ip地址路由寻址找到ip地址对应的主机。（三层）</li>
<li>主机通过TCP协议找到本机的端口号（进程listen）。（四层）</li>
<li>TCP三次握手。</li>
<li><strong>使用证书</strong>进行SSL握手（主机将自己的证书链发到浏览器，浏览器使用操作系统预置CA证书进行校验，校验不通过会提示链接不安全的风险）。（SSL层）</li>
<li>服务器进程和浏览器进程在应用层使用HTTP协议交换数据。（七层）</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>抓包解读smtp和tls协议</title>
			<link>https://cvvz.github.io/post/smtp-with-tls/</link>
			<pubDate>Sat, 22 Jun 2019 23:21:54 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/smtp-with-tls/</guid>
			<description>背景：某进程调用 libcurl 提供的 curl_easy_perform 接口与邮箱服务器进行smtp通信时，服务端返回56(CURLE_RECV_ERROR)错误。由于服务端日志信息不足</description>
			<content type="html"><![CDATA[<blockquote>
<p>背景：某进程调用 <code>libcurl</code> 提供的 <code>curl_easy_perform</code> 接口与邮箱服务器进行smtp通信时，服务端返回56(<code>CURLE_RECV_ERROR</code>)错误。由于服务端日志信息不足，于是想到可以通过抓包查看建立smtp连接时的错误信息。</p>
</blockquote>
<h3 id="第一次抓包">第一次抓包</h3>
<figure>
    <img src="/smtp-with-tls.png" width="1050px"/> 
</figure>

<p>从图中可以清晰看出整个SMTP连接从建立到断开的全过程：</p>
<ol>
<li>通过三次握手建立TCP连接</li>
<li>客户端向服务端发送 <code>STARTTLS</code>，服务端回复 <code>220 Ready to start TLS</code>后，SMTP协议准备建立安全信道</li>
<li><a href="https://cvvz.github.io/post/about-computer-security/#ssl%E5%8D%8F%E8%AE%AE">TLS协议握手</a>建立连接</li>
<li>TLS协议建立连接后，<strong>应用层协议的内容就被加密了，抓包只能看到图中的<code>Application Data</code>字样</strong>。</li>
<li>通过TCP四次挥手断开连接</li>
</ol>
<blockquote>
<p>由于smtp协议内容被加密了，因此需要先去掉TLS连接，再抓包分析。</p>
</blockquote>
<h3 id="第二次抓包">第二次抓包</h3>
<figure>
    <img src="/smtp-without-tls.png" width="1050px"/> 
</figure>

<p>从第二次抓包得到的信息，可以看出连接断开的根因是smtp服务器返回了<code>502 VRFY disallowed</code>。</p>
<p>接下来网上搜索<code>smtp VRFY disallowed</code>相关内容就能找到答案了：原来<code>libcurl</code>从7.34.0版本开始，要求SMTP客户端显式的设置 <code>CURLOPT_UPLOAD</code> 选项，否则libcurl将发送<code>VRFY</code>命令。而一般服务器出于安全性的考虑，会禁止执行VRFY命令。（参考<a href="https://issues.dlang.org/show_bug.cgi?id=13042">https://issues.dlang.org/show_bug.cgi?id=13042</a> ）</p>
<blockquote>
<p>通过抓包还证实了，不进行加密通信的应用层数据是明文传输的，smtp协议中的用户名密码被一览无余。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>【问题定位】异步回调函数造成踩内存</title>
			<link>https://cvvz.github.io/post/coredump/</link>
			<pubDate>Thu, 13 Jun 2019 03:54:36 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/coredump/</guid>
			<description>问题现象 进程概率性coredump 分析过程 分析core文件，堆栈栈顶函数为strncmp，coredump的原因是给strncmp传递的字符</description>
			<content type="html"><![CDATA[<h2 id="问题现象">问题现象</h2>
<p>进程概率性coredump</p>
<h2 id="分析过程">分析过程</h2>
<ol>
<li>分析core文件，堆栈栈顶函数为<code>strncmp</code>，coredump的原因是给strncmp传递的字符串指针（char*）为<code>0x01</code>，访问非法内存地址。</li>
<li>找到该字符串指针原始定义处，是某函数中的局部变量，内存地址正常。</li>
<li>该字符串生命周期内没有被改写过，但是在某一时刻突变为了<code>0x01</code>。</li>
<li>因此最大可能性是其所在的栈空间内存被其他线程踩到了。</li>
<li>通过两个手段来排查这个问题：
<ol>
<li>重点关注被踩的内存空间之前被哪些函数使用过。</li>
<li>一一排查core文件中的所有执行线程，重点关注可能引起踩内存的函数。</li>
</ol>
</li>
</ol>
<h2 id="原因解析">原因解析</h2>
<p>这个字符串的内存空间曾经被用作某个函数的局部变量，而这个函数中有一段逻辑是循环调用一个异步查询接口，并给这个异步查询接口提供一个回调函数，而这个回调函数的作用就是去修改这个局部变量。</p>
<p>问题发生的原因是这个异步回调接口返回的太慢，调用方函数已经运行完毕，此时栈空间已经被操作系统回收并分配给其他函数，这时再执行回调函数修改原先的局部变量，就造成了踩内存。</p>
<p>这里原先的局部变量是个<code>int</code>类型，回调函数想将其修改为1，结果就成了将一个<code>char*</code>类型的变量值修改为了<code>0x01</code>。</p>
]]></content>
		</item>
		
		<item>
			<title>gdb中的多线程和信号处理</title>
			<link>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</link>
			<pubDate>Mon, 10 Jun 2019 11:44:52 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/gdb-muti-process-and-signal-handle/</guid>
			<description>多线程调试 使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。 All-Stop 任何一个线程在断点处hang住时，所有其他线</description>
			<content type="html"><![CDATA[<h2 id="多线程调试">多线程调试</h2>
<p>使用GDB调试多线程时，控制程序的执行模式主要分两种：all-stop 模式和 non-stop 模式。</p>
<h3 id="all-stop">All-Stop</h3>
<blockquote>
<p>任何一个线程在断点处hang住时，所有其他线程也会hang住。默认为all-stop模式。</p>
</blockquote>
<ol>
<li>
<p>在all-stop模式中，当一个线程到达断点或产生信号，GDB将自动选择该线程作为当前线程并停住（提示<code>Switching to Thread n</code>），并且其他线程也都会停止运行；</p>
</li>
<li>
<p>当执行<code>continue</code>、<code>until</code>、<code>finish</code>、<code>next</code>、<code>step</code>等使线程继续运行，所有线程会同时继续运行，直到某一个线程再次被stop，然后该线程成为当前线程。</p>
</li>
<li>
<p>这里还存在这样一种情况：当你单步跟踪某个线程时，这个线程一定是执行了某条完整语句后在下一条语句前停住，<strong>但是这段时间里其他线程可能执行了半条、一条或多条语句</strong>。</p>
</li>
<li>
<p>在all-stop模式下，可以通过设定<code>scheduler-locking</code>（调度器锁定）来控制CPU调度器的行为从而控制多线程的并发运行行为。</p>
<ul>
<li><code>set scheduler-locking off</code>：默认调度器锁定为关，也就是CPU也可以进行自由调度，那么所有线程是“同进同止”的，一起stop，一起继续运行，竞争CPU资源；</li>
<li><code>set scheduler-locking on</code>：开启调度器锁定，不允许CPU自由调度，CPU只能执行当前线程中的指令，其他线程一直处于stop状态；</li>
</ul>
</li>
</ol>
<h3 id="non-stop">Non-Stop</h3>
<blockquote>
<p>任何一个线程被stop甚至单步调试时，其他线程可以自由运行。</p>
</blockquote>
<ol>
<li>通过<code>set non-stop on</code>手动开启non-stop模式。一般non-stop模式搭配异步执行命令使用。</li>
<li>GDB的可执行命令分为两种：同步执行和异步执行。
<ul>
<li>同步执行：即执行一条命令后，要等待有线程被stop了才会在弹出命令提示符。这是默认执行模式。</li>
<li>异步执行：立刻返回弹出命令提示符。打开命令异步执行模式开关的命令是<code>set target-async on</code>。</li>
</ul>
<blockquote>
<p>在命令后跟<code>&amp;</code>表示该命令以异步的方式执行，如<code>attach&amp;</code>、<code>continue&amp;</code>等。</p>
</blockquote>
</li>
<li>non-stop模式下可使用<code>interrupt</code>停止当前运行中的线程，<code>interrupt -a</code>停下所有线程。</li>
</ol>
<h2 id="信号处理">信号处理</h2>
<p>GDB能够检测到程序中产生的信号，并进行针对性的处理。通过<code>info handle</code>查看对所有信号的处理方式：</p>
<ul>
<li>Stop：检测到信号是否停住程序的运行；</li>
<li>Print：是否打印收到该信号的信息；</li>
<li>Pass to program：是否把该信号传给进程处理（或者说是否屏蔽该信号，无法屏蔽<code>SIGKILL</code>和<code>SIGSTOP</code>信号）</li>
</ul>
<p>通过<code>handle SIG</code>来指定某个信号的处理方式。</p>
]]></content>
		</item>
		
		<item>
			<title>解剖进程虚拟内存空间</title>
			<link>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</link>
			<pubDate>Fri, 07 Jun 2019 23:14:03 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/anatomy-of-a-program-in-memory/</guid>
			<description>对于32位 x86 Linux操作系统，典型的进程地址空间如下图所示： 每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFF</description>
			<content type="html"><![CDATA[<p>对于<strong>32位 x86 Linux操作系统</strong>，典型的进程地址空间如下图所示：</p>
<figure>
    <img src="/linuxFlexibleAddressSpaceLayout.png" width="750px"/> 
</figure>

<p>每一个进程运行在各自独立的虚拟内存空间中，从0x00000000到0xFFFFFFFF，共4GB。</p>
<p>进程地址空间从低到高依次是：</p>
<ul>
<li><strong>Text Segment：</strong> 机器指令，只读，一个程序的多个进程共享一个正文段。</li>
</ul>
<blockquote>
<p>如果进程带有调试信息，可以通过<code>addr2line</code> + 正文段地址获得对应的源代码位置。</p>
</blockquote>
<ul>
<li>
<p><strong>Data Segment：</strong> 具有初值的全局/静态变量。</p>
</li>
<li>
<p><strong>BSS Segment：</strong> 未赋初值的全局/静态变量。</p>
</li>
<li>
<p><strong>Heap：</strong> 堆。堆从低地址向高地址生长。堆区内存在分配过程中可能产生内存碎片：</p>
</li>
</ul>
<p><img src="/fragmentedHeap.png" alt="内存碎片" title="内存碎片"></p>
<blockquote>
<p>申请堆内存的接口是阻塞接口，即可能因为暂时分配不到够大的堆空间导致进程让出CPU。</p>
</blockquote>
<ul>
<li>
<p><strong>Memory Mapping Segment：</strong> 内存映射区。动态库、mmap、共享内存使用的都是内存映射区。</p>
</li>
<li>
<p><strong>Stack：</strong> 栈。栈从高地址向低地址生长。进程栈空间的总大小可通过
<code>ulimit -s</code>查看，默认为8MB。栈中不仅存放着局部变量，<strong>每次函数调用时，参数、返回地址、寄存器值等都会进行压栈。</strong></p>
</li>
<li>
<p><strong>Kernel space：</strong> 进程地址空间的最高1GB是内核空间。<strong>内核空间被所有进程共享</strong>，但是用户态进程只有通过系统调用陷入内核态才能执行内核态代码。</p>
</li>
</ul>
<blockquote>
<p>参考文章：<a href="https://manybutfinite.com/post/anatomy-of-a-program-in-memory/">https://manybutfinite.com/post/anatomy-of-a-program-in-memory/</a></p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>system系统调用探秘</title>
			<link>https://cvvz.github.io/post/system-and-shell/</link>
			<pubDate>Thu, 30 May 2019 00:28:40 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/system-and-shell/</guid>
			<description>6月3日更新 新的实验又发现使用/bin/sh和书中行为一致，但使用/bin/bash的行为和本文中的实验一致，看来是不同shell的底层的实</description>
			<content type="html"><![CDATA[<blockquote>
<p><strong>6月3日更新</strong></p>
<p>新的实验又发现使用<code>/bin/sh</code>和书中行为一致，但使用<code>/bin/bash</code>的行为和本文中的实验一致，看来是不同shell的底层的实现方式有差异。<strong>而之所以之前用<code>/bin/sh</code>做的实验和书中行为不一致，是因为在我做实验的机器上，<code>/bin/sh</code>其实是一个指向<code>/bin/bash</code>的软链接</strong>。。。</p>
<p>不过至少得到一个重要结论，那就是：<strong>对于不同的底层shell，system系统调用的表现会不同</strong>。这一点在编码时需要特别注意。</p>
</blockquote>
<h2 id="system实现原理">system实现原理</h2>
<p><code>system</code>这个系统调用的源码在网上已经有很多了，这里就不展示了。简单来说，就是父进程<code>fork</code>后，在子进程中通过执行<code>execl(&quot;/bin/sh&quot;, &quot;sh&quot;, &quot;-c&quot;, cmdstring, (char *)0)</code>，使得<code>/bin/sh</code>成为新的子进程，然后在<code>/bin/sh</code>中执行<code>cmdstring</code>命令；父进程循环执行<code>waitpid</code>，等待子进程退出的信号。</p>
<h2 id="到底有几个子进程">到底有几个子进程？</h2>
<h3 id="实验一">实验一</h3>
<p>在学习《UNIX环境高级编程（第3版）》信号一章时，根据图10-27所示，执行 <code>system(&quot;/bin/ed&quot;)</code> 命令后，会分别调用<code>fork</code>/<code>exec</code>系统调用两次：</p>
<ol>
<li>第一次发生在调用<code>system</code>时，父进程<code>fork</code>一次，子进程执行<code>execl(&quot;/bin/sh&quot;,&quot;sh&quot;,&quot;-c&quot;,&quot;/bin/ed&quot;,(char *)0)</code>一次，子进程被替换为<code>/bin/sh</code>。</li>
<li>第二次发生在<code>/bin/sh</code>这个子进程中，<code>/bin/sh</code>会先<code>fork</code>一个子进程，这个子进程执行<code>exec(&quot;/bin/ed&quot;)</code>，用<code>/bin/ed</code>替换<code>/bin/sh</code>。</li>
</ol>
<p>但是我在自己做实验时，用<code>strace</code>命令跟踪系统调用的过程，发现<code>system</code>系统调用执行过程中，<strong>只<code>fork</code>了一次，<code>exec</code>了两次，主要的差异在于<code>/bin/sh</code>并没有<code>fork</code>子进程，而是直接执行了<code>exec(&quot;/bin/ed&quot;)</code></strong>。</p>
<h3 id="实验二">实验二</h3>
<p>我在shell下执行<code>sh -c &quot;sleep 5&quot;&amp;</code>命令，根据书中的示例，执行<code>ps -f</code>后应该可以看到4个进程：</p>
<ul>
<li><code>ps -f</code></li>
<li>当前shell进程</li>
<li>当前shell的子进程<code>sh</code></li>
<li><code>sh</code>的子进程<code>sleep 5</code>；</li>
</ul>
<p><strong>但实际我只看到三个进程，缺少子进程<code>sh</code>，<code>sleep 5</code>直接成为了当前shell的子进程</strong>：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>Storage:~ <span class="c1"># sh -c &#34;sleep 5&#34; &amp;</span>
<span class="ln">2</span><span class="o">[</span>1<span class="o">]</span> <span class="m">101978</span>
<span class="ln">3</span>Storage:~ <span class="c1"># ps -o pid,ppid,cmd</span>
<span class="ln">4</span>PID PPID CMD
<span class="ln">5</span><span class="m">48673</span> <span class="m">48658</span> -bash
<span class="ln">6</span><span class="m">101978</span> <span class="m">48673</span> sleep <span class="m">5</span>
<span class="ln">7</span><span class="m">103012</span> <span class="m">48673</span> ps -o pid,ppid,cmd
</code></pre></div><h2 id="system的返回值到底是多少">system的返回值到底是多少？</h2>
<p>使用如下程序对system的返回值进行实验：</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="ln"> 1</span><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="ln"> 2</span><span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
</span><span class="ln"> 3</span><span class="cp"></span><span class="kt">void</span> <span class="nf">main</span> <span class="p">()</span>
<span class="ln"> 4</span><span class="p">{</span>
<span class="ln"> 5</span>    <span class="kt">int</span> <span class="n">iStatus</span><span class="p">;</span>
<span class="ln"> 6</span>    <span class="n">iStatus</span> <span class="o">=</span> <span class="n">system</span><span class="p">(</span><span class="s">&#34;sleep 5&#34;</span><span class="p">);</span>
<span class="ln"> 7</span>    <span class="k">if</span> <span class="p">(</span><span class="n">WIFEXITED</span><span class="p">(</span><span class="n">iStatus</span><span class="p">))</span>
<span class="ln"> 8</span>    <span class="p">{</span>
<span class="ln"> 9</span>        <span class="n">printf</span><span class="p">(</span><span class="s">&#34;normal exit code %d ,status %x</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span><span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">iStatus</span><span class="p">),</span><span class="n">iStatus</span><span class="p">);</span>
<span class="ln">10</span>    <span class="p">}</span>
<span class="ln">11</span>
<span class="ln">12</span>    <span class="k">if</span> <span class="p">(</span><span class="n">WIFSIGNALED</span><span class="p">(</span><span class="n">iStatus</span><span class="p">))</span>
<span class="ln">13</span>    <span class="p">{</span>
<span class="ln">14</span>        <span class="n">printf</span><span class="p">(</span><span class="s">&#34;signal code %d ,status %x</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span><span class="n">WTERMSIG</span><span class="p">(</span><span class="n">iStatus</span><span class="p">),</span><span class="n">iStatus</span><span class="p">);</span>
<span class="ln">15</span>    <span class="p">}</span>
<span class="ln">16</span><span class="p">}</span>
</code></pre></div><p>在这个实验程序中，通过<code>system</code>系统调用执行<code>sleep 5</code>，sleep期间通过<code>ctrl+C</code>向main进程发送<code>SIGINT</code>信号，观察会打印出什么。</p>
<p>按照书中的实验结果，是会打印&quot;normal exit&hellip;&ldquo;的，原因分析：</p>
<ol>
<li>收到<code>SIGINT</code>信号的是<code>sleep 5</code>进程，<code>sleep 5</code>进程异常退出时，它的退出值为2；</li>
<li>但<code>sleep 5</code>的父进程是<code>/bin/sh</code>，而<strong>shell会将子进程的退出码（此处为2）+128作为退出值正常退出（低8位全0）</strong>。</li>
<li>所以父进程<code>main</code>通过<code>waitpid</code>得到<code>/bin/sh</code>的退出码为130，认为是正常执行退出（低8位全0）。</li>
</ol>
<p>然而我的实验结果却是打印&quot;signal code 2&rdquo;。原因如下：</p>
<p>实际上<code>sleep 2</code>是main函数的子进程，所以，它收到信号退出，main函数通过<code>waitpid</code>得到的子进程退出的状态码就是2了。</p>
<blockquote>
<p><strong>waitpid得到的状态码</strong>：<strong>低7位代表信号值，第8位代表是否core，高8位代表exit退出码。由此可见信号最多127种，exit最大值为255</strong>。</p>
<p>通过<code>WIFEXITED</code>宏判断低七位的信号值是否为0，0为正常退出；通过<code>WEXITSTATUS</code>得到高8位的exit值；否则通过<code>WIFSIGNALED</code>得到低七位的信号值。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>【问题定位】串口登录失败</title>
			<link>https://cvvz.github.io/post/arm-login-failed/</link>
			<pubDate>Fri, 24 May 2019 02:45:41 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/arm-login-failed/</guid>
			<description>问题现象 通过串口无法正常登录ARM设备，shell闪退。 问题分析 首先梳理一下SSH登录和串口登录两种方式的流程： 两种登录方式首先都要经过PA</description>
			<content type="html"><![CDATA[<h2 id="问题现象">问题现象</h2>
<p>通过串口无法正常登录ARM设备，shell闪退。</p>
<h2 id="问题分析">问题分析</h2>
<p>首先梳理一下SSH登录和串口登录两种方式的流程：</p>
<figure>
    <img src="/linux-login.drawio.svg" width="400px"/> 
</figure>

<ol>
<li>两种登录方式首先都要经过PAM插件的处理，SSH登录是由SSHD通过子进程的方式启动shell，串口登录则是拉起/bin/login，由/bin/login启动shell替代自己。</li>
<li>shell启动后，会去执行<code>/etc/profile</code>中的一系列脚本，配置系统环境。</li>
</ol>
<p>这里面可能出问题的环节有：PAM插件、/bin/login进程、/bin/bash和/etc/profile。但这个问题的现象是/bin/bash被拉起后，很快又闪退了，因此问题肯定出在/etc/profile脚本中。最后排查发现脚本中限制了串口登录的终端设备名为<code>ttyS0</code>，否则直接退出。但新的ARM设备的串行终端名称是<code>ttyAMA0</code>。</p>
]]></content>
		</item>
		
		<item>
			<title>【问题定位】/bin/bash无权限导致SSH登录失败</title>
			<link>https://cvvz.github.io/post/login-permission-denied/</link>
			<pubDate>Thu, 23 May 2019 02:21:56 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/login-permission-denied/</guid>
			<description>问题现象 SSH登录主机失败，提示错误：/bin/bash: Permission denied。 分析过程 Linux处理SSH远程登录的流程如下： SSHD进程后台</description>
			<content type="html"><![CDATA[<h2 id="问题现象">问题现象</h2>
<p>SSH登录主机失败，提示错误：<code>/bin/bash: Permission denied</code>。</p>
<h2 id="分析过程">分析过程</h2>
<p>Linux处理SSH远程登录的流程如下：</p>
<ol>
<li>SSHD进程后台监听SSH连接</li>
<li>当有连接到达时，启动一个子进程，并打开一个伪终端设备（pts）</li>
<li>从passwd中获得用户id、组id、shell路径等信息，并为打开的子进程设置进程uid、gid等</li>
<li>通过<code>exec</code>系统调用将子进程替换为登录shell（这里是<code>/bin/bash</code>），shell的0、1、2文件描述符和伪终端相连</li>
<li>用户通过伪终端和主机通信</li>
</ol>
<p>很明显这里的错误原因是因为设置了登陆用户的uid、gid的子进程没有<code>/bin/bash</code>的执行权限导致的，也就是第4步出错。通过<code>strace</code>跟踪sshd进程的系统调用，也印证了这一点：子进程确实是在执行<code>execve(/bin/bash)</code>时报<code>Permission denied</code>。</p>
<p>继续实验，发现只有非root组内用户登录才会报该错误。因此将一个已登录的root组内用户修改为非root组内用户后，通过<code>strace</code>跟踪其执行<code>/bin/bash</code>的过程，发现是在<code>open</code>某个动态库权限不足。查看该库文件及路径的权限，发现原本应该是<code>755</code>权限的<code>/usr</code>目录变成了<code>750</code>。通过<code>stat</code>命令查看该文件夹被修改的时间点，定位到是设备上电脚本中的一个bug。</p>
]]></content>
		</item>
		
		<item>
			<title>记一次编译错误的解决过程</title>
			<link>https://cvvz.github.io/post/compile-error/</link>
			<pubDate>Thu, 01 Nov 2018 20:31:15 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/compile-error/</guid>
			<description>最近开发新的需求需要使用某个外部模块的库文件，该模块在文档中提供了一个demo，但makefile文件编译报错。通过摸索和学习最终把demo</description>
			<content type="html"><![CDATA[<p>最近开发新的需求需要使用某个外部模块的库文件，该模块在文档中提供了一个demo，但makefile文件编译报错。通过摸索和学习最终把demo编译成功并运行起来，下面记录一下过程中碰到的问题并进行总结。</p>
<h2 id="so-not-found">so not found</h2>
<p>使用gcc编译c/c++程序时，编译时用<code>-I</code>指定头文件查找路径，<code>-L</code>指定库文件查找路径，<code>-l</code>具体指定依赖的库。</p>
<p>如果指定了<code>-L</code>，也使用<code>-l</code>链接了该库，但是报如下告警：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>warning: libxxx.so, needed by ./libyyy.so, not found <span class="o">(</span>try using -rpath or -rpath-link<span class="o">)</span>
</code></pre></div><p>说明该so依赖的其他so无法找到。使用<code>ldd</code>命令查看该so依赖的所有其他so，会有类似于</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>/usr/bin/ld: cannot find -lxxx
</code></pre></div><p>的打印，这时就需要找到被依赖的so所在的绝对路径，添加到<code>/etc/ld.so.conf</code>文件中，并执行<code>ldconfig</code>。</p>
<p>另一种办法是向环境变量<code>LD_LIBRARY_PATH</code>中添加路径，指定动态库加载路径；对应的静态库加载路径的环境变量名<code>LIBRARY_PATH</code>。</p>
<blockquote>
<p>注意: 使用<code>env</code>命令查看系统中若无环境变量<code>LD_LIBRARY_PATH</code>和<code>LIBRARY_PATH</code>，则需要使用<code>export</code>命令将变量变成环境变量，即该变量在子shell进程中也可见。但重新登录时该环境变量会消失。要想环境变量每次登录都存在，可以向<code>/etc/profile</code>文件尾用export添加环境变量。这是因为<strong>每次登录时系统会自动执行/etc/profile脚本</strong>。</p>
</blockquote>
<h2 id="file-format-not-recognized">file format not recognized</h2>
<p>编译时提示错误如：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>/usr/bin/ld:./libxxx.so: file format not recognized<span class="p">;</span> treating as linker script
<span class="ln">2</span>/usr/bin/ld:./libxxx.so:2: syntax error
</code></pre></div><p>意思是这个so文件格式不识别，ld试图将它当作链接文件来看待，但仍然出错。查看发现该so文件大小只有几字节，且附近有一个带后缀.1的文件libxxx.so.1。<strong>原因是该so文件实际是一个软链接文件，链接对象就是libxxx.so.1</strong>；但由于该模块提供的lib压缩包是在windows下解压后通过远程文件系统挂载到linux系统上的，软连接文件被当成普通文件解压了。解决办法是重新创建软连接或直接在linux下解压。</p>
<blockquote>
<p>so后面带的.1是版本号为1的意思。这是linux下动态库版本控制的一种方法。具体可以看<a href="https://cvvz.github.io/post/version-control-of-shared-object">动态链接库的版本控制</a>一文。</p>
</blockquote>
<h2 id="undefined-reference-to">undefined reference to</h2>
<p><code>undefined reference to</code> 即未定义的引用，表示某函数被声明了但是却没有找到对应的实现，这种情况是可以编译成功的，但是链接会失败。类似的还有<code>Undeclared references</code>，即未声明的引用，表示找不到函数声明。</p>
<p>出现这种情况只能考虑是编译时还有必要的库没有链接，对库文件夹中所有的库执行<code>nm</code>命令，过滤该函数名，找到该函数定义(<code>T类</code>)所在的库文件，并将其加入到编译链接库中。</p>
<blockquote>
<p><code>nm</code>用于打印库或可执行文件中的符号名：</p>
<ul>
<li>T类：是在库中定义的函数，用T表示；</li>
<li>U类：是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示；</li>
</ul>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>动态链接库的版本控制</title>
			<link>https://cvvz.github.io/post/version-control-of-shared-object/</link>
			<pubDate>Sat, 20 Oct 2018 21:00:51 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/version-control-of-shared-object/</guid>
			<description>DLL Hell DLL Hell：同一台机器上，运行着A和B两个程序，他们使用了同一个so；程序A在升级时使用新的so直接覆盖老的so，此时可能会造成程序B无</description>
			<content type="html"><![CDATA[<h2 id="dll-hell">DLL Hell</h2>
<p><strong><a href="https://en.wikipedia.org/wiki/DLL_Hell">DLL Hell</a></strong>：同一台机器上，运行着A和B两个程序，他们使用了同一个so；程序A在升级时使用新的so<strong>直接覆盖</strong>老的so，此时可能会造成程序B无法正常运行。</p>
<p>因此需要对动态链接库进行版本控制。</p>
<h2 id="so-name">so name</h2>
<p>在介绍版本控制前，需要先了解动态链接库的三种name：<code>real name</code>、<code>soname</code>、<code>link name</code>。</p>
<ul>
<li><strong>link name</strong>：<code>libxxx.so</code>称为动态链接库的<code>link name</code>。</li>
<li><strong>real name</strong>：实际编译出来的动态链接库是具有版本号后缀的，如<code>libxxx.so.x.y.z</code>，称为动态链接库的<code>real name</code>。
<blockquote>
<p>其中<code>x</code>代表主版本号，<code>y</code>代表小版本号，<code>z</code>代表duild号。</p>
</blockquote>
</li>
<li><strong>soname</strong>：<code>link name</code>+<code>主版本号</code>，即<code>libxxx.so.1</code>。</li>
</ul>
<h2 id="编译动态库">编译动态库</h2>
<p>编译动态链接库时要带上编译选项<code>-soname</code>以指定soname。例如编译动态库<code>libtest.so.1.0.0</code>时，编译方式如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>gcc -fPIC -o test.o -c test.c
<span class="ln">2</span>gcc -shared -Wl,-soname,libtest.so.1 -o libtest.so.1.0.0 test.o
</code></pre></div><p>通过<code>readelf -d</code>查看动态段，可以发现<code>soname</code>信息被记录到了<code>libtest.so.1.0.0</code>的文件头中：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="ln">1</span>readelf -d libtest.so.1.0.0 <span class="p">|</span> grep soname
<span class="ln">2</span> 0x0000000e <span class="o">(</span>SONAME<span class="o">)</span> Library soname: <span class="o">[</span>libtest.so.1<span class="o">]</span>
</code></pre></div><p><strong>此时执行<code>ldconfig</code>命令将自动生成<code>libtest.so.1</code>文件，它是一个指向<code>libtest.so.1.0.0</code>的软连接</strong>。</p>
<p>不难想到：</p>
<ul>
<li>如果主版本发生变化，新老版本的soname会发生变化。</li>
<li>如果小版本发生变化，新老版本的soname应该保持不变。</li>
</ul>
<h2 id="编译程序">编译程序</h2>
<p>以使用上面编译好的<code>libtest.so.1.0.0</code>动态库的程序为例，编译的标准步骤如下：</p>
<ol>
<li>创建一个指向real name文件的link name文件，即 <code>ln -s libtest.so.1.0.0 libtest.so</code></li>
<li>编译程序，通过指定<code>-ltest</code>，编译器会去查找<code>libtest.so</code>文件，但实际参与编译的是<code>libtest.so.1.0.0</code>文件</li>
<li>编译器发现<code>libtest.so.1.0.0</code>中记录着soname <code>libtest.so.1</code>，告诉程序在运行时应该引用<code>libtest.so.1</code></li>
<li>而<code>libtest.so.1</code>文件，则是通过执行<code>ldconfig</code>命令生成出来的指向<code>libtest.so.1.0.0</code>的软链接，所以程序实际运行过程中使用的是<code>libtest.so.1.0.0</code></li>
</ol>
<h2 id="升级动态库">升级动态库</h2>
<ol>
<li>小版本升级，比如从<code>libtest.so.1.0.0</code>升级为<code>libtest.so.1.1.1</code>。这个时候，按照约定它的soname<code>libtest.so.1</code>是不变的，所以使用者可以直接把新版本so丢到机器上，执行<code>ldconfig</code>，新生成的<code>libtest.so.1</code>就变成了指向<code>libtest.so.1.1.1</code>的软连接。小版本升级是后向兼容的，所以这里直接进行升级是没有问题的。</li>
<li>主版本升级，比如从<code>libtest.so.1.1.1</code>升级为<code>libtest.so.2.0.0</code>。这个时候，按照约定它的soname变成了<code>libtest.so.2</code>，此时<code>ldconfig</code>生成的软连接为<code>libtest.so.2</code>，指向<code>libtest.so.2.0.0</code>。一般主版本升级会有后向兼容性问题，但是由于使用了新的soname，因此对使用老版本so的程序没有影响。</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>关于进程和线程的一些思考</title>
			<link>https://cvvz.github.io/post/process-and-thread/</link>
			<pubDate>Sat, 23 Jun 2018 20:34:56 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/process-and-thread/</guid>
			<description>从“程序”开始 对于UNIX操作系统，程序是存放在磁盘上的ELF文件（可以通过file命令查看文件类型） 对于windows操作系统，程序是存放</description>
			<content type="html"><![CDATA[<h2 id="从程序开始">从“程序”开始</h2>
<ul>
<li>对于UNIX操作系统，程序是存放在磁盘上的<strong>ELF文件</strong>（可以通过<code>file</code>命令查看文件类型）</li>
<li>对于windows操作系统，程序是存放在磁盘上的<strong>PE文件</strong>，其中最常见的是<code>.exe</code>文件。</li>
</ul>
<p>编译器将高级语言编写成的程序编译成机器码，操作系统将ELF文件读入内存后，ELF文件中的<strong>代码段</strong>也就是CPU可以执行的机器码（可以通过<code>readelf</code>命令查看ELF文件的代码段内容），CPU从内存中读取机器码并执行。</p>
<h2 id="为进程分配资源">为进程分配资源</h2>
<p>进程产生的标志是：内核为每一个进程都分配了一个<code>task_struct</code>结构体，在<code>task_struct</code>中记录了这个进程所拥有的资源，如全局变量、虚拟内存等，所以说<strong>进程是资源分配的最小单位</strong>。</p>
<h2 id="调度线程">调度线程</h2>
<p><strong>线程是CPU调度的最小单位</strong>，也就是说<strong>内核进行调度的对象实际上是线程，而进程是负责为线程提供共享资源的</strong>。</p>
<p>一个进程中的多个线程共享这个进程的资源，但是<strong>它们虽然共享同一片虚拟内存，自身却拥有这片虚拟内存中的不同的栈空间</strong>；</p>
<h2 id="通信方式">通信方式</h2>
<p>由于同一进程中的线程共享资源，所以通信非常方便，直接读写同一块用户态内存即可，但是这必然就涉及到互斥和原子性问题。</p>
<p>而进程要实现通信则需要借助内核和文件，所有的IPC，都是把内核和文件充当交换信息的桥梁。</p>
<h2 id="上下文切换">上下文切换</h2>
<p>cpu调度基本的单位是线程，所以在运行不同的线程时，会导致<strong>cpu上下文切换</strong>，即CPU寄存器和程序计数器的保存和更新。而根据被调度的线程是同一个进程里的还是不同进程里的，又分为<strong>线程上下文切换</strong>和<strong>进程上下文切换</strong>。</p>
<p>CPU上下文切换是需要CPU运行内核代码的，所以过多的cpu上下文切换会导致cpu将大量的时间都用来运行内核代码，导致真正的给用户态线程运行的时间变少。所以一般我们会根据机器的核数来决定进程的线程数量或者子进程数量，避免进行频繁的上下文切换。</p>
<p>由于线程共享进程中的虚拟内存空间，所以线程上下文切换时，<strong>不需要更新虚拟内存到物理内存的内存映射表</strong>。而进程上下文切换时，由于不同进程虚拟内存的改变，则要更新虚拟内存到物理内存的内存映射表。当内核找不到虚拟内存到物理内存的映射关系时，便会产生<code>缺页中断</code>。所以<strong>进程上下文切换后，程序执行更容易产生缺页中断</strong>，这也就是进程切换比线程切换对性能影响更大的原因。</p>
<h2 id="怎么理解linux中的线程是以进程的方式实现的">怎么理解Linux中的线程是以进程的方式实现的</h2>
<ul>
<li>对于支持线程的操作系统而言，如果一个进程中有N个线程，则存在一个进程描述符，依次轮流指向N个线程。这个进程描述符指明共享资源，包括内存空间和打开的文件。而每一个线程描述它们自己独享的资源。也就是说<strong>内核中描述线程的结构体和描述进程的结构体不同</strong>。</li>
<li>而在Linux中，则有N个<code>task_struct</code>数据结构，只是这些数据结构的某些资源项是共享的（指向同一片内存），某些是独占的。</li>
</ul>
<figure>
    <img src="/%e4%b8%8a%e4%b8%8b%e6%96%87%e5%88%87%e6%8d%a2.png" width="1000px"/> 
</figure>

]]></content>
		</item>
		
		<item>
			<title>Git笔记</title>
			<link>https://cvvz.github.io/post/usage-of-git/</link>
			<pubDate>Sat, 02 Jun 2018 23:41:24 +0800</pubDate>
			
			<guid>https://cvvz.github.io/post/usage-of-git/</guid>
			<description>整理一下最近学习的git知识，以及平时常用的git功能。 .git 使用git init或clone一个远端仓，会在本地建立一个.git目录。这个目录是</description>
			<content type="html"><![CDATA[<blockquote>
<p>整理一下最近学习的git知识，以及平时常用的git功能。</p>
</blockquote>
<h2 id="git">.git</h2>
<p>使用git init或clone一个远端仓，会在本地建立一个.git目录。<strong>这个目录是git仓的全部，把.git拷贝到其他目录下，就能在该目录下建立一个一模一样的git仓</strong>。</p>
<h2 id="缓存区staged">缓存区（staged）</h2>
<ul>
<li>对working derictoy中的文件做的改动，他们的状态是unstaged</li>
<li>使用 <code>git add</code>/<code>git rm</code>/<code>git mv</code> 将其送入缓存区（staged）</li>
<li>使用 <code>git commit</code> 提交缓存区中记录的改动。</li>
<li><code>git diff {filename}</code> 可以查看unstaged和staged中文件的不同</li>
<li><code>git diff --staged {filename}</code> 可以查看staged中的文件和原文件的不同</li>
<li>注意staged和<code>stash</code>的区别</li>
</ul>
<h2 id="上游分支">上游分支</h2>
<p><code>git clone</code>可以通过参数 <code>-b</code> 来指定clone远端仓库到本地后拉取哪条分支，不指定则默认拉取<code>master</code>；远端仓库中必须存在同名分支，作为本地分支的上游分支。</p>
<p>通过<code>git branch -vv</code> 或 <code>git status</code> 命令可以查看本地分支相比上游分支领先/落后多少个commit。</p>
<p><code>git checkout -b {local_branch} {remote_branch}</code>用来创建并切换分支，并指定该分支的上游分支。</p>
<h2 id="revert和reset">revert和reset</h2>
<p><code>git reset</code>把HEAD指针指向到某一个commit id，这次commit之后的所有commit都会被删除。</p>
<p><code>git revert</code>用来撤销某一次commit带来的变化，不会影响其他commit。revert本身也需要commit。</p>
<p>非fast-forward形式合并两条分支时，git会自动生成一个合并提交。如果想回退某条分支的merge操作，可以revert这次合并提交的commit，git会让你选择留下这次合并提交的哪一个父分支，另一个父分支所作的改动会被回退。</p>
<h2 id="如何修改一次历史commit">如何修改一次历史commit</h2>
<p>执行<code>git rebase -i {commitid}^</code>（commitid是想要修改的那次提交），git会以commitid的前一次提交作为base，采用交互式的方式，重新提交后面的每一次commit，将想要修改的那一次的提交命令设置为edit即可。</p>
]]></content>
		</item>
		
	</channel>
</rss>
